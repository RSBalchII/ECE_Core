[
  {
    "id": "CHANGELOG.md",
    "timestamp": 1766311214,
    "role": "file",
    "content": "# Context-Engine Changelog\r\n\r\n## [Unreleased]\r\n\r\n### Added\r\n- **Root Mic (Audio Input)**: Renamed `sovereign-mic.html` to `root-mic.html` and added \"Summarize & Clarify\" feature using the local Qwen2.5 model.\r\n- **Long-Form Transcription**: Fixed Whisper pipeline to support recordings >30s using chunking and striding.\r\n- **CozoDB Corruption Recovery**: Enhanced error handling for IndexedDB corruption with automatic fallback to in-memory database, manual recovery button, and timeout protection against hanging WASM calls.\r\n- **Bulk CozoDB Import Tool**: Added `tools/prepare_cozo_import.py` to transform `combined_memory.json` into the canonical `relations` payload (`cozo_import_memory.json`) for atomic bulk imports into CozoDB.\r\n- **Import Safety & Verification**: Added recommended import procedure and a post-import verification + backup step to avoid Schema Detachment.\r\n\r\n### Changed\r\n- **Ingestion Defaults**: Recommended batch size increased to 100 to prevent long-running slow writes that can desync CozoDB's in-memory metadata.\r\n\r\n---\r\n\r\n## [1.2.3] - 2025-12-19 \"Snapdragon Optimization\"\r\n\r\n### Added\r\n- **Qwen3 Support**: Added `Qwen3-4B-Instruct` to the verified model list.\r\n- **Llama 3.2 Support**: Added `Llama-3.2-1B-Instruct` as the recommended lightweight model.\r\n- **Buffer Override**: Implemented `appConfig` overrides to force high-end performance on 256MB GPUs (fixing Adreno throttling).\r\n\r\n### Changed\r\n- **Portable Launchers**: All scripts now use `--user-data-dir=\"%~dp0browser_data\"` for fully portable, clean-running instances.\r\n- **Model Config**: Refactored `CreateMLCEngine` initialization to handle both URL-based and ID-based model definitions reliably.\r\n\r\n---\r\n\r\n## [1.2.2] - 2025-12-18 \"Hermes & CozoDB Fixes\"\r\n\r\n### Fixed\r\n- **Hermes Model Support**: Fixed 404 errors for OpenHermes and NeuralHermes by mapping them to the verified `Mistral-v0.3` WASM library.\r\n- **CozoDB Date Formatting**: Removed `strftime` dependency from WASM queries (causing `no_implementation` errors) and moved date formatting to client-side JavaScript.\r\n- **Drag-and-Drop Import**: Fixed handling of CozoDB `relations` export format in drag-and-drop ingestion.\r\n- **Documentation**: Established `specs/mlc-urls.md` as a registry for verified WASM binaries.\r\n\r\n---\r\n\r\n## [1.2.1] - 2025-12-15 \"DeepSeek & CozoDB Stabilization\"\r\n\r\n### Fixed\r\n- **CozoDB Initialization**: Resolved `CozoDb.new_from_path is not a function` error by switching to `CozoDb.new_from_indexed_db` for persistent browser storage (IndexedDB backend).\r\n- **WASM Memory Access**: Fixed \"memory access out of bounds\" error in `sovereign-db-builder.html` and `unified-coda.html` by correctly stringifying JSON parameters passed to `db.run()`.\r\n- **DeepSeek Configuration**: Fixed \"Cannot find model record\" error in `unified-coda.html` by decoupling the internal model ID from the HuggingFace URL.\r\n\r\n### Added\r\n- **Sovereign Hub**: Created `tools/index.html` as a central dashboard for the Console, Builder, and Log Viewer.\r\n- **Log Viewer Upgrade**: Refactored `tools/log-viewer.html` to use `BroadcastChannel` for real-time, polling-free log updates from the console.\r\n- **Expanded File Support**: Updated `sovereign-db-builder.html` to support ingestion of a wider range of code and config files (ts, rs, go, sql, ini, xml, etc.).\r\n\r\n## [1.2.0] - 2025-12-15 \"Sovereign Architecture\"\r\n\r\n### Added\r\n- **Sovereign Console**: Created `tools/unified-coda.html`, a standalone WASM-based chat console with local CozoDB (OPFS) and Transformers.js.\r\n- **Sovereign DB Builder**: Created `tools/sovereign-db-builder.html` for ingesting JSON logs into the browser-based database.\r\n- **Model Support**: Expanded `unified-coda.html` to support the full range of MLC-compatible models (Llama 3.2, Qwen 2.5, Gemma 2, etc.).\r\n\r\n### Changed\r\n- **Log Management**: Updated backend logging to truncate files at 500KB to prevent disk bloat.\r\n\r\n## [1.1.0] - 2025-12-14 \"Browser Stability & Bridge Fixes\"\r\n\r\n### Fixed\r\n- **WebGPU Bridge**: Patched `tools/webgpu_bridge.py` to accept any model name, resolving 503 errors during embedding requests.\r\n- **LLM Client**: Updated `backend/src/llm.py` to correctly identify and use the configured embedding model (`nomic-embed-text-v1.5`).\r\n- **Coda Chat**: Modified `backend/src/recipes/coda_chat.py` to sanitize and truncate `retrieve_memory` outputs. Large JSON payloads were causing `Maximum call stack size exceeded` errors in the browser-based LLM worker.\r\n\r\n## [1.0.0] - 2025-12-08 \"Infinite Context Pipeline\"\r\n\r\n### Added\r\n- **Phase 1: Hardware Foundation**: All LLM servers now boot with 65,536 context window and Flash Attention enabled\r\n- **Phase 2: Context Rotation Protocol**: ContextManager automatically rotates context when exceeding 55k tokens\r\n- **Phase 3: Graph-R1 Enhancement**: GraphReasoner now retrieves ContextGist memories for historical continuity\r\n- **ContextGist Nodes**: Neo4j storage for compressed historical context summaries with chronological links\r\n- **Context Shifting Logic**: Intelligent distillation of old content using Distiller agent with gist creation\r\n- **Documentation Structure**: Organized specs/ directories at root, backend, and anchor levels with spec.md, plan.md, tasks.md\r\n- **Infinite Context Pipeline**: Complete end-to-end implementation enabling unlimited context window management\r\n\r\n### Changed\r\n- **Upgraded Context Windows**: All start scripts now default to 64k context for infinite work capability\r\n- **Enhanced Memory Architecture**: Neo4j now stores both active memories and ContextGist historical summaries\r\n- **Improved ContextManager**: Added check_and_rotate_context() logic with automatic gist creation and storage\r\n- **Extended GraphReasoner**: Updated retrieval queries to include ContextGist nodes alongside regular memories\r\n- **Optimized Distiller Integration**: Enhanced _chunk_and_distill functionality for context rotation use cases\r\n- **Refined Archivist Agent**: Now coordinates context rotation and gist management operations\r\n\r\n### Fixed\r\n- **Context Limit Elimination**: Fixed issue where systems would crash when reaching context limits\r\n- **Memory Continuity**: Resolved problems with historical context access across conversation boundaries\r\n- **Performance Optimization**: Fixed inefficiencies in large context handling with 64k window support\r\n- **Rotation Logic**: Fixed issues with context preservation during rotation cycles\r\n\r\n---\r\n\r\n## [0.9.0] - 2025-12-07 \"Reka & Local Proxy\"\r\n\r\n### Added\r\n- **Reka Configuration**: Full support for Reka-Flash-3-21B (Q4_K_S) with 16k context, stop tokens, and optimized LLaMa server flags.\r\n- **Local API Proxy**: Added `scripts/local_api_proxy.py` to enforce static API keys for local LLaMa instances (fixes Cline extension \"OpenAI API Key\" requirement).\r\n- **VS Code Integration**: Added `.vscode/settings.json` template and `VSCODE_CLINE_SETUP.md` for seamless local development.\r\n- **MCP Health**: Added `/health` endpoint to Unified Launcher for better compatibility.\r\n\r\n### Fixed\r\n- **MCP Routing**: Resolved duplicate `/mcp` prefix in Unified Launcher routes (`/mcp/tools` is now accessible).\r\n- **LLM Client**: Added `stop` token support to API payloads and local GGUF generation.\r\n\r\n## [0.8.0] - 2025-12-06 \"Archivist Protocol\"\r\n\r\n### Added\r\n- **Archivist Ingestion**: Implemented `POST /archivist/ingest` endpoint to accept live data from the browser.\r\n- **Memory Schema**: Enforced **Directive INJ-A1** (`PlaintextMemory`) for immutable \"Page-Store\" records.\r\n- **Modular DOM Adapters**:\r\n    - `GeminiAdapter`: Clean extraction for Google Gemini.\r\n    - `ChatGPTAdapter`: Clean extraction for ChatGPT.\r\n    - `ClaudeAdapter`: Clean extraction for Claude.ai.\r\n    - `GenericAdapter`: Universal fallback for any webpage.\r\n- **Extension UI**: Added **[Save to Memory]** button to the Side Panel for manual ingestion.\r\n\r\n### Fixed\r\n- **Encoding Crash**: Resolved Windows `charmap` error by enforcing `PYTHONIOENCODING='utf-8'`.\r\n- **Server Stability**: Fixed startup crashes caused by `MemoryWeaver` resource contention.\r\n\r\n## [0.7.0] - 2025-12-06 \"Operation Concrete\"\r\n\r\n### Added\r\n- **Browser Bridge**: A Chrome Extension (MV3) capable of:\r\n    - **Voice**: Streaming chat interface via Side Panel.\r\n    - **Sight**: Context injection (reading active tab).\r\n    - **Hands**: JavaScript execution on active pages (User-ratified).\r\n- **Backend Architecture**: Migrated from monolithic scripts to **Modular Recipes** (MAX Agentic Cookbook standard).\r\n    - `CodaChatRecipe`: Handles orchestration, context, and tool execution.\r\n- **Persistence**: Side panel now saves chat history to local storage.\r\n- **Markdown Support**: Chat interface renders code blocks and syntax highlighting.\r\n\r\n### Changed\r\n- **Identity**: System formally renamed from \"Sybil\" to **\"Coda\"**.\r\n- **Documentation**: Adopted `specs/` based documentation policy.\r\n\r\n### Fixed\r\n- **Audit Logger**: Patched critical `NameError` in streaming endpoints.\r\n- **Security**: Hardened extension execution via `world: \"MAIN\"` to bypass strict CSP on some sites.\r\n\r\n---\r\n\r\n## [0.6.0] - 2025-11-30 \"Operation MCP Integrated\"\r\n\r\n### Added\r\n- **MCP Integration**: Complete integration of MCP server into main ECE Core server\r\n- **Unified Endpoint**: All MCP functionality now available at `/mcp` on main server (port 8000)\r\n- **Memory Tools**: Enhanced MCP tools for memory operations:\r\n    - `add_memory` - Add to Neo4j memory graph\r\n    - `search_memories` - Search memory graph with relationships\r\n    - `get_summaries` - Get session summaries\r\n- **Configuration**: New `mcp_enabled` setting in config.yaml to toggle integration\r\n- **Authentication**: MCP endpoints now inherit main server authentication settings\r\n\r\n### Changed\r\n- **Architecture**: MCP server no longer runs as separate process, now integrated into main ECE server\r\n- **Endpoints**: MCP tools now accessed via `/mcp/tools` and `/mcp/call` instead of separate server\r\n- **Deployment**: Simplified deployment - no need to start separate MCP service\r\n- **Resources**: Reduced memory footprint by eliminating duplicate server processes\r\n\r\n### Fixed\r\n- **Connection Issues**: Resolved intermittent connection failures between ECE and external MCP server\r\n- **Latency**: Reduced tool call latency by eliminating inter-service communication overhead\r\n- **Synchronization**: Fixed race conditions in concurrent tool executions\r\n\r\n---\r\n\r\n## [0.5.1] - 2025-11-29 \"Memory Weaver Security Audit\"\r\n\r\n### Added\r\n- **Security Hardening**: Added input validation for all GraphReasoner queries\r\n- **Audit Trail**: Enhanced logging for all automated relationship repairs\r\n- **Circuit Breakers**: Added fail safes for Weaver operations\r\n\r\n### Changed\r\n- **Weaver Engine**: Refactored to use parameterized queries, preventing Cypher injection\r\n- **Permission Model**: Strengthened access controls for relationship modification operations\r\n\r\n### Fixed\r\n- **Cypher Injection**: Patched vulnerability in Neo4j relationship queries\r\n- **Race Conditions**: Fixed concurrency issues in automated repair operations\r\n- **Resource Exhaustion**: Added limits to prevent DoS via excessive repair requests\r\n\r\n---\r\n\r\n## [0.5.0] - 2025-11-28 \"Memory Weaver (Automated Repair)\"\r\n\r\n### Added\r\n- **Memory Weaver Engine**: Automated system for detecting and repairing broken relationships in Neo4j\r\n- **Similarity Detection**: Embedding-based relationship discovery for linking related memories\r\n- **Audit System**: Complete traceability for all automated repairs with `auto_commit_run_id`\r\n- **Rollback Capability**: Deterministic reversal of automated changes via `rollback_commits_by_run.py`\r\n- **Scheduler**: Background maintenance tasks for continuous graph integrity\r\n\r\n### Changed\r\n- **Graph Maintenance**: Automated relationship repair now runs as background process\r\n- **Quality Assurance**: Enhanced relationship validation with similarity scoring\r\n- **Traceability**: All automated changes now logged with unique run identifiers\r\n\r\n### Fixed\r\n- **Orphaned Nodes**: Automatically discovers and connects isolated memories\r\n- **Broken Links**: Repairs missing relationships between related concepts\r\n- **Data Drift**: Corrects inconsistent metadata across related nodes\r\n\r\n---\r\n\r\n## [0.4.0] - 2025-11-25 \"Graph-R1 Implementation\"\r\n\r\n### Added\r\n- **Graph Reasoner**: Iterative \"Think â†’ Query â†’ Retrieve â†’ Rethink\" reasoning engine\r\n- **Q-Learning Retrieval**: Reinforcement learning for optimized memory access patterns\r\n- **Markovian Reasoning**: Chunked thinking with state preservation across context shifts\r\n- **Multi-Hop Queries**: Complex graph traversal for answering compound questions\r\n- **Cognitive Agents**: Plugin architecture for specialized reasoning tasks\r\n\r\n### Changed\r\n- **Retrieval Method**: Replaced simple vector search with Graph-R1 retrieval\r\n- **Memory Access**: Graph-based traversal now primary method for context assembly\r\n- **Agent Architecture**: Modular cognitive agents for specialized tasks\r\n- **Context Building**: Enhanced context with relationship-aware retrieval\r\n\r\n### Fixed\r\n- **Context Relevance**: Improved precision of memory retrieval\r\n- **Chain of Thought**: Better preservation of reasoning pathways\r\n- **Memory Decay**: Reduced loss of historical context in long conversations\r\n\r\n---\r\n\r\n## [0.3.1] - 2025-11-20 \"Security Hardening\"\r\n\r\n### Added\r\n- **API Authentication**: Token-based authentication for all endpoints\r\n- **Rate Limiting**: Request throttling to prevent abuse\r\n- **Input Sanitization**: Enhanced validation for all user inputs\r\n- **Audit Logging**: Comprehensive logging of all sensitive operations\r\n- **Secure Defaults**: Safe configuration presets for common deployment scenarios\r\n\r\n### Changed\r\n- **Security Model**: Implemented zero-trust architecture\r\n- **Credential Handling**: Secure storage and transmission of API keys\r\n- **Access Controls**: Granular permissions for different API endpoints\r\n\r\n### Fixed\r\n- **Authentication Bypass**: Patched critical vulnerability in API access\r\n- **Data Exposure**: Resolved information disclosure in error messages\r\n- **Injection Attacks**: Fixed potential SQL injection in Neo4j queries\r\n\r\n---\r\n\r\n## [0.3.0] - 2025-11-15 \"Neo4j Migration Complete\"\r\n\r\n### Added\r\n- **Neo4j Integration**: Complete migration from SQLite to Neo4j graph database\r\n- **Redis Cache**: Hot cache layer for active session management\r\n- **Graph Schema**: Formal schema definition for memory relationships\r\n- **Migration Tools**: Scripts to migrate existing SQLite data to Neo4j\r\n- **Backup System**: Automated graph backup and restoration procedures\r\n\r\n### Changed\r\n- **Storage Architecture**: Tiered storage (Redis hot cache + Neo4j persistent)\r\n- **Query Language**: Cypher queries for graph operations\r\n- **Relationship Modeling**: Graph-based connections between memories\r\n- **Indexing Strategy**: Graph-based indices for faster retrieval\r\n\r\n### Fixed\r\n- **Performance**: Significantly improved query performance for complex relationships\r\n- **Scalability**: Better handling of large-scale memory graphs\r\n- **Consistency**: Stronger data integrity with ACID-compliant transactions\r\n\r\n---\r\n\r\n## [0.2.0] - 2025-10-30 \"Cognitive Agents\"\r\n\r\n### Added\r\n- **Verifier Agent**: Fact-checking via empirical distrust protocol\r\n- **Archivist Agent**: Memory maintenance and staleness detection\r\n- **Distiller Agent**: Content summarization and extraction\r\n- **Agent Framework**: Plugin system for extensible cognitive capabilities\r\n- **Truth Scoring**: Provenance-aware fact-checking with primary source priority\r\n\r\n### Changed\r\n- **Memory Hygiene**: Automated maintenance of memory quality\r\n- **Verification Process**: Evidence-based fact-checking system\r\n- **Quality Assurance**: Continuous assessment of memory reliability\r\n- **Maintenance Schedule**: Regular memory grooming operations\r\n\r\n### Fixed\r\n- **Hallucinations**: Reduced false information in responses\r\n- **Stale Information**: Automatic detection and updating of outdated memories\r\n- **Data Quality**: Improved content validation and cleaning procedures\r\n\r\n---\r\n\r\n## [0.1.0] - 2025-09-15 \"Initial Architecture\"\r\n\r\n### Added\r\n- **Core Backend**: Initial ECE_Core with SQLite memory system\r\n- **Anchor Interface**: Terminal interface for user interaction\r\n- **Basic Memory**: Text-based memory storage and retrieval\r\n- **LLM Integration**: Support for various local LLM servers\r\n- **Plugin System**: Extensible tool architecture (UTCP)\r\n\r\n### Changed\r\n- **Foundation**: Established core architecture patterns\r\n- **API Design**: Defined RESTful API structure for components\r\n\r\n### Fixed\r\n- **Basic Functionality**: Initial implementation of core features",
    "source": "CHANGELOG.md"
  },
  {
    "id": "kill-edge.bat",
    "timestamp": 1766214451,
    "role": "file",
    "content": "@echo off\r\necho ðŸ”ª Killing all Microsoft Edge processes...\r\ntaskkill /F /IM msedge.exe /T\r\necho.\r\necho âœ… Edge terminated. You can now run 'launch-edge-unsafe.bat' cleanly.\r\npause\r\n",
    "source": "kill-edge.bat"
  },
  {
    "id": "launch-chromium-d3d12.bat",
    "timestamp": 1766311214,
    "role": "file",
    "content": "@echo off\r\nsetlocal EnableDelayedExpansion\r\n\r\n:: Define the User Data Directory (Project Relative)\r\nset \"USER_DATA=%~dp0browser_data\"\r\nif not exist \"%USER_DATA%\" mkdir \"%USER_DATA%\"\r\n\r\n:: Define Flags for D3D12 (Default for Windows)\r\nset \"FLAGS=--user-data-dir=\"%USER_DATA%\" --ignore-gpu-blocklist --enable-webgpu-developer-features --enable-unsafe-webgpu --enable-dawn-features=allow_unsafe_apis --disable-gpu-watchdog\"\r\nset \"URL=http://localhost:8000/tools/model-server-chat.html\"\r\n\r\necho ---------------------------------------------------\r\necho ðŸ” Detecting Browsers...\r\necho ---------------------------------------------------\r\n\r\nset \"count=0\"\r\n\r\n:: 1. Check Microsoft Edge\r\nif exist \"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Microsoft Edge\"\r\n    set \"path[!count!]=C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\"\r\n)\r\n\r\n:: 2. Check Google Chrome\r\nif exist \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome\"\r\n    set \"path[!count!]=C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\r\n) else if exist \"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome (x86)\"\r\n    set \"path[!count!]=C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"\r\n) else if exist \"%LOCALAPPDATA%\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome (User)\"\r\n    set \"path[!count!]=%LOCALAPPDATA%\\Google\\Chrome\\Application\\chrome.exe\"\r\n)\r\n\r\n:: 3. Check Brave\r\nif exist \"C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Brave Browser\"\r\n    set \"path[!count!]=C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe\"\r\n)\r\n\r\n:: Check if any found\r\nif %count%==0 (\r\n    echo âŒ No compatible Chromium browser found.\r\n    pause\r\n    exit /b\r\n)\r\n\r\n:: Display Menu\r\necho Select a browser to launch:\r\nfor /L %%i in (1,1,%count%) do (\r\n    echo [%%i] !name[%%i]!\r\n)\r\necho.\r\n\r\n:prompt\r\nset /p \"choice=Enter number (1-%count%): \"\r\n\r\n:: Validate Input\r\nif \"%choice%\"==\"\" goto prompt\r\nif %choice% LSS 1 goto prompt\r\nif %choice% GTR %count% goto prompt\r\n\r\nset \"BROWSER=!path[%choice%]!\"\r\nset \"BROWSER_NAME=!name[%choice%]!\"\r\n\r\necho.\r\necho ðŸš€ Launching %BROWSER_NAME% with D3D12 (Default) backend...\r\necho Path: \"%BROWSER%\"\r\necho Data: \"%USER_DATA%\"\r\necho.\r\n\r\n\"%BROWSER%\" %FLAGS% %URL%\r\npause\r\n",
    "source": "launch-chromium-d3d12.bat"
  },
  {
    "id": "launch-chromium-vulkan.bat",
    "timestamp": 1766311214,
    "role": "file",
    "content": "@echo off\r\nsetlocal EnableDelayedExpansion\r\n\r\n:: Define the User Data Directory (Project Relative)\r\nset \"USER_DATA=%~dp0browser_data\"\r\nif not exist \"%USER_DATA%\" mkdir \"%USER_DATA%\"\r\n\r\n:: Define Flags (Critical for Snapdragon)\r\nset \"FLAGS=--user-data-dir=\"%USER_DATA%\" --ignore-gpu-blocklist --enable-webgpu-developer-features --enable-unsafe-webgpu --enable-dawn-features=allow_unsafe_apis --enable-features=Vulkan --use-angle=vulkan --disable-gpu-watchdog\"\r\nset \"URL=http://localhost:8000/tools/model-server-chat.html\"\r\n\r\necho ---------------------------------------------------\r\necho ðŸ” Detecting Browsers (Vulkan Mode)...\r\necho ---------------------------------------------------\r\n\r\nset \"count=0\"\r\n\r\n:: 1. Check Microsoft Edge\r\nif exist \"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Microsoft Edge\"\r\n    set \"path[!count!]=C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\"\r\n)\r\n\r\n:: 2. Check Google Chrome\r\nif exist \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome\"\r\n    set \"path[!count!]=C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\r\n) else if exist \"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome (x86)\"\r\n    set \"path[!count!]=C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"\r\n) else if exist \"%LOCALAPPDATA%\\Google\\Chrome\\Application\\chrome.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Google Chrome (User)\"\r\n    set \"path[!count!]=%LOCALAPPDATA%\\Google\\Chrome\\Application\\chrome.exe\"\r\n)\r\n\r\n:: 3. Check Brave\r\nif exist \"C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe\" (\r\n    set /a count+=1\r\n    set \"name[!count!]=Brave Browser\"\r\n    set \"path[!count!]=C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe\"\r\n)\r\n\r\n:: Check if any found\r\nif %count%==0 (\r\n    echo âŒ No compatible Chromium browser found.\r\n    pause\r\n    exit /b\r\n)\r\n\r\n:: Display Menu\r\necho Select a browser to launch:\r\nfor /L %%i in (1,1,%count%) do (\r\n    echo [%%i] !name[%%i]!\r\n)\r\necho.\r\n\r\n:prompt\r\nset /p \"choice=Enter number (1-%count%): \"\r\n\r\n:: Validate Input\r\nif \"%choice%\"==\"\" goto prompt\r\nif %choice% LSS 1 goto prompt\r\nif %choice% GTR %count% goto prompt\r\n\r\nset \"BROWSER=!path[%choice%]!\"\r\nset \"BROWSER_NAME=!name[%choice%]!\"\r\n\r\necho.\r\necho ðŸš€ Launching %BROWSER_NAME% with VULKAN backend...\r\necho Path: \"%BROWSER%\"\r\necho Data: \"%USER_DATA%\"\r\necho.\r\n\r\n\"%BROWSER%\" %FLAGS% %URL%\r\npause\r\n",
    "source": "launch-chromium-vulkan.bat"
  },
  {
    "id": "README.md",
    "timestamp": 1766346821,
    "role": "file",
    "content": "# Context Engine (Sovereign Edition)\r\n\r\n> **Philosophy:** Your mind, augmented. Your data, sovereign. Your tools, open.\r\n\r\nA **Browser-Native** cognitive extraction system. No servers. No cloud. No installation.\r\nJust you, your browser, and your infinite context.\r\n\r\n---\r\n\r\n## âš¡ Quick Start\r\n\r\n1.  **Download** this repository.\r\n2.  **Open** `tools/index.html` in Chrome or Edge.\r\n3.  **Click** \"Double Click to Launch\" on the Console.\r\n\r\n*That's it. You are running a local LLM with persistent Graph Memory.*\r\n\r\n---\r\n\r\n## ðŸ—ï¸ Architecture\r\n\r\nThe system runs entirely in `tools/` using WebAssembly (WASM).\r\n\r\n### 1. The Sovereign Loop\r\n```mermaid\r\ngraph TD\r\n    User -->|Input| HTML[model-server-chat.html]\r\n    \r\n    subgraph Browser_Memory [\"Two Birds, One Stone\"]\r\n        HTML -->|Store/Retrieve| Cozo[\"CozoDB WASM\"]\r\n        Cozo -->|Persist| IDB[\"IndexedDB/OPFS\"]\r\n    end\r\n    \r\n    subgraph Cognitive_Engine\r\n        HTML -->|Context + Prompt| WebLLM[\"DeepSeek-R1 (WASM)\"]\r\n        WebLLM -->|Reasoning Trace| HTML\r\n    end\r\n```\r\n\r\n### 2. Core Components\r\n*   **Brain**: `model-server-chat.html` - Runs the Graph-R1 Reasoning Loop. Now uses **Hybrid Search** (Vector + Lexical) and supports SOTA models (Qwen 3, Gemma 3).\r\n*   **Memory**: `CozoDB (WASM)` - Stores relations (`*memory`) and vectors. Persists to browser IndexedDB.\r\n*   **Stomach**: `sovereign-db-builder.html` - Ingests files into the graph. Now \"Multisensory-Ready\" (Phase A): accepts images/audio as references.\r\n\r\n---\r\n\r\n## ðŸ“š Documentation\r\n\r\n*   **Architecture**: [specs/spec.md](specs/spec.md)\r\n*   **Roadmap**: [specs/plan.md](specs/plan.md)\r\n*   **Memory Schema**: [specs/architecture/memory-layer.spec.md](specs/architecture/memory-layer.spec.md)\r\n*   **WASM Layer**: [specs/architecture/sovereign-wasm.spec.md](specs/architecture/sovereign-wasm.spec.md)\r\n\r\n---\r\n\r\n## ðŸ§¹ Legacy Support\r\nThe old Python/Neo4j backend has been **archived**.\r\n*   Legacy README: [archive/v1_python_backend/README_LEGACY.md](archive/v1_python_backend/README_LEGACY.md)\r\n*   Legacy Code: `archive/v1_python_backend/`",
    "source": "README.md"
  },
  {
    "id": "read_all.py",
    "timestamp": 1766386539,
    "role": "file",
    "content": "#!/usr/bin/env python3\r\n\"\"\"\r\nRoot Reader: Aggregates content from relevant project files for orchestration.\r\n\r\nThis script scans the project directory and combines the content of source code,\r\nconfiguration, and documentation files into a single text file (combined_text.txt).\r\n\r\nIt respects the current project structure:\r\n- Root level scripts and docs\r\n- tools/: Sovereign Core (JS/HTML/CSS)\r\n- specs/: System Specifications\r\n- scripts/: CI/Utility scripts\r\n\"\"\"\r\nimport argparse\r\nimport json\r\nimport os\r\nfrom typing import List, Tuple, Any\r\n\r\ndef find_project_root(start_path: str | None = None) -> str:\r\n    \"\"\"\r\n    Locate project root by looking for indicators like .git, package.json, README.md\r\n    \"\"\"\r\n    if start_path is None:\r\n        start_path = os.path.abspath(__file__)\r\n\r\n    path = os.path.abspath(start_path)\r\n    if os.path.isfile(path):\r\n        path = os.path.dirname(path)\r\n\r\n    root_indicators = (\".git\", \"package.json\", \"README.md\")\r\n    while True:\r\n        if any(os.path.exists(os.path.join(path, ind)) for ind in root_indicators):\r\n            return path\r\n        parent = os.path.dirname(path)\r\n        if parent == path:\r\n            return os.getcwd()\r\n        path = parent\r\n\r\ndef get_allowed_files(project_root: str) -> List[Tuple[str, str]]:\r\n    \"\"\"\r\n    Returns list of (file_path, section_name) for all relevant project files.\r\n    \"\"\"\r\n    allowed_files = []\r\n    \r\n    # Extensions we care about\r\n    code_exts = {'.py', '.js', '.ts', '.html', '.css', '.json', '.md', '.bat', '.ps1', '.sh', '.yaml', '.yml'}\r\n    \r\n    # Directories to completely ignore\r\n    ignored_dirs = {'.git', '.venv', 'browser_data', 'archive', '__pycache__', 'node_modules', '.github'}\r\n    \r\n    # Files to ignore\r\n    ignored_files = {\r\n        'package-lock.json', \r\n        'combined_text.txt', \r\n        'cozo_lib_wasm_bg.wasm',\r\n        'combined_memory.json',\r\n        'cozo_import_memory.json'\r\n    }\r\n\r\n    for root, dirs, files in os.walk(project_root):\r\n        # Filter directories in-place to avoid walking into ignored ones\r\n        dirs[:] = [d for d in dirs if d not in ignored_dirs and not d.startswith('.')]\r\n        \r\n        rel_root = os.path.relpath(root, project_root)\r\n        section = \"ROOT\" if rel_root == \".\" else rel_root.replace(os.sep, \"_\").upper()\r\n\r\n        for f in files:\r\n            if f in ignored_files:\r\n                continue\r\n            \r\n            ext = os.path.splitext(f)[1].lower()\r\n            if ext in code_exts:\r\n                full_path = os.path.join(root, f)\r\n                allowed_files.append((full_path, section))\r\n                \r\n    return allowed_files\r\n\r\ndef to_yaml_style(obj: Any, indent: int = 0) -> str:\r\n    \"\"\"\r\n    Recursively converts a JSON-compatible object to a YAML-like string.\r\n    \"\"\"\r\n    lines = []\r\n    prefix = \"  \" * indent\r\n    \r\n    if isinstance(obj, dict):\r\n        for k, v in obj.items():\r\n            if isinstance(v, (dict, list)):\r\n                lines.append(f\"{prefix}{k}:\")\r\n                lines.append(to_yaml_style(v, indent + 1))\r\n            else:\r\n                # Handle multiline strings safely\r\n                v_str = str(v)\r\n                if '\\n' in v_str:\r\n                     lines.append(f\"{prefix}{k}: |\")\r\n                     for line in v_str.split('\\n'):\r\n                         lines.append(f\"{prefix}  {line}\")\r\n                else:\r\n                    lines.append(f\"{prefix}{k}: {v}\")\r\n    elif isinstance(obj, list):\r\n        for item in obj:\r\n            if isinstance(item, (dict, list)):\r\n                lines.append(f\"{prefix}-\")\r\n                # For list items that are objects, we want the properties to align slightly differently\r\n                # But for simplicity in this custom dumper:\r\n                sub = to_yaml_style(item, indent + 1)\r\n                lines.append(sub)\r\n            else:\r\n                lines.append(f\"{prefix}- {item}\")\r\n    else:\r\n        return f\"{prefix}{obj}\"\r\n\r\n    return \"\\n\".join(lines)\r\n\r\ndef create_project_corpus(\r\n    output_file: str | None = None,\r\n    dry_run: bool = False,\r\n):\r\n    \"\"\"\r\n    Aggregates content from project files into a single corpus.\r\n    \"\"\"\r\n    project_root = find_project_root()\r\n    output_file = output_file or os.path.join(project_root, \"combined_text.txt\")\r\n\r\n    print(f\"Project Root Detected: {project_root}\")\r\n    allowed_files = get_allowed_files(project_root)\r\n\r\n    if not allowed_files:\r\n        print(f\"No relevant files found in '{project_root}'.\")\r\n        return\r\n\r\n    print(f\"Found {len(allowed_files)} files to process.\")\r\n\r\n    if dry_run:\r\n        print(f\"Dry run enabled â€” would process {len(allowed_files)} files:\")\r\n        for file_path, section in allowed_files:\r\n            print(f\"  - {os.path.relpath(file_path, project_root)} ({section})\")\r\n        return\r\n\r\n    memory_records = []\r\n\r\n    with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\r\n        # Add a file map at the very top for the orchestrator\r\n        outfile.write(\"=== PROJECT FILE MAP ===\\n\")\r\n        for file_path, section in allowed_files:\r\n            rel_path = os.path.relpath(file_path, project_root)\r\n            outfile.write(f\"- {rel_path} ({section})\\n\")\r\n        outfile.write(\"========================\\n\\n\")\r\n\r\n        for file_path, section in allowed_files:\r\n            rel_path = os.path.relpath(file_path, project_root)\r\n            print(f\"Processing '{rel_path}'...\")\r\n            try:\r\n                with open(file_path, \"rb\") as raw_file:\r\n                    raw_data = raw_file.read()\r\n                if not raw_data:\r\n                    continue\r\n                \r\n                try:\r\n                    decoded_content = raw_data.decode(\"utf-8\")\r\n                except UnicodeDecodeError:\r\n                    decoded_content = raw_data.decode(\"utf-8\", errors=\"replace\")\r\n\r\n                ext = os.path.splitext(file_path)[1].lower()\r\n                final_content = decoded_content\r\n                \r\n                # Upgrade: Convert JSON to YAML-like text\r\n                if ext == '.json':\r\n                    try:\r\n                        json_obj = json.loads(decoded_content)\r\n                        # Use pretty print json as a reliable fallback or strict yaml style\r\n                        # The user asked for \"YAML-like string (key: value) or pretty-printed JSON (indent=2)\"\r\n                        # Let's try our YAML converter first, it's cleaner for reading.\r\n                        final_content = to_yaml_style(json_obj)\r\n                    except Exception:\r\n                        # Fallback to original content if parsing fails\r\n                        pass\r\n\r\n                outfile.write(f\"--- START OF FILE: {rel_path} ---\\n\")\r\n                outfile.write(final_content)\r\n                if not final_content.endswith('\\n'):\r\n                    outfile.write('\\n')\r\n                outfile.write(f\"--- END OF FILE: {rel_path} ---\\n\\n\")\r\n\r\n                # Store for JSON memory export (Node structure)\r\n                memory_records.append({\r\n                    \"id\": rel_path,\r\n                    \"timestamp\": int(os.path.getmtime(file_path)),\r\n                    \"role\": \"file\",\r\n                    \"content\": final_content,\r\n                    \"source\": rel_path\r\n                })\r\n\r\n            except Exception as e:\r\n                print(f\"Error processing '{rel_path}': {e}\")\r\n\r\n    # Save the combined memory records for Builder ingestion\r\n    memory_file = os.path.join(project_root, \"combined_memory.json\")\r\n    with open(memory_file, \"w\", encoding=\"utf-8\") as f:\r\n        json.dump(memory_records, f, indent=2, ensure_ascii=False)\r\n    print(f\"Memory records saved to '{memory_file}'.\")\r\n\r\n    print(f\"\\nAggregation complete. Corpus saved to '{output_file}'.\")\r\n\r\ndef _parse_cli() -> argparse.Namespace:\r\n    p = argparse.ArgumentParser(description=\"Aggregate project code and docs for orchestration.\")\r\n    p.add_argument(\r\n        \"--out\",\r\n        \"-o\",\r\n        default=None,\r\n        help=\"Output file path (defaults to combined_text.txt in project root)\",\r\n    )\r\n    p.add_argument(\r\n        \"--dry-run\",\r\n        action=\"store_true\",\r\n        help=\"Show what would be processed without writing the combined file\",\r\n    )\r\n    return p.parse_args()\r\n\r\nif __name__ == \"__main__\":\r\n    args = _parse_cli()\r\n    create_project_corpus(\r\n        output_file=args.out,\r\n        dry_run=args.dry_run,\r\n    )",
    "source": "read_all.py"
  },
  {
    "id": "secure-bridge-launch.ps1",
    "timestamp": 1766311214,
    "role": "file",
    "content": "<#\r\n.SYNOPSIS\r\n    Launches the WebGPU Bridge with an ephemeral Firewall rule.\r\n.DESCRIPTION\r\n    1. Picks a random port (or uses -Port).\r\n    2. Adds a Windows Firewall 'Allow' rule for that port.\r\n    3. Starts webgpu_bridge.py.\r\n    4. Removes the Firewall rule immediately upon exit.\r\n#>\r\n\r\nparam (\r\n    [int]$Port = 0\r\n)\r\n\r\n# 1. Pick Port\r\nif ($Port -eq 0) {\r\n    $Port = Get-Random -Minimum 9000 -Maximum 9999\r\n}\r\n\r\n$RuleName = \"SovereignCoda-Bridge-$Port\"\r\n\r\ntry {\r\n    Write-Host \"ðŸ”’ [Sovereign Coda] Configuring Secure Network...\" -ForegroundColor Cyan\r\n\r\n    # 2. Add Firewall Rule (Requires Admin usually, logic checks availability)\r\n    # Check if running as Admin\r\n    $isElevated = ([Security.Principal.WindowsPrincipal] [Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole([Security.Principal.WindowsBuiltInRole] \"Administrator\")\r\n    \r\n    if (-not $isElevated) {\r\n        Write-Warning \"âš ï¸  Not running as Administrator. Firewall rules might fail.\"\r\n        Write-Warning \"    Please right-click this script and 'Run as Administrator' if basic access fails.\"\r\n        Write-Host \"    Attempting to proceed (Localhost will work, LAN might not)...\" -ForegroundColor DarkGray\r\n    } else {\r\n        Write-Host \"    + Opening TCP Port $Port...\" -ForegroundColor Green\r\n        New-NetFirewallRule -DisplayName $RuleName -Direction Inbound -LocalPort $Port -Protocol TCP -Action Allow -Profile Private,Domain | Out-Null\r\n    }\r\n\r\n    # 3. Launch Bridge\r\n    $env:BRIDGE_PORT = $Port\r\n    $env:BRIDGE_HOST = \"0.0.0.0\"\r\n    \r\n    # Check if webgpu_bridge.py is in the same dir as script, or in tools/\r\n    $BridgeScript = Join-Path $PSScriptRoot \"webgpu_bridge.py\"\r\n    if (-not (Test-Path $BridgeScript)) {\r\n        $BridgeScript = Join-Path $PSScriptRoot \"tools\\webgpu_bridge.py\"\r\n    }\r\n    \r\n    if (-not (Test-Path $BridgeScript)) {\r\n        Write-Error \"Could not find webgpu_bridge.py in $PSScriptRoot or $PSScriptRoot\\tools\"\r\n        exit 1\r\n    }\r\n\r\n    Write-Host \"ðŸš€ Launching Bridge ($BridgeScript) on Port $Port...\" -ForegroundColor Cyan\r\n    python $BridgeScript\r\n\r\n} catch {\r\n    Write-Error \"An error occurred: $_\"\r\n} finally {\r\n    # 4. Cleanup\r\n    if ($isElevated) {\r\n        Write-Host \"`nðŸ”’ [Sovereign Coda] Cleaning up Firewall Rules...\" -ForegroundColor Cyan\r\n        try {\r\n            Remove-NetFirewallRule -DisplayName $RuleName -ErrorAction SilentlyContinue\r\n            Write-Host \"    + Rule '$RuleName' Removed.\" -ForegroundColor Green\r\n        } catch {\r\n            Write-Warning \"Failed to remove firewall rule. Please remove '$RuleName' manually.\"\r\n        }\r\n    }\r\n}\r\n",
    "source": "secure-bridge-launch.ps1"
  },
  {
    "id": "start-sovereign-console.bat",
    "timestamp": 1766171656,
    "role": "file",
    "content": "@echo off\r\necho Starting Sovereign Console Server...\r\n\r\necho.\r\necho Local Access: http://localhost:8000/\r\n\r\necho.\r\necho Network Access (for phone/other devices):\r\nfor /f \"tokens=*\" %%a in ('python -c \"import socket; s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM); s.connect(('8.8.8.8', 80)); print(s.getsockname()[0]); s.close()\"') do set IP=%%a\r\necho http://%IP%:8000/\r\necho.\r\n\r\ncd tools\r\n\r\necho Launching WebGPU Bridge (API Backend)...\r\nstart \"WebGPU Bridge\" cmd /k python webgpu_bridge.py\r\n\r\necho Launching File Server...\r\npython -m http.server 8000\r\npause",
    "source": "start-sovereign-console.bat"
  },
  {
    "id": "scripts\\ci\\check_docs.py",
    "timestamp": 1766241700,
    "role": "file",
    "content": "#!/usr/bin/env python3\r\n\"\"\"CI doc check script (Sovereign Era).\r\n\r\nVerifies the presence of critical spec files defined in specs/doc_policy.md.\r\n\"\"\"\r\nfrom __future__ import annotations\r\n\r\nimport os\r\nimport sys\r\nfrom pathlib import Path\r\n\r\n\r\nREPO_ROOT = Path(__file__).resolve().parents[2]\r\n\r\n\r\ndef main() -> int:\r\n    # 1. Check Core Specs (per specs/doc_policy.md Rule 3)\r\n    expected = [\r\n        REPO_ROOT / \"specs\" / \"spec.md\",\r\n        REPO_ROOT / \"specs\" / \"plan.md\",\r\n        REPO_ROOT / \"specs\" / \"tasks.md\",\r\n        REPO_ROOT / \"specs\" / \"doc_policy.md\",\r\n    ]\r\n    \r\n    missing = [str(p) for p in expected if not p.exists()]\r\n    if missing:\r\n        print(\"[FAIL] Missing core specification files:\")\r\n        for m in missing:\r\n            print(f\"  - {m}\")\r\n        return 2\r\n\r\n    # 2. Check README\r\n    readme = REPO_ROOT / \"README.md\"\r\n    if not readme.exists():\r\n        print(\"[FAIL] README.md not found\")\r\n        return 2\r\n\r\n    text = readme.read_text(encoding=\"utf-8\")\r\n    lower = text.lower()\r\n    \r\n    # 3. Simple Content Check (Sovereign Context Engine)\r\n    # We relax the strict \"UTCP\" check as architecture evolves.\r\n    checks = [\r\n        (\"context engine\", \"Project name 'Context Engine' not found in README\"),\r\n    ]\r\n    \r\n    failed = []\r\n    for token, msg in checks:\r\n        if token not in lower:\r\n            failed.append(msg)\r\n            \r\n    if failed:\r\n        print(\"[FAIL] README checks failed:\")\r\n        for f in failed:\r\n            print(f\"  - {f}\")\r\n        return 2\r\n\r\n    print(\"[OK] Sovereign Doc Checks Passed\")\r\n    return 0\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    sys.exit(main())\r\n",
    "source": "scripts\\ci\\check_docs.py"
  },
  {
    "id": "specs\\doc_policy.md",
    "timestamp": 1766070969,
    "role": "file",
    "content": "# Documentation Policy (Context-Engine)\r\n\r\n**Master Policy for all directories. Code is authoritative; documentation supports it.**\r\n\r\n---\r\n\r\n## Rule 1: Minimize Documentation\r\n\r\n- Code is the source of truth. Documentation explains *why* and guides *how*, but never replaces code.\r\n- Default assumption: No docs needed unless setup is genuinely ambiguous or painful.\r\n- LLM-generated reference docs are archived to `/archive/` after they're used.\r\n\r\n---\r\n\r\n## Rule 2: Allowed Documentation Per Directory\r\n\r\n### Root Level\r\n- **README.md** â€” 100 words. Answer: \"What is this repo?\"\r\n- **CHANGELOG.md** â€” Version history and major changes\r\n- **STARTUP.md** â€” Quick start (if needed)\r\n- **specs/** â€” Central spec layer (see Rule 3)\r\n\r\n### `backend/`, `tools/`, `extension/`, `scripts/`\r\n- **README.md** â€” Single sentence. Answer: \"What does this directory do?\"\r\n- **CONFIGURATION.md** â€” Only if env setup is non-obvious (backend only)\r\n- **No additional .md files** in directory root (see Rule 3)\r\n\r\n### `backend/src/`, `tools/src/`, `extension/src/`\r\n- No separate documentation. Inline code comments with `#file:specs/...` references.\r\n\r\n---\r\n\r\n## Rule 3: Specification Layer (`specs/`)\r\n\r\nThe `specs/` directory is the **single source of architectural truth**.\r\n\r\n### Core Files\r\n- **spec.md** â€” High-level system architecture (read this first)\r\n- **plan.md** â€” Roadmap and phases\r\n- **tasks.md** â€” Implementation task queue\r\n- **doc_policy.md** â€” This file (documentation governance)\r\n- **mlc-urls.md** â€” Registry of verified MLC-LLM model URLs (see Rule 3.1)\r\n\r\n### Architecture Subdirectory\r\n- **specs/architecture/** â€” Deep technical specifications\r\n  - **sovereign-wasm.spec.md** â€” Browser-native layer (WebGPU, CozoDB, model-server-chat, builder)\r\n  - **memory-layer.spec.md** â€” Neo4j/Redis architecture and schemas\r\n  - **extension-bridge.spec.md** â€” Chrome extension design (injection, pause triggers)\r\n  - **agents.spec.md** â€” Agent system (Verifier, Distiller, Archivist)\r\n  - **api.spec.md** â€” FastAPI endpoints and protocols\r\n\r\n### Where Each Spec Goes\r\n- **Architectural overview or design decisions?** â†’ `specs/spec.md`\r\n- **Multi-phase roadmap?** â†’ `specs/plan.md`\r\n- **Implementation tasks?** â†’ `specs/tasks.md`\r\n- **Deep technical details** (schemas, data flow, algorithms)? â†’ `specs/architecture/<domain>.spec.md`\r\n- **Local directory context** (e.g., \"what does scripts/ do\")? â†’ `README.md` in that directory\r\n\r\n---\r\n\r\n## Rule 4: Deprecated/Generated Documentation\r\n\r\nAll LLM-generated reference documentation (tutorials, examples, detailed walkthroughs) should be:\r\n1. **Used locally** (for context during development)\r\n2. **Archived to `/archive/`** after they served their purpose\r\n3. **Never** left in active project root or major directories\r\n\r\nExamples of archived docs:\r\n- `archive/docs_removed/` â€” Outdated technical docs\r\n- `archive/anchor/` â€” Deprecated CLI interface docs\r\n- `archive/setup_docs/` â€” Legacy setup guides\r\n\r\n---\r\n\r\n## Rule 5: Cross-Referencing Specs\r\n\r\nWithin any spec file, use markdown links to other specs:\r\n\r\n```markdown\r\nFor memory architecture, see [Memory Layer Spec](architecture/memory-layer.spec.md).\r\nFor browser integration, see [Sovereign WASM Spec](architecture/sovereign-wasm.spec.md).\r\n```\r\n\r\nIn code files, use comments to reference specs:\r\n```python\r\n# Graph-R1 reasoning flow (see specs/architecture/agents.spec.md)\r\ndef graph_r1_query():\r\n    pass\r\n```\r\n\r\n---\r\n\r\n## Rule 6: Truth Precedence\r\n\r\nIf **code conflicts with documentation**:\r\n1. Code is correct\r\n2. Update the relevant spec file immediately\r\n3. Add a git note explaining the discrepancy\r\n\r\nIf **multiple specs conflict**:\r\n1. `spec.md` is authoritative for architecture\r\n2. `architecture/*.spec.md` fills in implementation details\r\n3. Code is the final arbiter\r\n\r\n---\r\n\r\n## Rule 7: Reality Constraint\r\n\r\nDocumentation must never:\r\n- Contradict the \"Empirical Distrust\" protocol (retrieve > internal knowledge)\r\n- Promise features not implemented in code\r\n- Reference deprecated repositories or APIs without clear deprecation notices\r\n\r\n---\r\n\r\n## Enforcement\r\n\r\n- **Review checklist:** Before merging PRs, verify no new .md files are scattered (should only be in specs/ or as single README.md per directory)\r\n- **Quarterly cleanup:** Archive generated/reference docs older than 3 months\r\n- **Broken links:** Use `specs/architecture/` links; verify they exist before committing\r\n\r\n---\r\n\r\n## Quick Reference\r\n\r\n| Question | Answer |\r\n|----------|--------|\r\n| Where's the architecture? | `specs/spec.md` |\r\n| Where's the roadmap? | `specs/plan.md` |\r\n| Where are the tasks? | `specs/tasks.md` |\r\n| How do I set up the backend? | `backend/CONFIGURATION.md` |\r\n| What's in tools/? | `tools/README.md` |\r\n| How do I understand WASM layer? | `specs/architecture/sovereign-wasm.spec.md` |\r\n| How do Neo4j/Redis work? | `specs/architecture/memory-layer.spec.md` |\r\n| How does the extension work? | `specs/architecture/extension-bridge.spec.md` |\r\n| Where are old docs? | `archive/docs_removed/` |\r\n\r\n---\r\n\r\n## CozoDB Import Format & Recovery\r\n\r\n**Purpose:** Describe the canonical JSON format used for bulk imports into the browser CozoDB instance and recovery steps when a Schema Detachment occurs.\r\n\r\n**Note:** As of HTML pivot, CozoDB runs entirely in browser WASM with IndexedDB persistence. Recovery procedures apply to browser-native tools in `tools/` directory.\r\n\r\n### Canonical Import JSON\r\nCozoDB expects a top-level JSON object with a `relations` array. Each relation should look like this:\r\n\r\n```json\r\n{\r\n  \"relations\": [\r\n    {\r\n      \"name\": \"memory\",\r\n      \"headers\": [\"id\",\"timestamp\",\"role\",\"content\",\"source\",\"embedding\"],\r\n      \"rows\": [\r\n        [\"id-1\", 1688790000000, \"system\", \"file text...\", \"path/to/file.md\", null],\r\n        [...]\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n- `id`: string, unique identifier (UUID or deterministic hash)\r\n- `timestamp`: integer, Unix ms\r\n- `role`: string, e.g., `system` or `user`\r\n- `content`: string, textual content (truncate if exceedingly large)\r\n- `source`: string, origin path or descriptor\r\n- `embedding`: either an array of floats (embedding vector) or `null` if embeddings will be computed later\r\n\r\n### Recovery: Schema Detachment\r\nWhen `export_relations({})` returns `{\"message\":\"missing field `relations` ...\"}` or queries report `query::relation_not_found`:\r\n1. Attempt non-destructive reattach:\r\n```js\r\nawait window.db.run(\":create memory { id: String => timestamp: Int, role: String, content: String, source: String, embedding: <F32; 384> } IF NOT EXISTS\");\r\n```\r\n2. If reattach fails, export raw OPFS/IndexedDB blobs and decode them locally using `tools/decode_cozo_blob.py`.\r\n3. Prefer bulk import from canonical source (`cozo_import_memory.json`) rather than reimporting individual rows.\r\n\r\n### Tooling & Best Practices\r\n- Use `tools/prepare_cozo_import.py` to create `cozo_import_memory.json` from `combined_memory.json`.\r\n- For a guaranteed atomic result: nuke the DB and `Force Import Relations from JSON` (or use `db.import_relations(payload)` in Console) with the produced file.\r\n- After import, run `export_relations({})` and persist the result (backup) plus verify by running `?[count] := *memory{id}`.\r\n\r\n---\r\n\r\n**Last Updated:** 2025-12-15  \r\n**Version:** 1.0  \r\n**Policy Owner:** Architecture Council\r\n",
    "source": "specs\\doc_policy.md"
  },
  {
    "id": "specs\\mlc-urls.md",
    "timestamp": 1766387187,
    "role": "file",
    "content": "# Verified MLC Model Registry\r\n\r\n**Status:** Living Document\r\n**Purpose:** Centralize trusted, verified URLs for MLC-LLM models and WASM libraries to prevent cache errors and guessing games.\r\n\r\n## Protocol for Adding\r\n1. **Verify** the URL returns 200 OK (use `curl -I`).\r\n2. **Test** the model loads in `model-server-chat.html` (or equivalent).\r\n3. **Commit** the entry here.\r\n\r\n---\r\n\r\n## Verified Models\r\n\r\n### Hermes Family (Users Favorites)\r\n\r\n| Model Name | HuggingFace ID | WASM Library URL | Status |\r\n| :--- | :--- | :--- | :--- |\r\n| **Hermes-3-Llama-3.2-3B** | `mlc-ai/Hermes-3-Llama-3.2-3B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Llama-3.2-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** |\r\n| **OpenHermes-2.5** | `mlc-ai/OpenHermes-2.5-Mistral-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** (via v0.3 engine) |\r\n| **NeuralHermes-2.5** | `mlc-ai/NeuralHermes-2.5-Mistral-7B-q3f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q3f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** (via v0.3 engine) |\r\n| **Hermes-2-Pro-Mistral** | `mlc-ai/Hermes-2-Pro-Mistral-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** (via v0.3 engine) |\r\n\r\n### Standard MLC Models\r\n\r\n| Model Name | HuggingFace ID | WASM Library URL | Status |\r\n| :--- | :--- | :--- | :--- |\r\n| **Llama-3.2-3B-Instruct** | `mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Llama-3.2-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** |\r\n| **DeepSeek-R1-Distill-Qwen** | `mlc-ai/DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** |\r\n\r\n### 14B Models (High-End)\r\n\r\n| Model Name | HuggingFace ID | WASM Library URL | Status |\r\n| :--- | :--- | :--- | :--- |\r\n| **Qwen 2.5 14B Instruct** | `mlc-ai/Qwen2.5-14B-Instruct-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2.5-14B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** |\r\n| **DeepSeek R1 Distill 14B** | `mlc-ai/DeepSeek-R1-Distill-Qwen-14B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2.5-14B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | âœ… **VERIFIED** (Shared WASM) |\r\n",
    "source": "specs\\mlc-urls.md"
  },
  {
    "id": "specs\\plan.md",
    "timestamp": 1766311214,
    "role": "file",
    "content": "# Root Coda Roadmap (V2.0)\r\n\r\n**Status:** Root Architecture Deployed\r\n**Focus:** Expansion, Agentic Capabilities, Multimodal.\r\n\r\n## Phase 1: Foundation (Completed)\r\n- [x] Pivot to WebLLM/WebGPU stack.\r\n- [x] Implement CozoDB (WASM) for memory.\r\n- [x] Create core HTML tools (`model-server-chat`, `sovereign-db-builder`, `log-viewer`).\r\n\r\n## Phase 2: Stabilization (Completed)\r\n- [x] Fix Model Loading (Quota/VRAM config).\r\n- [x] Add 14B Model Support (Qwen2.5, DeepSeek-R1).\r\n- [x] **Snapdragon Optimization**: Implemented Buffer Override (256MB).\r\n\r\n## Phase 2.5: Root Refactor (Completed)\r\n- [x] **Kernel Implementation**: Created `sovereign.js` (Unified Logger, State, Hardware).\r\n- [x] **The Ears**: Refactored `sovereign-mic.html` to Root Architecture.\r\n- [x] **The Stomach**: Refactored `sovereign-db-builder.html` to Root Architecture.\r\n- [x] **The Brain**: Refactored `model-server-chat.html` to Root Architecture (Graph-R1 preservation).\r\n\r\n## Phase 3: Expansion (Current)\r\n- [ ] **Agentic Capabilities**: Re-introduce Verifier/Distiller logic in JS.\r\n- [ ] **Mobile Optimization**: Polish mobile UX for `model-server-chat.html`.\r\n- [ ] **Hybrid RAG**: Optimize vector + graph retrieval weighting.\r\n\r\n## Phase 4: Federation\r\n- [ ] **Device Sync**: Sync IndexedDB across devices (Peer-to-Peer).\r\n- [ ] **Local-First Cloud**: Optional encrypted backup.",
    "source": "specs\\plan.md"
  },
  {
    "id": "specs\\spec.md",
    "timestamp": 1766382411,
    "role": "file",
    "content": "# Architecture Overview: Root Coda (v2.0)\r\n\r\n**Status:** Production (Root Architecture)\r\n**Philosophy:** 100% Local, 100% Browser, 100% Sovereign.\r\n\r\n## Core Stack\r\n\r\nThe system has evolved into **Root Coda**, a pure [WASM (WebAssembly)](https://webassembly.org/) ecosystem where the browser is the Operating System.\r\n\r\n### 1. The Kernel (`sovereign.js`)\r\n- **Role:** The central nervous system.\r\n- **Function:**\r\n  - **Unified Logging:** Broadcasts to `log-viewer` and Mission Control.\r\n  - **Reactive State:** Zero-dependency `Proxy` store for UI state.\r\n  - **Hardware Abstraction:** \"Snapdragon Fix\" (WebGPU buffer clamping) and Profile management.\r\n  - **Memory Driver:** Standardized CozoDB WASM initialization.\r\n\r\n### 2. The Compute (`web-llm`)\r\n- **Engine:** [WebLLM](https://webllm.mlc.ai/) (MLC-AI)\r\n- **Runtime:** WebGPU (Hardware accelerated)\r\n- **Models:**\r\n  - **SOTA (Latest):** Qwen 3 (4B, 8B) / Gemma 3 (1B) / Phi 3.5\r\n  - **High Performance:** SmolLM2 (1.7B, 360M) / Qwen2.5-3B\r\n  - **Legacy:** Qwen2.5-14B / DeepSeek-R1 (16GB+ VRAM)\r\n\r\n### 3. The Memory (`cozo-lib-wasm`)\r\n- **Database:** [CozoDB](https://cozodb.org/) (Datalog/Relational/Graph)\r\n- **Storage:** IndexedDB / OPFS (Origin Private File System) -> Persistent.\r\n- **Schema:**\r\n  - `*memory`: Stored relations (content, timestamp, embedding).\r\n    - **Multisensory (Phase A):** Now includes `mime_type` and `blob_ref` for binary file referencing.\r\n  - `*vectors`: HNSW vector index for semantic search.\r\n\r\n### 4. The Interfaces (Root Tools)\r\n- **Root Console** (`model-server-chat.html`): The **Brain**. Runs Graph-R1 in a **Web Worker** (`llm-worker.js`) to prevent UI freezing during inference.\r\n- **Root Builder** (`sovereign-db-builder.html`): The **Stomach**. Ingests files/logs into the Graph.\r\n- **Root Mic** (`sovereign-mic.html`): The **Ears**. Whisper-Tiny (WASM) + LLM cleanup.\r\n- **Log Viewer** (`log-viewer.html`): The **Nerves**. System-wide diagnostics.\r\n- **Root Dreamer** (`tools/root-dreamer.html`): The **Subconscious**. Background optimization and association.\r\n\r\n## Data Flow\r\n\r\n```mermaid\r\ngraph TD\r\n    User -->|Voice| Mic[Root Mic]\r\n    User -->|Files| Builder[Root Builder]\r\n    User -->|Chat| Console[Root Console]\r\n    \r\n    Mic -->|Text| Console\r\n    Builder -->|Insert| Cozo[CozoDB WASM]\r\n    \r\n    subgraph Browser Kernel\r\n        Console -->|Msg| Worker[LLM Worker]\r\n        Worker -->|Inference| WebGPU\r\n        Console -->|Query| Cozo\r\n        Cozo -->|Persist| IDB[IndexedDB]\r\n    end\r\n```\r\n\r\n## Critical Workflows\r\n\r\n### 1. The Reasoning Loop (Graph-R1)\r\n1. User input triggers **Hybrid Reflex** (Vector Embedding + Keyword/Regex search in CozoDB).\r\n2. **Context Manager** assembles a \"Virtual Prompt\" with retrieved clues.\r\n3. LLM executes **R1 Loop**:\r\n   - If answer found: Synthesize.\r\n   - If missing info: Request specific search (`NEED_CONTEXT: term`).\r\n4. Final answer streamed to user.\r\n\r\n### 2. Root Persistence\r\n- **Zero Backend:** Python is only used for serving static files (`http.server`).\r\n- **Portability:** The entire \"Brain\" is contained in `browser_data` and IndexedDB.\r\n\r\n## Reference Specs\r\n- [Sovereign WASM Spec](architecture/sovereign-wasm.spec.md) (Detailed Kernel Docs)\r\n- [Memory Layer Spec](architecture/memory-layer.spec.md)",
    "source": "specs\\spec.md"
  },
  {
    "id": "specs\\tasks.md",
    "timestamp": 1766382403,
    "role": "file",
    "content": "# Context-Engine Implementation Tasks\r\n\r\n## Current Work Queue (Root Architecture)\r\n\r\n### Completed - Root Refactor âœ…\r\n- [x] **Kernel**: Implement `tools/modules/sovereign.js`.\r\n- [x] **Mic**: Refactor `sovereign-mic.html` to use Kernel.\r\n- [x] **Builder**: Refactor `sovereign-db-builder.html` to use Kernel.\r\n- [x] **Console**: Refactor `model-server-chat.html` to use Kernel (Graph-R1).\r\n- [x] **Docs**: Update all specs to reflect Root Architecture.\r\n\r\n### Completed - Hardware Optimization ðŸ‰\r\n- [x] **WebGPU Buffer Optimization**: Implemented 256MB override for Adreno GPUs.\r\n- [x] **Model Profiles**: Added Lite, Mid, High, Ultra profiles.\r\n- [x] **Crash Prevention**: Context clamping for constrained drivers.\r\n- [x] **Mobile Optimization**: Service Worker (`llm-worker.js`) for non-blocking inference.\r\n\r\n## Phase 3: The Subconscious (Completed) âœ…\r\n- [x] **Root Dreamer**: Created `tools/root-dreamer.html` for background memory consolidation.\r\n- [x] **Ingestion Refinement**: Upgraded `read_all.py` to produce LLM-legible YAML.\r\n- [x] **Root Architecture Docs**: Finalized terminology (Sovereign -> Root).\r\n\r\n### Active Development - Expansion\r\n- [ ] **Agentic Tools**: Port Verifier/Distiller logic to `tools/modules/agents.js`.\r\n- [ ] **Multimodal**: Add image support to Builder (drag-and-drop embedding).\r\n- [ ] **Voice Output**: Add TTS to Console.\r\n\r\n## Phase 4: The Specialist Array\r\n- [ ] **Dataset Generation**: Samsung TRM / Distillation.\r\n- [ ] **Unsloth Training Pipeline**: RTX 4090 based fine-tuning.\r\n- [ ] **Model Merging**: FrankenMoE construction.\r\n\r\n## Backlog\r\n- [ ] **Federation Protocol**: P2P sync.\r\n- [ ] **Android App**: Wrapper for Root Coda.\r\n",
    "source": "specs\\tasks.md"
  },
  {
    "id": "specs\\architecture\\extension-bridge.spec.md",
    "timestamp": 1765839244,
    "role": "file",
    "content": "# Chrome Extension Bridge Specification\r\n\r\n**Silent context injection for corporate LLMs. Turn Gemini/ChatGPT into your \"dumb terminal\".**\r\n\r\n---\r\n\r\n## Identity\r\n\r\n- **Name:** Sovereign Context Bridge\r\n- **Target Platforms:** `gemini.google.com`, `chatgpt.openai.com` (extensible)\r\n- **Trigger:** 3-second pause in text input\r\n- **Injection Method:** Automatic text append before submission\r\n- **Data Source:** Local CozoDB (zero backend latency)\r\n\r\n---\r\n\r\n## Architecture Overview\r\n\r\n```\r\nUser types in gemini.google.com\r\n  â†“\r\nContent Script detects 3-second pause\r\n  â†“\r\nBackground Service Worker queries local CozoDB\r\n  â†“\r\nMemory results returned (< 100ms)\r\n  â†“\r\nContext Summary generated\r\n  â†“\r\nSilently append to text area (or insert as system instruction if available)\r\n  â†“\r\nUser hits Enter (normal flow)\r\n```\r\n\r\n---\r\n\r\n## Components\r\n\r\n### 1. Manifest (`manifest.json`)\r\n\r\n**MV3 Manifest Structure:**\r\n```json\r\n{\r\n  \"manifest_version\": 3,\r\n  \"name\": \"Sovereign Context Bridge\",\r\n  \"version\": \"1.0.0\",\r\n  \"description\": \"Silent context injection for LLM conversations\",\r\n  \"permissions\": [\r\n    \"activeTab\",\r\n    \"scripting\",\r\n    \"storage\",\r\n    \"webRequest\"\r\n  ],\r\n  \"host_permissions\": [\r\n    \"*://gemini.google.com/*\",\r\n    \"*://chatgpt.openai.com/*\"\r\n  ],\r\n  \"content_scripts\": [\r\n    {\r\n      \"matches\": [\"*://gemini.google.com/*\", \"*://chatgpt.openai.com/*\"],\r\n      \"js\": [\"content.js\"],\r\n      \"run_at\": \"document_start\"\r\n    }\r\n  ],\r\n  \"background\": {\r\n    \"service_worker\": \"background.js\"\r\n  },\r\n  \"action\": {\r\n    \"default_popup\": \"popup.html\",\r\n    \"default_title\": \"Sovereign Context Bridge\"\r\n  },\r\n  \"icons\": {\r\n    \"16\": \"images/icon-16.png\",\r\n    \"32\": \"images/icon-32.png\",\r\n    \"128\": \"images/icon-128.png\"\r\n  }\r\n}\r\n```\r\n\r\n### 2. Content Script (`content.js`)\r\n\r\n**Responsibilities:**\r\n- Inject status indicator into page\r\n- Detect user input in text area\r\n- Monitor for 3-second pause\r\n- Receive context from background worker\r\n- Inject context into textarea\r\n\r\n**Key Functions:**\r\n\r\n#### `detectTextArea()`\r\n```javascript\r\nfunction detectTextArea() {\r\n  // Platform-specific selectors\r\n  const selectors = {\r\n    'gemini.google.com': 'div[contenteditable=\"true\"], textarea',\r\n    'chatgpt.openai.com': 'textarea'\r\n  };\r\n  return document.querySelector(selectors[domain]);\r\n}\r\n```\r\n\r\n#### `setupPauseDetector()`\r\n```javascript\r\nlet inputTimeout;\r\nconst PAUSE_THRESHOLD = 3000; // 3 seconds\r\n\r\ntextArea.addEventListener('input', () => {\r\n  clearTimeout(inputTimeout);\r\n  inputTimeout = setTimeout(() => {\r\n    console.log('[Sovereign] 3-second pause detected, querying memories...');\r\n    chrome.runtime.sendMessage(\r\n      { action: 'queryMemories', query: getVisibleText() },\r\n      (response) => injectContext(response)\r\n    );\r\n  }, PAUSE_THRESHOLD);\r\n});\r\n```\r\n\r\n#### `injectContext(contextData)`\r\n```javascript\r\nfunction injectContext(contextData) {\r\n  const summary = `[Sovereign Context Injection at ${new Date().toLocaleTimeString()}]\\n${contextData.summary}\\n---\\n`;\r\n  \r\n  // For contenteditable (Gemini)\r\n  if (textArea.contentEditable === 'true') {\r\n    const currentText = textArea.textContent;\r\n    textArea.textContent = currentText + '\\n' + summary;\r\n  }\r\n  // For textarea (ChatGPT)\r\n  else {\r\n    textArea.value += '\\n' + summary;\r\n  }\r\n  \r\n  displayIndicator('âœ“ Context injected (memories found)', 'success');\r\n}\r\n```\r\n\r\n#### Status Indicator\r\n```javascript\r\nfunction displayIndicator(message, type) {\r\n  const indicator = document.getElementById('sovereign-indicator') || \r\n                    createIndicator();\r\n  indicator.textContent = message;\r\n  indicator.className = `sovereign-indicator ${type}`;\r\n  setTimeout(() => indicator.remove(), 5000);\r\n}\r\n```\r\n\r\n### 3. Background Service Worker (`background.js`)\r\n\r\n**Responsibilities:**\r\n- Maintain persistent connection to local CozoDB (if backend running)\r\n- Query memories based on visible text\r\n- Generate summaries\r\n- Handle pause trigger messages\r\n\r\n**Key Functions:**\r\n\r\n#### `queryMemories()`\r\n```javascript\r\nchrome.runtime.onMessage.addListener((request, sender, sendResponse) => {\r\n  if (request.action === 'queryMemories') {\r\n    queryMemoriesFromCozoDB(request.query)\r\n      .then(memories => ({\r\n        success: true,\r\n        memories: memories,\r\n        summary: generateSummary(memories)\r\n      }))\r\n      .then(sendResponse)\r\n      .catch(err => ({\r\n        success: false,\r\n        error: err.message\r\n      }));\r\n    return true; // Keep channel open for async response\r\n  }\r\n});\r\n```\r\n\r\n#### `queryMemoriesFromCozoDB(userInput)`\r\n```javascript\r\nasync function queryMemoriesFromCozoDB(userInput) {\r\n  try {\r\n    // Option 1: If backend API available\r\n    const response = await fetch('http://localhost:8000/memories/search', {\r\n      method: 'POST',\r\n      headers: { 'Content-Type': 'application/json' },\r\n      body: JSON.stringify({ query: userInput })\r\n    });\r\n    return response.json();\r\n  } catch (e) {\r\n    // Option 2: Fall back to local CozoDB via SharedArrayBuffer or WebWorker\r\n    console.warn('[Sovereign] Backend unavailable, querying local store...');\r\n    return queryLocalCozoDB(userInput);\r\n  }\r\n}\r\n```\r\n\r\n#### `generateSummary(memories)`\r\n```javascript\r\nfunction generateSummary(memories) {\r\n  if (memories.length === 0) return 'No relevant memories found.';\r\n  \r\n  const maxMemories = 3;\r\n  const relevant = memories.slice(0, maxMemories);\r\n  \r\n  return relevant\r\n    .map((m, idx) => `[Memory ${idx + 1}] ${m.content.substring(0, 100)}...`)\r\n    .join('\\n');\r\n}\r\n```\r\n\r\n### 4. Popup UI (`popup.html`)\r\n\r\n**Simple status page shown when user clicks extension icon:**\r\n\r\n```html\r\n<!DOCTYPE html>\r\n<html>\r\n<head>\r\n  <link rel=\"stylesheet\" href=\"styles.css\">\r\n</head>\r\n<body>\r\n  <div class=\"popup-container\">\r\n    <h3>ðŸ§  Sovereign Context Bridge</h3>\r\n    \r\n    <div id=\"status\">\r\n      <p>Status: <span id=\"status-badge\">â—</span></p>\r\n      <p id=\"status-text\">Initializing...</p>\r\n    </div>\r\n    \r\n    <div id=\"stats\">\r\n      <p>Memories cached: <span id=\"mem-count\">0</span></p>\r\n      <p>Last injection: <span id=\"last-inject\">Never</span></p>\r\n    </div>\r\n    \r\n    <button id=\"settings-btn\">âš™ï¸ Settings</button>\r\n    <button id=\"test-inject-btn\">ðŸ§ª Test Injection</button>\r\n  </div>\r\n  \r\n  <script src=\"popup.js\"></script>\r\n</body>\r\n</html>\r\n```\r\n\r\n---\r\n\r\n## Data Flow: Query â†’ Inject\r\n\r\n```\r\nStep 1: User types \"Tell me about Chronos\" in Gemini\r\n  â†“\r\nStep 2: Content script detects 3-second pause\r\n  â†“\r\nStep 3: Send message to background worker: {action: 'queryMemories', query: '...'}\r\n  â†“\r\nStep 4: Background worker queries memories\r\n  (Option A: /memories/search endpoint if backend available)\r\n  (Option B: Direct CozoDB query if local store accessible)\r\n  â†“\r\nStep 5: Return top-3 memories + summary\r\n  {\r\n    success: true,\r\n    memories: [\r\n      {id: \"123\", content: \"Chronos is about time management...\"},\r\n      {id: \"124\", content: \"In July session...\"},\r\n      {id: \"125\", content: \"Key insight: context rotation...\"}\r\n    ],\r\n    summary: \"[Memory 1] Chronos is about... [Memory 2] In July... [Memory 3] Key insight...\"\r\n  }\r\n  â†“\r\nStep 6: Content script injects into textarea:\r\n  \"Tell me about Chronos\r\n   \r\n   [Sovereign Context Injection at 14:32:05]\r\n   [Memory 1] Chronos is about time management...\r\n   [Memory 2] In July session we discovered...\r\n   [Memory 3] Key insight: context rotation prevents token loss...\r\n   ---\"\r\n  â†“\r\nStep 7: User presses Enter â†’ Gemini processes augmented prompt\r\n  â†“\r\nStep 8: Response includes your memory context!\r\n```\r\n\r\n---\r\n\r\n## Trigger Mechanisms\r\n\r\n### Primary: 3-Second Pause\r\n\r\n```javascript\r\n// User stops typing â†’ wait 3 seconds â†’ trigger query\r\nconst PAUSE_THRESHOLD = 3000;\r\nlet pauseTimer;\r\n\r\ntextArea.addEventListener('input', () => {\r\n  clearTimeout(pauseTimer);\r\n  pauseTimer = setTimeout(() => triggerMemoryQuery(), PAUSE_THRESHOLD);\r\n});\r\n```\r\n\r\n### Secondary: Manual Hotkey (Optional)\r\n\r\n```javascript\r\n// Ctrl+Shift+M to manually inject\r\ndocument.addEventListener('keydown', (e) => {\r\n  if (e.ctrlKey && e.shiftKey && e.code === 'KeyM') {\r\n    triggerMemoryQuery();\r\n  }\r\n});\r\n```\r\n\r\n---\r\n\r\n## Context Injection Format\r\n\r\n### Option 1: Append to User Text\r\n```\r\nTell me about Project Chronos\r\n\r\n[Sovereign Context - Memories]\r\n[Mem 1] Project Chronos explores infinite context windows...\r\n[Mem 2] Discovered in July: context rotation is key...\r\n[Mem 3] Verifier agent reduces hallucinations...\r\n---\r\n```\r\n\r\n### Option 2: System Instruction (if API allows)\r\n```json\r\n{\r\n  \"messages\": [\r\n    {\r\n      \"role\": \"system\",\r\n      \"content\": \"You have access to these contextual memories: [Mem 1] ... [Mem 2] ...\"\r\n    },\r\n    {\r\n      \"role\": \"user\",\r\n      \"content\": \"Tell me about Project Chronos\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n---\r\n\r\n## Configuration & Settings\r\n\r\n**User-Configurable (popup.js):**\r\n```javascript\r\nconst CONFIG = {\r\n  pauseThreshold: 3000,           // 3 seconds\r\n  maxMemoriesToInject: 3,          // Top 3\r\n  injectionFormat: 'append',       // or 'system-instruction'\r\n  enabledSites: {\r\n    'gemini.google.com': true,\r\n    'chatgpt.openai.com': true\r\n  },\r\n  backendUrl: 'http://localhost:8000',\r\n  fallbackToLocal: true            // Use local CozoDB if backend down\r\n};\r\n```\r\n\r\n---\r\n\r\n## Error Handling\r\n\r\n### Scenario 1: Backend Unavailable\r\n```\r\nâ†’ Fall back to local CozoDB (if accessible)\r\nâ†’ If local unavailable, show status: \"âš  No memories available\"\r\n```\r\n\r\n### Scenario 2: No Relevant Memories Found\r\n```\r\nâ†’ Display indicator: \"No relevant memories found\"\r\nâ†’ Still allow user to submit normally\r\n```\r\n\r\n### Scenario 3: Injection Failed\r\n```\r\nâ†’ Show error: \"Failed to inject context\"\r\nâ†’ Allow user to retry manually via button\r\n```\r\n\r\n---\r\n\r\n## Performance Targets\r\n\r\n- **Pause detection latency:** < 50ms\r\n- **Memory query latency:** < 100ms (local) or < 500ms (backend)\r\n- **Injection latency:** < 50ms\r\n- **Total E2E:** < 150ms (user should not notice delay)\r\n\r\n---\r\n\r\n## Privacy & Security\r\n\r\n- **Local-first:** All queries stay on user's machine\r\n- **No logging:** Extension doesn't upload queries to external services\r\n- **User control:** Manual disable via popup toggle\r\n- **Memory source:** Only accesses local CozoDB, never user's active Gemini text\r\n\r\n---\r\n\r\n## Platform Adaptations\r\n\r\n### For Gemini\r\n- **Text Area:** `div[contenteditable=\"true\"]`\r\n- **Submission:** Detect Enter key or \"Send\" button click\r\n- **Format:** Append to contenteditable div\r\n\r\n### For ChatGPT\r\n- **Text Area:** `textarea`\r\n- **Submission:** Detect Enter or Ctrl+Enter\r\n- **Format:** Append to textarea value\r\n\r\n### Future: Claude, Copilot, etc.\r\n- Extend `host_permissions` in manifest\r\n- Add platform-specific selector in `content.js`\r\n\r\n---\r\n\r\n## Related Specs\r\n\r\n- See [Sovereign WASM Spec](sovereign-wasm.spec.md) for CozoDB query patterns\r\n- See [Memory Layer Spec](memory-layer.spec.md) for memory retrieval\r\n- See [API Spec](api.spec.md) for `/memories/search` endpoint\r\n\r\n---\r\n\r\n**Last Updated:** 2025-12-15  \r\n**Status:** Design Phase (ready for implementation)\r\n**Development Phase:** Priority 3 (Sovereign Stack must be operational first)\r\n",
    "source": "specs\\architecture\\extension-bridge.spec.md"
  },
  {
    "id": "specs\\architecture\\memory-layer.spec.md",
    "timestamp": 1766133139,
    "role": "file",
    "content": "# Sovereign Memory Architecture (CozoDB + WASM)\r\n\r\n**Status:** Active (Production)\r\n**Implementation:** `tools/sovereign-db-builder.html` and `tools/model-server-chat.html`\r\n\r\nThe memory layer is a **Browser-Native Hybrid Graph-Vector Database** running entirely in WebAssembly (WASM). It consolidates the roles of the legacy Redis (Cache) and Neo4j (Graph) into a single, persistent CozoDB instance backed by IndexedDB/OPFS.\r\n\r\n---\r\n\r\n## 1. Core Schema (`*memory`)\r\n\r\nThe system uses a single unified relation for all ingested knowledge, serving both as the \"Long Term Memory\" and the source for \"Context Injection\".\r\n\r\n### Datalog Definition\r\n```datalog\r\n:create memory {\r\n    id: String\r\n    =>\r\n    timestamp: Int,         # Unix Epoch (ms) - Used for sorting/recency\r\n    role: String,           # 'user', 'assistant', 'system'\r\n    content: String,        # The raw text (truncated at 20KB for WASM stability)\r\n    source: String,         # File path or 'session'\r\n    embedding: <F32; 384>   # Vector for semantic search (all-MiniLM-L6-v2)\r\n}\r\n```\r\n\r\n### Fields\r\n*   **`id`** *(Key)*: Unique identifier. Format: `Timestamp-RandomID`.\r\n*   **`timestamp`**: Time of creation. Critical for \"Recent Memory\" retrieval.\r\n*   **`role`**: Speaker identity.\r\n*   **`content`**: The actual knowledge or chat message.\r\n*   **`source`**: Provenance (e.g., `logs/session-123.json` or `specs/spec.md`).\r\n*   **`embedding`**: 384-dimensional vector generated by `transformers.js`.\r\n\r\n---\r\n\r\n## 2. Persistence (The \"Sovereign Loop\")\r\n\r\n1.  **Write**: Data is written to CozoDB (WASM memory).\r\n2.  **Flush**: CozoDB automatically syncs to **IndexedDB** (`coda_memory` / `cozo_store`).\r\n3.  **Load**: On page refresh, the app probes IndexedDB and rehydrates the CozoDB instance.\r\n\r\n> **Zero-Loss Guarantee:** If the CozoDB instance crashes or the tab is closed, data is safe in IndexedDB.\r\n\r\n---\r\n\r\n## 3. Retrieval Strategies\r\n\r\n### A. Graph-R1 Recency (Default)\r\nRetrieves the most recent context to ground the reasoning loop.\r\n```datalog\r\n?[timestamp, role, source, content] := \r\n    *memory{timestamp, role, source, content}\r\n    :sort -timestamp\r\n    :limit 20\r\n```\r\n\r\n### B. Semantic Search (Vector)\r\nRetrieves context based on embedding similarity (Cosine distance).\r\n```datalog\r\n?[id, dist] := \r\n    *memory{id, embedding},\r\n    vec_l2(embedding, $query_vec)\r\n    :limit 10\r\n```\r\n\r\n---\r\n\r\n## 4. Import / Export\r\n\r\n*   **Import**: Drag & Drop `combined_memory.json` into `sovereign-db-builder.html`.\r\n*   **Export**: The builder allows exporting the full graph (with embeddings) to JSON for backup or transfer between devices.\r\n",
    "source": "specs\\architecture\\memory-layer.spec.md"
  },
  {
    "id": "specs\\architecture\\sovereign-wasm.spec.md",
    "timestamp": 1766359040,
    "role": "file",
    "content": "# Sovereign WASM Specification (Root Kernel)\r\n\r\n## Architecture Overview\r\nThe **Root Coda** system runs entirely in the browser using a unified Kernel (`sovereign.js`) that manages Compute (WebLLM) and Memory (CozoDB).\r\n\r\n## 1. The Kernel (`tools/modules/sovereign.js`)\r\nThe Kernel is the standard library for all Root Tools. It enforces consistency and safety.\r\n\r\n### 1.1 Hardware Abstraction (\"Snapdragon Fix\")\r\n**Problem**: Adreno GPUs (Snapdragon X Elite) and some mobile chips crash if a WebGPU buffer >256MB is requested, or if context exceeds 4k tokens without specific driver flags.\r\n**Solution**: `getWebGPUConfig(profile)`\r\n- **Lite**: Clamps buffer to 256MB, Context to 2048.\r\n- **Mid**: Clamps buffer to 1GB, Context to 4096.\r\n- **High/Ultra**: Unlocked.\r\n\r\n### 1.2 Unified Logging\r\n**Problem**: `console.log` is invisible on mobile or when running as a PWA.\r\n**Solution**: `SovereignLogger`\r\n- Broadcasts all logs to `BroadcastChannel('sovereign-logs')`.\r\n- Consumed by `log-viewer.html` for real-time remote debugging.\r\n\r\n### 1.3 Reactive State\r\n**Problem**: Spaghetti code updating DOM elements manually.\r\n**Solution**: `createStore(initialState)`\r\n- Lightweight `Proxy`-based store.\r\n- Components subscribe to changes: `subscribe((key, val) => updateUI(key, val))`.\r\n\r\n## 2. Memory Layer (CozoDB WASM)\r\nThe Kernel provides a standardized loader: `initCozo(wasmPath)`.\r\n\r\n### Data Portability\r\n- **Lossless Export**: The Root Builder features a \"Lossless Export\" button.\r\n- **Mechanism**: Dumps full Cozo relations (including vectors) to a JSON file.\r\n- **Use Case**: Transfer full \"Brain\" state between devices or backup.\r\n\r\n### Schema\r\n```datalog\r\n:create memory {\r\n    id: String \r\n    => \r\n    timestamp: Int, \r\n    role: String, \r\n    content: String, \r\n    source: String, \r\n    embedding: <F32; 384> \r\n}\r\n```\r\n\r\n## 3. Tool Bridge (Legacy Support)\r\nThe `webgpu_bridge.py` acts as a secure relay (websocket <-> http) for external tools (like VS Code extensions) to access the Browser's LLM.\r\n- **Input**: HTTP/REST (`/v1/chat/completions`)\r\n- **Output**: WebSocket (`ws://localhost:8080/ws/chat`)\r\n\r\n## 4. Audio Input (Root Mic)\r\n**Goal**: Pure client-side speech-to-text without sending audio to a cloud.\r\n\r\n### 4.1 Pipeline\r\n1. **Capture**: `MediaRecorder` (WebM) -> 48kHz decoding.\r\n2. **Preprocessing**:\r\n   - Downsampling to 16kHz (Whisper Native).\r\n   - **Noise Gate**: Discards audio if peak amplitude < 0.01 (Prevents transcribing silence).\r\n   - **Amplification**: Smart gain (max 5x) for quiet voices, but capped to avoid boosting noise floor.\r\n3. **Inference (WASM)**: \r\n   - Model: `Xenova/whisper-tiny.en` (Quantized).\r\n   - **Long-form Strategy**: Uses `chunk_length_s: 30` and `stride_length_s: 5` to process audio exceeding the model's native 30s window.\r\n4. **Post-Processing (Refinement)**:\r\n   - **Hallucination Filter**: Regex removal of common Whisper artifacts (e.g., \"[Music]\", \"Applause\", \"Amara.org\").\r\n   - **LLM Cleanup**: The raw transcript is passed to the local Qwen2.5 instance with a system prompt to fix grammar/punctuation without altering meaning.\r\n\r\n### 4.2 Summarization Loop\r\n- **Trigger**: User clicks \"Summarize & Clarify\" after a successful transcription.\r\n- **Process**: The cleaned transcript is sent back to the Local Kernel (Qwen2.5) with a prompt to \"summarize and clarify core meaning.\"\r\n- **Output**: The transcript is replaced by the summary, which is automatically copied to the clipboard.\r\n\r\n## 5. Parallel Compute (The Worker)\r\nTo prevent UI freezing during heavy inference, the LLM runs in a dedicated Web Worker.\r\n\r\n### 5.1 `tools/modules/llm-worker.js`\r\n- **Role**: Hosts the `MLCEngine` instance.\r\n- **Communication**: Uses `WebWorkerMLCEngineHandler` to bridge messages between the main thread and the worker.\r\n- **Benefit**: Ensures the UI remains responsive (scrolling, typing) even while the GPU is crunching tokens.",
    "source": "specs\\architecture\\sovereign-wasm.spec.md"
  },
  {
    "id": "templates\\waveai_ece.json",
    "timestamp": 1766171656,
    "role": "file",
    "content": "ece-local:\n  display:name: Sovereign Console (ECE)\n  display:order: 1\n  display:icon: microchip\n  display:description: Local WebGPU Model via ECE Bridge\n  ai:provider: custom\n  ai:apitype: openai-chat\n  ai:model: webgpu-chat\n  ai:thinkinglevel: medium\n  ai:endpoint: http://127.0.0.1:8080/v1/chat/completions\n  ai:apitoken: not-needed\n  ai:capabilities:\n    - tools",
    "source": "templates\\waveai_ece.json"
  },
  {
    "id": "tools\\CHANGELOG.md",
    "timestamp": 1765553559,
    "role": "file",
    "content": "# Changelog\r\n\r\nAll notable changes to the Sovereign Tools suite will be documented in this file.\r\n\r\n## [Unreleased]\r\n\r\n### Added\r\n- **WebGPU Bridge**: `webgpu_bridge.py` for proxying OpenAI API requests to browser workers.\r\n- **Chat Worker**: `webgpu-server-chat.html` for running LLMs in the browser.\r\n- **Embed Worker**: `webgpu-server-embed.html` for running embedding models in the browser.\r\n- **Mobile Chat**: `mobile-chat.html` for a lightweight, mobile-friendly UI.\r\n- **Log Viewer**: `log-viewer.html` for real-time server log monitoring.\r\n- **Documentation**: Added `README.md` and `specs/sovereign-tools.spec.md`.\r\n",
    "source": "tools\\CHANGELOG.md"
  },
  {
    "id": "tools\\code_tools.py",
    "timestamp": 1764687908,
    "role": "file",
    "content": "\"\"\"Top-level shim to re-export `anchor.tools.code_tools` for test imports that expect `tools.code_tools`.\r\n\"\"\"\r\ntry:\r\n    from anchor.tools.code_tools import *  # noqa: F401, F403\r\nexcept Exception:\r\n    # Minimal fallback implementations\r\n    def code_search(root: str, query: str, **kwargs):\r\n        return {\"root\": root, \"query\": query, \"count\": 0, \"results\": []}\r\n\r\n    def code_grep(root: str, query: str, **kwargs):\r\n        return {\"root\": root, \"query\": query, \"files\": 0, \"total_matches\": 0, \"results\": []}\r\n\r\n__all__ = [\"code_search\", \"code_grep\"]\r\n",
    "source": "tools\\code_tools.py"
  },
  {
    "id": "tools\\cozo_lib_wasm.js",
    "timestamp": 1765938677,
    "role": "file",
    "content": "import { loadAllFromIndexedDb, flushPendingWrites, writeToIndexedDb, setWriteCounter } from './indexeddb.js';\n\nlet wasm;\n\nconst heap = new Array(128).fill(undefined);\n\nheap.push(undefined, null, true, false);\n\nfunction getObject(idx) { return heap[idx]; }\n\nlet heap_next = heap.length;\n\nfunction dropObject(idx) {\n    if (idx < 132) return;\n    heap[idx] = heap_next;\n    heap_next = idx;\n}\n\nfunction takeObject(idx) {\n    const ret = getObject(idx);\n    dropObject(idx);\n    return ret;\n}\n\nconst cachedTextDecoder = (typeof TextDecoder !== 'undefined' ? new TextDecoder('utf-8', { ignoreBOM: true, fatal: true }) : { decode: () => { throw Error('TextDecoder not available') } } );\n\nif (typeof TextDecoder !== 'undefined') { cachedTextDecoder.decode(); };\n\nlet cachedUint8Memory0 = null;\n\nfunction getUint8Memory0() {\n    if (cachedUint8Memory0 === null || cachedUint8Memory0.byteLength === 0) {\n        cachedUint8Memory0 = new Uint8Array(wasm.memory.buffer);\n    }\n    return cachedUint8Memory0;\n}\n\nfunction getStringFromWasm0(ptr, len) {\n    ptr = ptr >>> 0;\n    return cachedTextDecoder.decode(getUint8Memory0().subarray(ptr, ptr + len));\n}\n\nfunction addHeapObject(obj) {\n    if (heap_next === heap.length) heap.push(heap.length + 1);\n    const idx = heap_next;\n    heap_next = heap[idx];\n\n    heap[idx] = obj;\n    return idx;\n}\n\nfunction makeMutClosure(arg0, arg1, dtor, f) {\n    const state = { a: arg0, b: arg1, cnt: 1, dtor };\n    const real = (...args) => {\n        // First up with a closure we increment the internal reference\n        // count. This ensures that the Rust closure environment won't\n        // be deallocated while we're invoking it.\n        state.cnt++;\n        const a = state.a;\n        state.a = 0;\n        try {\n            return f(a, state.b, ...args);\n        } finally {\n            if (--state.cnt === 0) {\n                wasm.__wbindgen_export_0.get(state.dtor)(a, state.b);\n\n            } else {\n                state.a = a;\n            }\n        }\n    };\n    real.original = state;\n\n    return real;\n}\nfunction __wbg_adapter_22(arg0, arg1, arg2) {\n    wasm.wasm_bindgen__convert__closures__invoke1_mut__hd17e34166836fd48(arg0, arg1, addHeapObject(arg2));\n}\n\nlet WASM_VECTOR_LEN = 0;\n\nconst cachedTextEncoder = (typeof TextEncoder !== 'undefined' ? new TextEncoder('utf-8') : { encode: () => { throw Error('TextEncoder not available') } } );\n\nconst encodeString = (typeof cachedTextEncoder.encodeInto === 'function'\n    ? function (arg, view) {\n    return cachedTextEncoder.encodeInto(arg, view);\n}\n    : function (arg, view) {\n    const buf = cachedTextEncoder.encode(arg);\n    view.set(buf);\n    return {\n        read: arg.length,\n        written: buf.length\n    };\n});\n\nfunction passStringToWasm0(arg, malloc, realloc) {\n\n    if (realloc === undefined) {\n        const buf = cachedTextEncoder.encode(arg);\n        const ptr = malloc(buf.length, 1) >>> 0;\n        getUint8Memory0().subarray(ptr, ptr + buf.length).set(buf);\n        WASM_VECTOR_LEN = buf.length;\n        return ptr;\n    }\n\n    let len = arg.length;\n    let ptr = malloc(len, 1) >>> 0;\n\n    const mem = getUint8Memory0();\n\n    let offset = 0;\n\n    for (; offset < len; offset++) {\n        const code = arg.charCodeAt(offset);\n        if (code > 0x7F) break;\n        mem[ptr + offset] = code;\n    }\n\n    if (offset !== len) {\n        if (offset !== 0) {\n            arg = arg.slice(offset);\n        }\n        ptr = realloc(ptr, len, len = offset + arg.length * 3, 1) >>> 0;\n        const view = getUint8Memory0().subarray(ptr + offset, ptr + len);\n        const ret = encodeString(arg, view);\n\n        offset += ret.written;\n    }\n\n    WASM_VECTOR_LEN = offset;\n    return ptr;\n}\n\nlet cachedInt32Memory0 = null;\n\nfunction getInt32Memory0() {\n    if (cachedInt32Memory0 === null || cachedInt32Memory0.byteLength === 0) {\n        cachedInt32Memory0 = new Int32Array(wasm.memory.buffer);\n    }\n    return cachedInt32Memory0;\n}\n\nfunction handleError(f, args) {\n    try {\n        return f.apply(this, args);\n    } catch (e) {\n        wasm.__wbindgen_exn_store(addHeapObject(e));\n    }\n}\nfunction __wbg_adapter_76(arg0, arg1, arg2, arg3) {\n    wasm.wasm_bindgen__convert__closures__invoke2_mut__h62fdc46dd4e23c5d(arg0, arg1, addHeapObject(arg2), addHeapObject(arg3));\n}\n\n/**\n*/\nexport class CozoDb {\n\n    static __wrap(ptr) {\n        ptr = ptr >>> 0;\n        const obj = Object.create(CozoDb.prototype);\n        obj.__wbg_ptr = ptr;\n\n        return obj;\n    }\n\n    __destroy_into_raw() {\n        const ptr = this.__wbg_ptr;\n        this.__wbg_ptr = 0;\n\n        return ptr;\n    }\n\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_cozodb_free(ptr);\n    }\n    /**\n    * @returns {CozoDb}\n    */\n    static new() {\n        const ret = wasm.cozodb_new();\n        return CozoDb.__wrap(ret);\n    }\n    /**\n    * Create CozoDb from IndexedDB\n    * @param {string} db_name\n    * @param {string} store_name\n    * @param {any} on_write_callback\n    * @returns {Promise<CozoDb>}\n    */\n    static new_from_indexed_db(db_name, store_name, on_write_callback) {\n        const ptr0 = passStringToWasm0(db_name, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n        const len0 = WASM_VECTOR_LEN;\n        const ptr1 = passStringToWasm0(store_name, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n        const len1 = WASM_VECTOR_LEN;\n        const ret = wasm.cozodb_new_from_indexed_db(ptr0, len0, ptr1, len1, addHeapObject(on_write_callback));\n        return takeObject(ret);\n    }\n    /**\n    * @param {string} script\n    * @param {string} params\n    * @param {boolean} immutable\n    * @returns {Promise<string>}\n    */\n    run(script, params, immutable) {\n        const ptr0 = passStringToWasm0(script, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n        const len0 = WASM_VECTOR_LEN;\n        const ptr1 = passStringToWasm0(params, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n        const len1 = WASM_VECTOR_LEN;\n        const ret = wasm.cozodb_run(this.__wbg_ptr, ptr0, len0, ptr1, len1, immutable);\n        return takeObject(ret);\n    }\n    /**\n    * @param {string} data\n    * @returns {string}\n    */\n    export_relations(data) {\n        let deferred2_0;\n        let deferred2_1;\n        try {\n            const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);\n            const ptr0 = passStringToWasm0(data, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n            const len0 = WASM_VECTOR_LEN;\n            wasm.cozodb_export_relations(retptr, this.__wbg_ptr, ptr0, len0);\n            var r0 = getInt32Memory0()[retptr / 4 + 0];\n            var r1 = getInt32Memory0()[retptr / 4 + 1];\n            deferred2_0 = r0;\n            deferred2_1 = r1;\n            return getStringFromWasm0(r0, r1);\n        } finally {\n            wasm.__wbindgen_add_to_stack_pointer(16);\n            wasm.__wbindgen_free(deferred2_0, deferred2_1, 1);\n        }\n    }\n    /**\n    * @param {string} data\n    * @returns {string}\n    */\n    import_relations(data) {\n        // Normalize common JSON payload shapes so the WASM importer receives\n        // a canonical `{\"relations\": [{ name, headers, rows }]}` shape.\n        let normalized = null;\n        try {\n            const parsed = JSON.parse(data);\n            // Top-level 'memory' -> convert\n            if (parsed && parsed.memory) {\n                const mem = parsed.memory;\n                const headers = mem.headers || (mem.named_rows && mem.named_rows.headers) || null;\n                const rows = mem.rows || (mem.named_rows && mem.named_rows.rows) || [];\n                normalized = { relations: [{ name: 'memory', headers: headers || [], rows }] };\n            }\n            // Already a relations wrapper\n            else if (parsed && parsed.relations && Array.isArray(parsed.relations)) {\n                const rels = parsed.relations.map(r => {\n                    const headers = r.headers || (r.named_rows && r.named_rows.headers) || (r.NamedRows && r.NamedRows.headers) || ['id','timestamp','role','content','source','embedding'];\n                    const rawRows = r.rows || (r.named_rows && r.named_rows.rows) || (r.NamedRows && r.NamedRows.rows) || [];\n                    const rows = rawRows.map(row => {\n                        // Normalize object rows into arrays using headers order\n                        if (row && typeof row === 'object' && !Array.isArray(row)) {\n                            return headers.map(h => (row[h] === undefined ? null : row[h]));\n                        }\n                        // Ensure array rows have proper length and default embedding\n                        const arr = Array.isArray(row) ? row.slice(0, headers.length) : [];\n                        while (arr.length < headers.length) arr.push(null);\n                        const embIdx = headers.indexOf('embedding');\n                        if (embIdx >= 0 && (arr[embIdx] === null || arr[embIdx] === undefined)) arr[embIdx] = [];\n                        return arr;\n                    });\n                    // Provide multiple shapes to satisfy various importer variants\n                    return {\n                        name: r.name || 'memory',\n                        headers,\n                        rows,\n                        named_rows: { headers, rows },\n                        NamedRows: { headers, rows }\n                    };\n                });\n                normalized = { relations: rels };\n            }\n            // Else, could be raw array of records -> convert to rows\n            else if (Array.isArray(parsed)) {\n                const rows = parsed.map(rec => {\n                    const ts = rec.timestamp ? (isNaN(Number(rec.timestamp)) ? new Date(rec.timestamp).getTime() : Number(rec.timestamp)) : Date.now();\n                    return [\n                        `${ts}-${Math.random().toString(36).substr(2,9)}`,\n                        ts,\n                        rec.role || rec.type || 'unknown',\n                        (rec.content || rec.response_content || rec.message || '').substring(0, 20000),\n                        rec.source || 'combined_memory.json',\n                        null\n                    ];\n                });\n                normalized = { relations: [{ name: 'memory', headers: ['id','timestamp','role','content','source','embedding'], rows }] };\n            }\n        } catch (e) {\n            // Not valid JSON or normalization failed; fall back to raw string\n        }\n\n        const payload = normalized ? JSON.stringify(normalized) : data;\n\n        let deferred2_0;\n        let deferred2_1;\n        try {\n            // Debug: show the exact payload being passed into WASM importer (trimmed)\n            try {\n                console.log('CozoDb.import_relations - payload preview (trimmed):', payload.slice(0, 2000));\n                const parsedPreview = JSON.parse(payload);\n                console.log('CozoDb.import_relations - parsed relations preview:', parsedPreview.relations && parsedPreview.relations[0] ? Object.keys(parsedPreview.relations[0]) : null);\n            } catch (pe) {\n                console.warn('CozoDb.import_relations - payload not parseable as JSON preview.');\n            }\n            const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);\n            const ptr0 = passStringToWasm0(payload, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n            const len0 = WASM_VECTOR_LEN;\n            try {\n                wasm.cozodb_import_relations(retptr, this.__wbg_ptr, ptr0, len0);\n            } catch (e) {\n                console.error('CozoDb.import_relations wasm call failed:', e, 'payload_preview:', payload.slice(0,2000));\n                throw e;\n            }\n            var r0 = getInt32Memory0()[retptr / 4 + 0];\n            var r1 = getInt32Memory0()[retptr / 4 + 1];\n            deferred2_0 = r0;\n            deferred2_1 = r1;\n            const resultStr = getStringFromWasm0(r0, r1);\n\n            // If WASM returned a NamedRows header error, try a fallback shaped payload where relation includes NamedRows explicitly.\n            try {\n                const parsedResult = JSON.parse(resultStr);\n                if (parsedResult && parsedResult.ok === false && typeof parsedResult.message === 'string' && parsedResult.message.includes('NamedRows requires')) {\n                    try {\n                        const parsedPayload = JSON.parse(payload);\n                        if (parsedPayload && parsedPayload.relations && Array.isArray(parsedPayload.relations)) {\n                            const fallback = { relations: parsedPayload.relations.map(r => ({ name: r.name || 'memory', NamedRows: { headers: r.headers || (r.named_rows && r.named_rows.headers) || (r.NamedRows && r.NamedRows.headers) || ['id','timestamp','role','content','source','embedding'], rows: r.rows || (r.named_rows && r.named_rows.rows) || (r.NamedRows && r.NamedRows.rows) || [] } })) };\n                            const fallbackStr = JSON.stringify(fallback);\n                            console.log('CozoDb.import_relations - retrying with fallback NamedRows payload (trimmed):', fallbackStr.slice(0,2000));\n                            const ptrF = passStringToWasm0(fallbackStr, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n                            const lenF = WASM_VECTOR_LEN;\n                            wasm.cozodb_import_relations(retptr, this.__wbg_ptr, ptrF, lenF);\n                            var r0b = getInt32Memory0()[retptr / 4 + 0];\n                            var r1b = getInt32Memory0()[retptr / 4 + 1];\n                            // free previous\n                            wasm.__wbindgen_free(deferred2_0, deferred2_1, 1);\n                            deferred2_0 = r0b;\n                            deferred2_1 = r1b;\n                            return getStringFromWasm0(r0b, r1b);\n                        }\n                    } catch (retryErr) {\n                        console.warn('CozoDb.import_relations - fallback retry failed to build payload or call wasm:', retryErr);\n                    }\n                }\n            } catch (e) {\n                // ignore parse errors\n            }\n\n            return resultStr;\n        } finally {\n            wasm.__wbindgen_add_to_stack_pointer(16);\n            wasm.__wbindgen_free(deferred2_0, deferred2_1, 1);\n        }\n    }\n}\n\nasync function __wbg_load(module, imports) {\n    if (typeof Response === 'function' && module instanceof Response) {\n        if (typeof WebAssembly.instantiateStreaming === 'function') {\n            try {\n                return await WebAssembly.instantiateStreaming(module, imports);\n\n            } catch (e) {\n                if (module.headers.get('Content-Type') != 'application/wasm') {\n                    console.warn(\"`WebAssembly.instantiateStreaming` failed because your server does not serve wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\\n\", e);\n\n                } else {\n                    throw e;\n                }\n            }\n        }\n\n        const bytes = await module.arrayBuffer();\n        return await WebAssembly.instantiate(bytes, imports);\n\n    } else {\n        const instance = await WebAssembly.instantiate(module, imports);\n\n        if (instance instanceof WebAssembly.Instance) {\n            return { instance, module };\n\n        } else {\n            return instance;\n        }\n    }\n}\n\nfunction __wbg_get_imports() {\n    const imports = {};\n    imports.wbg = {};\n    imports.wbg.__wbindgen_object_drop_ref = function(arg0) {\n        takeObject(arg0);\n    };\n    imports.wbg.__wbg_log_b78d654f19d681e0 = function(arg0, arg1) {\n        console.log(getStringFromWasm0(arg0, arg1));\n    };\n    imports.wbg.__wbg_loadAllFromIndexedDb_05f8df9a19c8d344 = function(arg0, arg1, arg2, arg3, arg4) {\n        const ret = loadAllFromIndexedDb(getStringFromWasm0(arg0, arg1), getStringFromWasm0(arg2, arg3), getObject(arg4));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_flushPendingWrites_dd4341a0dafcf428 = function() {\n        const ret = flushPendingWrites();\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_string_new = function(arg0, arg1) {\n        const ret = getStringFromWasm0(arg0, arg1);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_cozodb_new = function(arg0) {\n        const ret = CozoDb.__wrap(arg0);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_cb_drop = function(arg0) {\n        const obj = takeObject(arg0).original;\n        if (obj.cnt-- == 1) {\n            obj.a = 0;\n            return true;\n        }\n        const ret = false;\n        return ret;\n    };\n    imports.wbg.__wbg_new_abda76e883ba8a5f = function() {\n        const ret = new Error();\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_stack_658279fe44541cf6 = function(arg0, arg1) {\n        const ret = getObject(arg1).stack;\n        const ptr1 = passStringToWasm0(ret, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);\n        const len1 = WASM_VECTOR_LEN;\n        getInt32Memory0()[arg0 / 4 + 1] = len1;\n        getInt32Memory0()[arg0 / 4 + 0] = ptr1;\n    };\n    imports.wbg.__wbg_error_f851667af71bcfc6 = function(arg0, arg1) {\n        let deferred0_0;\n        let deferred0_1;\n        try {\n            deferred0_0 = arg0;\n            deferred0_1 = arg1;\n            console.error(getStringFromWasm0(arg0, arg1));\n        } finally {\n            wasm.__wbindgen_free(deferred0_0, deferred0_1, 1);\n        }\n    };\n    imports.wbg.__wbg_setWriteCounter_295838a9805b3542 = function(arg0) {\n        setWriteCounter(arg0 >>> 0);\n    };\n    imports.wbg.__wbg_writeToIndexedDb_ec8ba47108ce4d3a = function(arg0, arg1) {\n        const ret = writeToIndexedDb(getObject(arg0), getObject(arg1));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_crypto_c48a774b022d20ac = function(arg0) {\n        const ret = getObject(arg0).crypto;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_is_object = function(arg0) {\n        const val = getObject(arg0);\n        const ret = typeof(val) === 'object' && val !== null;\n        return ret;\n    };\n    imports.wbg.__wbg_process_298734cf255a885d = function(arg0) {\n        const ret = getObject(arg0).process;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_versions_e2e78e134e3e5d01 = function(arg0) {\n        const ret = getObject(arg0).versions;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_node_1cd7a5d853dbea79 = function(arg0) {\n        const ret = getObject(arg0).node;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_is_string = function(arg0) {\n        const ret = typeof(getObject(arg0)) === 'string';\n        return ret;\n    };\n    imports.wbg.__wbg_msCrypto_bcb970640f50a1e8 = function(arg0) {\n        const ret = getObject(arg0).msCrypto;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_require_8f08ceecec0f4fee = function() { return handleError(function () {\n        const ret = module.require;\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbindgen_is_function = function(arg0) {\n        const ret = typeof(getObject(arg0)) === 'function';\n        return ret;\n    };\n    imports.wbg.__wbg_randomFillSync_dc1e9a60c158336d = function() { return handleError(function (arg0, arg1) {\n        getObject(arg0).randomFillSync(takeObject(arg1));\n    }, arguments) };\n    imports.wbg.__wbg_getRandomValues_37fa2ca9e4e07fab = function() { return handleError(function (arg0, arg1) {\n        getObject(arg0).getRandomValues(getObject(arg1));\n    }, arguments) };\n    imports.wbg.__wbg_get_44be0491f933a435 = function(arg0, arg1) {\n        const ret = getObject(arg0)[arg1 >>> 0];\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_length_fff51ee6522a1a18 = function(arg0) {\n        const ret = getObject(arg0).length;\n        return ret;\n    };\n    imports.wbg.__wbg_newnoargs_581967eacc0e2604 = function(arg0, arg1) {\n        const ret = new Function(getStringFromWasm0(arg0, arg1));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_call_cb65541d95d71282 = function() { return handleError(function (arg0, arg1) {\n        const ret = getObject(arg0).call(getObject(arg1));\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbindgen_object_clone_ref = function(arg0) {\n        const ret = getObject(arg0);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_self_1ff1d729e9aae938 = function() { return handleError(function () {\n        const ret = self.self;\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbg_window_5f4faef6c12b79ec = function() { return handleError(function () {\n        const ret = window.window;\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbg_globalThis_1d39714405582d3c = function() { return handleError(function () {\n        const ret = globalThis.globalThis;\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbg_global_651f05c6a0944d1c = function() { return handleError(function () {\n        const ret = global.global;\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbindgen_is_undefined = function(arg0) {\n        const ret = getObject(arg0) === undefined;\n        return ret;\n    };\n    imports.wbg.__wbg_isArray_4c24b343cb13cfb1 = function(arg0) {\n        const ret = Array.isArray(getObject(arg0));\n        return ret;\n    };\n    imports.wbg.__wbg_call_01734de55d61e11d = function() { return handleError(function (arg0, arg1, arg2) {\n        const ret = getObject(arg0).call(getObject(arg1), getObject(arg2));\n        return addHeapObject(ret);\n    }, arguments) };\n    imports.wbg.__wbg_now_9c5990bda04c7e53 = function() {\n        const ret = Date.now();\n        return ret;\n    };\n    imports.wbg.__wbg_new_43f1b47c28813cbd = function(arg0, arg1) {\n        try {\n            var state0 = {a: arg0, b: arg1};\n            var cb0 = (arg0, arg1) => {\n                const a = state0.a;\n                state0.a = 0;\n                try {\n                    return __wbg_adapter_76(a, state0.b, arg0, arg1);\n                } finally {\n                    state0.a = a;\n                }\n            };\n            const ret = new Promise(cb0);\n            return addHeapObject(ret);\n        } finally {\n            state0.a = state0.b = 0;\n        }\n    };\n    imports.wbg.__wbg_resolve_53698b95aaf7fcf8 = function(arg0) {\n        const ret = Promise.resolve(getObject(arg0));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_then_f7e06ee3c11698eb = function(arg0, arg1) {\n        const ret = getObject(arg0).then(getObject(arg1));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_then_b2267541e2a73865 = function(arg0, arg1, arg2) {\n        const ret = getObject(arg0).then(getObject(arg1), getObject(arg2));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_buffer_085ec1f694018c4f = function(arg0) {\n        const ret = getObject(arg0).buffer;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_newwithbyteoffsetandlength_6da8e527659b86aa = function(arg0, arg1, arg2) {\n        const ret = new Uint8Array(getObject(arg0), arg1 >>> 0, arg2 >>> 0);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_new_8125e318e6245eed = function(arg0) {\n        const ret = new Uint8Array(getObject(arg0));\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_set_5cf90238115182c3 = function(arg0, arg1, arg2) {\n        getObject(arg0).set(getObject(arg1), arg2 >>> 0);\n    };\n    imports.wbg.__wbg_length_72e2208bbc0efc61 = function(arg0) {\n        const ret = getObject(arg0).length;\n        return ret;\n    };\n    imports.wbg.__wbg_instanceof_Uint8Array_d8d9cb2b8e8ac1d4 = function(arg0) {\n        let result;\n        try {\n            result = getObject(arg0) instanceof Uint8Array;\n        } catch {\n            result = false;\n        }\n        const ret = result;\n        return ret;\n    };\n    imports.wbg.__wbg_newwithlength_e5d69174d6984cd7 = function(arg0) {\n        const ret = new Uint8Array(arg0 >>> 0);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbg_subarray_13db269f57aa838d = function(arg0, arg1, arg2) {\n        const ret = getObject(arg0).subarray(arg1 >>> 0, arg2 >>> 0);\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_throw = function(arg0, arg1) {\n        throw new Error(getStringFromWasm0(arg0, arg1));\n    };\n    imports.wbg.__wbindgen_memory = function() {\n        const ret = wasm.memory;\n        return addHeapObject(ret);\n    };\n    imports.wbg.__wbindgen_closure_wrapper186 = function(arg0, arg1, arg2) {\n        const ret = makeMutClosure(arg0, arg1, 87, __wbg_adapter_22);\n        return addHeapObject(ret);\n    };\n\n    return imports;\n}\n\nfunction __wbg_init_memory(imports, maybe_memory) {\n\n}\n\nfunction __wbg_finalize_init(instance, module) {\n    wasm = instance.exports;\n    __wbg_init.__wbindgen_wasm_module = module;\n    cachedInt32Memory0 = null;\n    cachedUint8Memory0 = null;\n\n\n    return wasm;\n}\n\nfunction initSync(module) {\n    if (wasm !== undefined) return wasm;\n\n    const imports = __wbg_get_imports();\n\n    __wbg_init_memory(imports);\n\n    if (!(module instanceof WebAssembly.Module)) {\n        module = new WebAssembly.Module(module);\n    }\n\n    const instance = new WebAssembly.Instance(module, imports);\n\n    return __wbg_finalize_init(instance, module);\n}\n\nasync function __wbg_init(input) {\n    if (wasm !== undefined) return wasm;\n\n    if (typeof input === 'undefined') {\n        input = new URL('cyb_cozo_lib_wasm_bg.wasm', import.meta.url);\n    }\n    const imports = __wbg_get_imports();\n\n    if (typeof input === 'string' || (typeof Request === 'function' && input instanceof Request) || (typeof URL === 'function' && input instanceof URL)) {\n        input = fetch(input);\n    }\n\n    __wbg_init_memory(imports);\n\n    const { instance, module } = await __wbg_load(await input, imports);\n\n    return __wbg_finalize_init(instance, module);\n}\n\nexport { initSync }\nexport default __wbg_init;\n",
    "source": "tools\\cozo_lib_wasm.js"
  },
  {
    "id": "tools\\decode_cozo_blob.py",
    "timestamp": 1765895668,
    "role": "file",
    "content": "#!/usr/bin/env python3\r\n\"\"\"Quick decoder for CozoDB blob files to try to recover JSON/relations.\r\n\r\nUsage: python tools\\decode_cozo_blob.py C:\\path\\to\\cozo_blob_0.bin C:\\path\\to\\cozo_blob_1.bin\r\n\r\nIt attempts: UTF-8 decode, zlib.inflate, gzip, zstd (if installed), base64 decode, and searches for JSON-like markers.\r\n\"\"\"\r\nimport sys\r\nimport json\r\nimport zlib\r\nimport gzip\r\nimport base64\r\nimport bz2\r\nimport lzma\r\nfrom pathlib import Path\r\n\r\n# Optional compressors\r\ntry:\r\n    import zstandard as zstd\r\nexcept Exception:\r\n    zstd = None\r\n\r\ntry:\r\n    import brotli\r\nexcept Exception:\r\n    brotli = None\r\n\r\ntry:\r\n    import lz4.frame as lz4frame\r\nexcept Exception:\r\n    lz4frame = None\r\n\r\n\r\ndef hexdump(b, length=64):\r\n    return ' '.join(f\"{x:02x}\" for x in b[:length])\r\n\r\n\r\ndef try_utf8(b):\r\n    try:\r\n        s = b.decode('utf-8', errors='replace')\r\n        return s\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_zlib(b):\r\n    try:\r\n        return zlib.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_gzip(b):\r\n    try:\r\n        return gzip.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_base64(b):\r\n    try:\r\n        s = b.decode('ascii', errors='ignore').strip()\r\n        s2 = ''.join(s.split())\r\n        dec = base64.b64decode(s2)\r\n        return dec\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_bz2(b):\r\n    try:\r\n        return bz2.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_lzma(b):\r\n    try:\r\n        return lzma.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_brotli(b):\r\n    if not brotli:\r\n        return None\r\n    try:\r\n        return brotli.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_lz4(b):\r\n    if not lz4frame:\r\n        return None\r\n    try:\r\n        return lz4frame.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef try_zstd(b):\r\n    if not zstd:\r\n        return None\r\n    try:\r\n        dctx = zstd.ZstdDecompressor()\r\n        return dctx.decompress(b)\r\n    except Exception:\r\n        return None\r\n\r\n\r\ndef find_json_in_bytes(b):\r\n    try:\r\n        txt = b.decode('utf-8', errors='ignore')\r\n    except Exception:\r\n        txt = None\r\n    if not txt:\r\n        return None\r\n    idx = txt.find('{')\r\n    if idx >= 0:\r\n        # Try progressive parse\r\n        for end in range(idx+100, min(len(txt), idx+20000), 100):\r\n            try:\r\n                candidate = txt[idx:end]\r\n                parsed = json.loads(candidate)\r\n                return parsed\r\n            except Exception:\r\n                continue\r\n    if 'relations' in txt or 'memory' in txt or 'NamedRows' in txt:\r\n        return txt\r\n    return None\r\n\r\n\r\ndef analyze(path: Path):\r\n    print(f\"\\n=== Analyzing: {path} ===\")\r\n    b = path.read_bytes()\r\n    print(f\"Size: {len(b)} bytes\")\r\n    print(\"Hex (first 64 bytes):\", hexdump(b, 64))\r\n\r\n    s = try_utf8(b)\r\n    if s and ('{' in s or 'relations' in s or 'memory' in s or 'NamedRows' in s):\r\n        print(\"\\n-- UTF-8 text looks promising (preview):\\n\")\r\n        print(s[:2000])\r\n        return\r\n\r\n    z = try_zlib(b)\r\n    if z:\r\n        print(\"\\n-- zlib decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = z.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(z[:200]))\r\n        return\r\n\r\n    g = try_gzip(b)\r\n    if g:\r\n        print(\"\\n-- gzip decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = g.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(g[:200]))\r\n        return\r\n\r\n    zd = try_zstd(b)\r\n    if zd:\r\n        print(\"\\n-- zstd decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = zd.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(zd[:200]))\r\n        return\r\n\r\n    bz = try_bz2(b)\r\n    if bz:\r\n        print(\"\\n-- bz2 decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = bz.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(bz[:200]))\r\n        return\r\n\r\n    lz = try_lzma(b)\r\n    if lz:\r\n        print(\"\\n-- lzma decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = lz.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(lz[:200]))\r\n        return\r\n\r\n    br = try_brotli(b)\r\n    if br:\r\n        print(\"\\n-- brotli decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = br.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(br[:200]))\r\n        return\r\n\r\n    l4 = try_lz4(b)\r\n    if l4:\r\n        print(\"\\n-- lz4 decompressed (first 2000 chars):\\n\")\r\n        try:\r\n            txt = l4.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(l4[:200]))\r\n        return\r\n\r\n    bb = try_base64(b)\r\n    if bb:\r\n        print(\"\\n-- base64 decoded (preview):\\n\")\r\n        try:\r\n            txt = bb.decode('utf-8', errors='ignore')\r\n            print(txt[:2000])\r\n        except Exception:\r\n            print(repr(bb[:200]))\r\n        return\r\n\r\n    found = find_json_in_bytes(b)\r\n    if found:\r\n        print(\"\\n-- Found JSON-like content:\\n\")\r\n        if isinstance(found, str):\r\n            print(found[:2000])\r\n        else:\r\n            print(json.dumps(found, indent=2)[:4000])\r\n        return\r\n\r\n    out = path.with_suffix(path.suffix + '.raw')\r\n    out.write_bytes(b)\r\n    print(f\"\\nNo decode succeeded. Wrote raw blob to {out}\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    if len(sys.argv) < 2:\r\n        print('Usage: python tools\\\\decode_cozo_blob.py C:\\\\path\\\\to\\\\blob1 [blob2 ...]')\r\n        sys.exit(1)\r\n    for p in sys.argv[1:]:\r\n        analyze(Path(p))",
    "source": "tools\\decode_cozo_blob.py"
  },
  {
    "id": "tools\\eyes.py",
    "timestamp": 1765659368,
    "role": "file",
    "content": "import argparse\r\nimport requests\r\nimport sys\r\nimport os\r\n\r\ndef ingest(content, source_type=\"text\", adapter=\"eyes-cli\"):\r\n    url = \"http://localhost:8000/archivist/ingest\"\r\n    headers = {\r\n        \"Content-Type\": \"application/json\",\r\n        \"X-API-Key\": \"ece-secret-key\" \r\n    }\r\n    payload = {\r\n        \"content\": content,\r\n        \"type\": source_type,\r\n        \"adapter\": adapter\r\n    }\r\n    \r\n    print(f\"Sending to {url}...\")\r\n    try:\r\n        response = requests.post(url, json=payload, headers=headers)\r\n        response.raise_for_status()\r\n        print(f\"âœ… Success: {response.json()}\")\r\n    except requests.exceptions.RequestException as e:\r\n        print(f\"âŒ Error: {e}\")\r\n        if hasattr(e, 'response') and e.response is not None:\r\n            print(f\"Details: {e.response.text}\")\r\n        sys.exit(1)\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser(description=\"Sovereign Eyes - Ingest content into ECE Memory\")\r\n    parser.add_argument(\"input\", help=\"File path or text content to ingest\")\r\n    parser.add_argument(\"--type\", default=\"text\", help=\"Source type (text, web_page, etc.)\")\r\n    parser.add_argument(\"--adapter\", default=\"eyes-cli\", help=\"Adapter name\")\r\n    \r\n    args = parser.parse_args()\r\n    \r\n    content = args.input\r\n    \r\n    # Check if input is a file\r\n    if os.path.exists(args.input):\r\n        try:\r\n            with open(args.input, 'r', encoding='utf-8') as f:\r\n                content = f.read()\r\n            print(f\"ðŸ“– Read content from file: {args.input}\")\r\n        except Exception as e:\r\n            print(f\"âš ï¸ Could not read file '{args.input}', treating as raw text.\")\r\n            \r\n    ingest(content, args.type, args.adapter)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n",
    "source": "tools\\eyes.py"
  },
  {
    "id": "tools\\index.html",
    "timestamp": 1766386706,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>Sovereign Console | Launcher</title>\r\n    <style>\r\n        :root {\r\n            --bg-color: #1a1a1a;\r\n            --card-bg: #2d2d2d;\r\n            --accent: #0078d4;\r\n            --text: #ffffff;\r\n            --secondary-text: #aaaaaa;\r\n        }\r\n\r\n        body {\r\n            font-family: 'Segoe UI', system-ui, sans-serif;\r\n            background-color: var(--bg-color);\r\n            color: var(--text);\r\n            margin: 0;\r\n            display: flex;\r\n            flex-direction: column;\r\n            align-items: center;\r\n            justify-content: center;\r\n            height: 100vh;\r\n        }\r\n\r\n        h1 {\r\n            font-weight: 300;\r\n            margin-bottom: 40px;\r\n            letter-spacing: 2px;\r\n        }\r\n\r\n        .grid {\r\n            display: grid;\r\n            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\r\n            gap: 20px;\r\n            width: 100%;\r\n            max-width: 900px;\r\n            padding: 20px;\r\n        }\r\n\r\n        .card {\r\n            background-color: var(--card-bg);\r\n            border-radius: 12px;\r\n            padding: 30px;\r\n            text-decoration: none;\r\n            color: var(--text);\r\n            transition: transform 0.2s, box-shadow 0.2s;\r\n            border: 1px solid #333;\r\n            display: flex;\r\n            flex-direction: column;\r\n            align-items: center;\r\n            text-align: center;\r\n        }\r\n\r\n        .card:hover {\r\n            transform: translateY(-5px);\r\n            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.4);\r\n            border-color: var(--accent);\r\n        }\r\n\r\n        .icon {\r\n            font-size: 48px;\r\n            margin-bottom: 20px;\r\n        }\r\n\r\n        .title {\r\n            font-size: 1.25rem;\r\n            font-weight: 600;\r\n            margin-bottom: 10px;\r\n        }\r\n\r\n        .desc {\r\n            font-size: 0.9rem;\r\n            color: var(--secondary-text);\r\n        }\r\n\r\n        .status {\r\n            margin-top: 15px;\r\n            font-size: 0.8rem;\r\n            padding: 4px 8px;\r\n            border-radius: 4px;\r\n            background: #333;\r\n            color: #888;\r\n        }\r\n\r\n        .card:hover .status {\r\n            background: rgba(0, 120, 212, 0.2);\r\n            color: var(--accent);\r\n        }\r\n    </style>\r\n</head>\r\n\r\n<body>\r\n\r\n    <h1>SOVEREIGN <span style=\"color:var(--accent); font-weight:600;\">CONSOLE</span></h1>\r\n\r\n    <div class=\"grid\">\r\n        <a href=\"model-server-chat.html\" class=\"card\">\r\n            <div class=\"icon\">ðŸ’¬</div>\r\n            <div class=\"title\">Sovereign Chat</div>\r\n            <div class=\"desc\">The core WebGPU interface. Run LLMs locally with memory integration.</div>\r\n            <div class=\"status\">Active</div>\r\n        </a>\r\n\r\n        <a href=\"log-viewer.html\" class=\"card\">\r\n            <div class=\"icon\">ðŸ“Š</div>\r\n            <div class=\"title\">Log Viewer</div>\r\n            <div class=\"desc\">Monitor engine performance, VRAM usage, and debug events.</div>\r\n            <div class=\"status\">Utility</div>\r\n        </a>\r\n\r\n        <a href=\"sovereign-db-builder.html\" class=\"card\">\r\n            <div class=\"icon\">ðŸ§ </div>\r\n            <div class=\"title\">Memory Builder</div>\r\n            <div class=\"desc\">Manage and build the CozoDB memory store.</div>\r\n            <div class=\"status\">Admin</div>\r\n        </a>\r\n\r\n        <a href=\"root-mic.html\" class=\"card\">\r\n            <div class=\"icon\">ðŸŽ™ï¸</div>\r\n            <div class=\"title\">Root Mic</div>\r\n            <div class=\"desc\">Dictate directly to the engine using Whisper.</div>\r\n            <div class=\"status\">Input</div>\r\n        </a>\r\n\r\n        <a href=\"root-dreamer.html\" class=\"card\">\r\n            <div class=\"icon\">ðŸŒ™</div>\r\n            <div class=\"title\">Root Dreamer</div>\r\n            <div class=\"desc\">The synthetic subconscious. Background memory consolidation and association.</div>\r\n            <div class=\"status\">Subconscious</div>\r\n        </a>\r\n    </div>\r\n\r\n    <div style=\"margin-top: 50px; color: #555; font-size: 0.8rem;\">\r\n        Running on Localhost â€¢ WebGPU Enabled\r\n    </div>\r\n\r\n</body>\r\n\r\n</html>",
    "source": "tools\\index.html"
  },
  {
    "id": "tools\\indexeddb.js",
    "timestamp": 1766026191,
    "role": "file",
    "content": "let db = null;\nlet cozoDbStore = null;\nlet writeCounter = 0;\nlet writeCallback = null;\n\nlet cmdFlag = false;\n\nexport function setWriteCounter(count) {\n  writeCounter = count;\n}\n\nfunction storeRequestToPromise(req) {\n  return new Promise((resolve, reject) => {\n    req.onsuccess = () => resolve(req.result);\n    req.onerror = (e) => reject(e.error);\n  });\n}\n\nasync function openDatabase(dbName, storeName) {\n  cozoDbStore = storeName;\n\n  return new Promise((resolve, reject) => {\n    const request = indexedDB.open(dbName, 1);\n    request.onupgradeneeded = function (event) {\n      const db = event.target.result;\n      if (!db.objectStoreNames.contains(storeName)) {\n        db.createObjectStore(storeName);\n      }\n    };\n\n    request.onsuccess = function (event) {\n      db = event.target.result;\n      resolve(db);\n    };\n    request.onerror = function (event) {\n      reject(event.error);\n    };\n  });\n}\n\nasync function readStore() {\n  return new Promise((resolve, reject) => {\n    const transaction = db.transaction(cozoDbStore, \"readonly\");\n    const store = transaction.objectStore(cozoDbStore);\n\n    const itemsPromise = storeRequestToPromise(store.getAll());\n    const keysPromise = storeRequestToPromise(store.getAllKeys());\n\n    Promise.all([keysPromise, itemsPromise])\n      .then((results) => {\n        const keys = results[0].map((item) => new Uint8Array(item));\n        const items = results[1];\n        resolve([keys, items]);\n      })\n      .catch(reject);\n  });\n}\n\nexport async function flushPendingWrites(timeoutDuration = 60000) {\n  let timeout = null;\n\n  // allow only one command runnig at a time\n  if (cmdFlag) {\n    await new Promise((resolve, reject) => {\n      const interval = setInterval(() => {\n        if (!cmdFlag) {\n          clearInterval(interval);\n          resolve();\n        }\n      }, 10);\n    });\n  }\n\n  cmdFlag = true;\n\n  const waitPromise = new Promise((resolve, reject) => {\n    const interval = setInterval(() => {\n      if (writeCounter <= 0) {\n        if (timeout) {\n          clearTimeout(timeout);\n        }\n        clearInterval(interval);\n        resolve();\n      }\n    }, 10);\n  });\n\n  const timeoutPromise = new Promise((_, reject) => {\n    timeout = setTimeout(() => {\n      reject(new Error(\"waitForPendingWrites timed out!\"));\n    }, timeoutDuration);\n  });\n\n  // wait until all pending writes are done\n  return Promise.race([waitPromise, timeoutPromise]).finally(() => {\n    cmdFlag = false;\n  });\n}\n\nexport async function loadAllFromIndexedDb(dbName, storeName, onWriteCallback) {\n  writeCallback = onWriteCallback;\n  await openDatabase(dbName, storeName);\n  return await readStore();\n}\n\nexport async function writeToIndexedDb(key, value) {\n  return new Promise((resolve, reject) => {\n    const transaction = db.transaction(cozoDbStore, \"readwrite\");\n    const store = transaction.objectStore(cozoDbStore);\n    const request = value ? store.put(value, key) : store.delete(key);\n    return storeRequestToPromise(request)\n      .then(resolve)\n      .catch(reject)\n      .finally(() => {\n        writeCounter--;\n        writeCallback && writeCallback(writeCounter);\n      });\n  });\n}\n\nexport function closeDatabase() {\n  if (db) {\n    db.close();\n    db = null;\n  }\n}\n\nexport async function clearIndexedDbStore(dbName, storeName) {\n  // Ensure we open a connection first if one isn't open\n  if (!db) {\n    await openDatabase(dbName, storeName);\n  }\n  return new Promise((resolve, reject) => {\n    const transaction = db.transaction(storeName, \"readwrite\");\n    const store = transaction.objectStore(storeName);\n    const request = store.clear();\n\n    request.onsuccess = () => resolve();\n    request.onerror = (e) => reject(e.target.error);\n  });\n}\n",
    "source": "tools\\indexeddb.js"
  },
  {
    "id": "tools\\log-viewer.html",
    "timestamp": 1766214451,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <title>Sovereign System Debugger</title>\r\n    <style>\r\n        body {\r\n            background-color: #000;\r\n            color: #0f0;\r\n            font-family: 'Consolas', 'Monaco', monospace;\r\n            margin: 0;\r\n            display: flex;\r\n            flex-direction: column;\r\n            height: 100vh;\r\n            overflow: hidden;\r\n        }\r\n\r\n        #toolbar {\r\n            background-color: #111;\r\n            padding: 10px;\r\n            border-bottom: 1px solid #333;\r\n            display: flex;\r\n            gap: 10px;\r\n            align-items: center;\r\n        }\r\n\r\n        button {\r\n            background: #333;\r\n            color: #fff;\r\n            border: 1px solid #444;\r\n            cursor: pointer;\r\n            padding: 5px 10px;\r\n        }\r\n\r\n        button:hover {\r\n            background: #444;\r\n        }\r\n\r\n        #main-container {\r\n            display: flex;\r\n            flex: 1;\r\n            overflow: hidden;\r\n        }\r\n\r\n        .panel {\r\n            flex: 1;\r\n            display: flex;\r\n            flex-direction: column;\r\n            border-right: 1px solid #333;\r\n            min-width: 0;\r\n        }\r\n\r\n        .panel:last-child {\r\n            border-right: none;\r\n        }\r\n\r\n        .panel-header {\r\n            background: #1a1a1a;\r\n            padding: 5px 10px;\r\n            font-weight: bold;\r\n            border-bottom: 1px solid #333;\r\n            display: flex;\r\n            justify-content: space-between;\r\n        }\r\n\r\n        .log-container {\r\n            flex: 1;\r\n            overflow-y: auto;\r\n            padding: 10px;\r\n            white-space: pre-wrap;\r\n            font-size: 12px;\r\n        }\r\n\r\n        .log-line {\r\n            padding: 2px 0;\r\n            border-bottom: 1px solid #111;\r\n            word-break: break-all;\r\n        }\r\n\r\n        .log-line:hover {\r\n            background-color: #111;\r\n        }\r\n\r\n        .info {\r\n            color: #88ccff;\r\n        }\r\n\r\n        .warning {\r\n            color: #ffcc00;\r\n        }\r\n\r\n        .error {\r\n            color: #ff4444;\r\n            font-weight: bold;\r\n        }\r\n\r\n        .debug {\r\n            color: #888;\r\n        }\r\n\r\n        .success {\r\n            color: #00ff00;\r\n        }\r\n\r\n        /* Context specific styles */\r\n        .context-block {\r\n            border: 1px solid #333;\r\n            margin-bottom: 10px;\r\n            padding: 5px;\r\n            background: #050505;\r\n            font-size: 11px;\r\n        }\r\n\r\n        .context-header {\r\n            color: #aaa;\r\n            border-bottom: 1px solid #333;\r\n            margin-bottom: 5px;\r\n            font-weight: bold;\r\n        }\r\n    </style>\r\n</head>\r\n\r\n<body>\r\n    <div id=\"toolbar\">\r\n        <span style=\"color: #88ccff; font-weight: bold;\">Sovereign Broadcast Receiver</span>\r\n        <span id=\"connection-status\" style=\"color: #888; margin-left: 10px;\">â— Listening...</span>\r\n        <div style=\"flex: 1;\"></div>\r\n        <button id=\"copy-all-btn\" title=\"Copy all logs to clipboard\">ðŸ“‹ Copy All</button>\r\n        <button id=\"retry-logs-btn\" title=\"Retry fetching backend logs\">Retry Backend Logs</button>\r\n        <button id=\"clear-btn\">Clear All</button>\r\n    </div>\r\n\r\n    <div id=\"main-container\">\r\n        <!-- Panel 1: System Logs -->\r\n        <div class=\"panel\">\r\n            <div class=\"panel-header\">\r\n                <span>System Logs</span>\r\n            </div>\r\n            <div id=\"system-logs\" class=\"log-container\"></div>\r\n        </div>\r\n\r\n        <!-- Panel 2: Chat Stream -->\r\n        <div class=\"panel\">\r\n            <div class=\"panel-header\">\r\n                <span>Chat Stream</span>\r\n            </div>\r\n            <div id=\"chat-logs\" class=\"log-container\"></div>\r\n        </div>\r\n\r\n        <!-- Panel 3: Context Inspector -->\r\n        <div class=\"panel\">\r\n            <div class=\"panel-header\">\r\n                <span>Context / Memory</span>\r\n            </div>\r\n            <div id=\"context-view\" class=\"log-container\"></div>\r\n        </div>\r\n    </div>\r\n\r\n    <script>\r\n        const systemContainer = document.getElementById('system-logs');\r\n        const chatContainer = document.getElementById('chat-logs');\r\n        const contextContainer = document.getElementById('context-view');\r\n        const clearBtn = document.getElementById('clear-btn');\r\n        const copyBtn = document.getElementById('copy-all-btn');\r\n        const statusIndicator = document.getElementById('connection-status');\r\n\r\n        copyBtn.onclick = () => {\r\n            const allText = [\r\n                \"--- SYSTEM LOGS ---\", systemContainer.innerText,\r\n                \"\\n--- CHAT LOGS ---\", chatContainer.innerText,\r\n                \"\\n--- CONTEXT LOGS ---\", contextContainer.innerText\r\n            ].join(\"\\n\");\r\n\r\n            navigator.clipboard.writeText(allText).then(() => {\r\n                const original = copyBtn.innerHTML;\r\n                copyBtn.innerHTML = \"âœ… Copied!\";\r\n                setTimeout(() => copyBtn.innerHTML = original, 2000);\r\n            }).catch(e => alert(\"Copy failed: \" + e));\r\n        };\r\n\r\n        const logChannel = new BroadcastChannel('sovereign-logs');\r\n        const codaChannel = new BroadcastChannel('coda_logs');\r\n        // Simple de-duplication for server polling\r\n        const serverLogSet = new Set();\r\n\r\n        function markActive() {\r\n            statusIndicator.style.color = '#0f0';\r\n            statusIndicator.innerText = 'â— Active';\r\n            setTimeout(() => {\r\n                statusIndicator.style.color = '#888';\r\n                statusIndicator.innerText = 'â— Listening...';\r\n            }, 2000);\r\n        }\r\n\r\n        logChannel.onmessage = (event) => {\r\n            markActive();\r\n            const data = event.data;\r\n\r\n            if (data.source === 'system') {\r\n                appendLog(systemContainer, `[${data.time}] [${data.type}] ${data.msg}`, data.type);\r\n            } else if (data.source === 'chat') {\r\n                appendLog(chatContainer, `[${data.time}] ${data.role}: ${data.text}`, 'info');\r\n                if (data.context) {\r\n                    appendContext(data.context);\r\n                }\r\n            }\r\n        };\r\n\r\n        // Mission Control channel (coda_logs) - short JSON messages\r\n        codaChannel.onmessage = (event) => {\r\n            markActive();\r\n            const data = event.data;\r\n            try {\r\n                // Known sources: 'Sovereign-Console' | 'Sovereign-Chat' | 'Sovereign-DB' | 'Sovereign-Embed'\r\n                if (data.source === 'Sovereign-Console') {\r\n                    appendLog(systemContainer, `[${new Date().toLocaleTimeString()}] [SOVEREIGN] ${data.message}`, data.type || 'info');\r\n                } else if (data.source === 'Sovereign-Chat') {\r\n                    appendLog(chatContainer, `[${new Date().toLocaleTimeString()}] ${data.role || 'assistant'}: ${data.message}`, 'info');\r\n                    if (data.context) appendContext(data.context);\r\n                } else if (data.source === 'Sovereign-DB') {\r\n                    appendLog(systemContainer, `[${new Date().toLocaleTimeString()}] [DB] ${data.message}`, data.type || 'info');\r\n                } else if (data.source === 'Sovereign-Embed' || data.source === 'WebGPU-Embed') {\r\n                    appendLog(systemContainer, `[${new Date().toLocaleTimeString()}] [EMBED] ${data.message}`, 'debug');\r\n                } else if (data.source === 'WebGPU-Chat') {\r\n                    appendLog(chatContainer, `[${new Date().toLocaleTimeString()}] ${data.role || 'assistant'}: ${data.message}`, 'info');\r\n                } else {\r\n                    appendLog(systemContainer, `[${new Date().toLocaleTimeString()}] ${JSON.stringify(data)}`, 'debug');\r\n                }\r\n            } catch (e) {\r\n                appendLog(systemContainer, `[coda_logs parsing error] ${e.message}`, 'error');\r\n            }\r\n        };\r\n\r\n        // Poll backend server logs every 2s with graceful 404 handling and retry\r\n        let pollIntervalId = null;\r\n        let serverLogsErrorShown = false;\r\n\r\n        async function pollServerLogs() {\r\n            try {\r\n                // Use relative path so it targets same origin when proxied; fall back to explicit host if needed\r\n                const resp = await fetch('http://localhost:8080/audit/server-logs?limit=50');\r\n\r\n                if (resp.status === 404) {\r\n                    if (!serverLogsErrorShown) {\r\n                        appendLog(systemContainer, `[ECE-Core] Backend logs endpoint returned 404. Is the backend running?`, 'warning');\r\n                        statusIndicator.style.color = '#ffcc00';\r\n                        statusIndicator.innerText = 'â— Backend logs unavailable';\r\n                        serverLogsErrorShown = true;\r\n                    }\r\n                    // Stop polling to avoid tight 404 loops\r\n                    if (pollIntervalId) {\r\n                        clearInterval(pollIntervalId);\r\n                        pollIntervalId = null;\r\n                    }\r\n                    return;\r\n                }\r\n\r\n                if (!resp.ok) {\r\n                    appendLog(systemContainer, `[ECE-Core] Poll error: HTTP ${resp.status}`, 'error');\r\n                    return;\r\n                }\r\n\r\n                const payload = await resp.json();\r\n                if (payload && Array.isArray(payload.logs)) {\r\n                    for (const line of payload.logs) {\r\n                        if (!serverLogSet.has(line)) {\r\n                            serverLogSet.add(line);\r\n                            appendLog(systemContainer, `[ECE-Core] ${line}`, 'success');\r\n                        }\r\n                    }\r\n                    // Prevent unbounded growth\r\n                    if (serverLogSet.size > 500) {\r\n                        serverLogSet.clear();\r\n                    }\r\n                }\r\n            } catch (e) {\r\n                if (!serverLogsErrorShown) {\r\n                    appendLog(systemContainer, `[ECE-Core] Poll error: ${e.message}`, 'error');\r\n                    statusIndicator.style.color = '#ff4444';\r\n                    statusIndicator.innerText = 'â— Poll error';\r\n                    serverLogsErrorShown = true;\r\n                }\r\n            }\r\n        }\r\n\r\n        function startPolling() {\r\n            if (pollIntervalId) return;\r\n            serverLogsErrorShown = false;\r\n            statusIndicator.style.color = '#0f0';\r\n            statusIndicator.innerText = 'â— Active';\r\n            pollIntervalId = setInterval(pollServerLogs, 2000);\r\n            pollServerLogs();\r\n        }\r\n\r\n        function stopPolling() {\r\n            if (pollIntervalId) {\r\n                clearInterval(pollIntervalId);\r\n                pollIntervalId = null;\r\n            }\r\n        }\r\n\r\n        // Start polling initially\r\n        startPolling();\r\n\r\n        // Retry button\r\n        document.getElementById('retry-logs-btn').addEventListener('click', () => {\r\n            appendLog(systemContainer, '[ECE-Core] Manual retry requested', 'info');\r\n            statusIndicator.style.color = '#88ccff';\r\n            statusIndicator.innerText = 'â— Retrying...';\r\n            startPolling();\r\n        });\r\n\r\n        function appendLog(container, text, type) {\r\n            const div = document.createElement('div');\r\n            div.className = 'log-line';\r\n            div.innerHTML = colorize(text, type);\r\n            container.appendChild(div);\r\n            container.scrollTop = container.scrollHeight;\r\n        }\r\n\r\n        function appendContext(contextData) {\r\n            const div = document.createElement('div');\r\n            div.className = 'context-block';\r\n            div.innerHTML = `<div class=\"context-header\">Context Update</div><pre>${JSON.stringify(contextData, null, 2)}</pre>`;\r\n            contextContainer.appendChild(div);\r\n            contextContainer.scrollTop = contextContainer.scrollHeight;\r\n        }\r\n\r\n        function colorize(line, type) {\r\n            if (type === 'error' || line.includes('ERROR') || line.includes('âŒ')) return `<span class=\"error\">${line}</span>`;\r\n            if (type === 'warn' || line.includes('WARNING')) return `<span class=\"warning\">${line}</span>`;\r\n            if (type === 'success' || line.includes('SUCCESS') || line.includes('âœ…')) return `<span class=\"success\">${line}</span>`;\r\n            if (type === 'info' || line.includes('INFO')) return `<span class=\"info\">${line}</span>`;\r\n            return `<span class=\"debug\">${line}</span>`;\r\n        }\r\n\r\n        clearBtn.onclick = () => {\r\n            systemContainer.innerHTML = '';\r\n            chatContainer.innerHTML = '';\r\n            contextContainer.innerHTML = '';\r\n        };\r\n    </script>\r\n</body>\r\n\r\n</html>",
    "source": "tools\\log-viewer.html"
  },
  {
    "id": "tools\\mobile-chat.html",
    "timestamp": 1766240107,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\">\r\n    <title>Sovereign Coda Mobile</title>\r\n    <style>\r\n        :root {\r\n            --bg: #0f1115;\r\n            --surface: #1a1d23;\r\n            --primary: #3b82f6;\r\n            --text: #e2e8f0;\r\n            --text-dim: #94a3b8;\r\n        }\r\n\r\n        body {\r\n            margin: 0;\r\n            background: var(--bg);\r\n            color: var(--text);\r\n            font-family: -apple-system, system-ui, sans-serif;\r\n            display: flex;\r\n            flex-direction: column;\r\n            height: 100vh;\r\n            overflow: hidden;\r\n        }\r\n\r\n        /* Login Modal */\r\n        #auth-overlay {\r\n            position: fixed;\r\n            top: 0;\r\n            left: 0;\r\n            right: 0;\r\n            bottom: 0;\r\n            background: var(--bg);\r\n            display: flex;\r\n            align-items: center;\r\n            justify-content: center;\r\n            z-index: 1000;\r\n        }\r\n\r\n        .card {\r\n            background: var(--surface);\r\n            padding: 2rem;\r\n            border-radius: 12px;\r\n            width: 90%;\r\n            max-width: 320px;\r\n            text-align: center;\r\n            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);\r\n        }\r\n\r\n        input {\r\n            width: 100%;\r\n            padding: 12px;\r\n            margin: 10px 0;\r\n            border-radius: 8px;\r\n            border: 1px solid #333;\r\n            background: #000;\r\n            color: white;\r\n            font-size: 16px;\r\n            box-sizing: border-box;\r\n            /* Fix padding expanding width */\r\n        }\r\n\r\n        button {\r\n            width: 100%;\r\n            padding: 12px;\r\n            border-radius: 8px;\r\n            border: none;\r\n            background: var(--primary);\r\n            color: white;\r\n            font-weight: bold;\r\n            font-size: 16px;\r\n            cursor: pointer;\r\n        }\r\n\r\n        button:active {\r\n            opacity: 0.8;\r\n            transform: scale(0.98);\r\n        }\r\n\r\n        /* Chat UI */\r\n        header {\r\n            padding: 15px;\r\n            background: var(--surface);\r\n            border-bottom: 1px solid #333;\r\n            display: flex;\r\n            justify-content: space-between;\r\n            align-items: center;\r\n        }\r\n\r\n        #chat-box {\r\n            flex: 1;\r\n            overflow-y: auto;\r\n            padding: 15px;\r\n            display: flex;\r\n            flex-direction: column;\r\n            gap: 12px;\r\n        }\r\n\r\n        .msg {\r\n            max-width: 85%;\r\n            padding: 10px 14px;\r\n            border-radius: 16px;\r\n            line-height: 1.4;\r\n            word-wrap: break-word;\r\n        }\r\n\r\n        .user {\r\n            align-self: flex-end;\r\n            background: var(--primary);\r\n            color: white;\r\n            border-bottom-right-radius: 4px;\r\n        }\r\n\r\n        .assistant {\r\n            align-self: flex-start;\r\n            background: var(--surface);\r\n            color: var(--text);\r\n            border-bottom-left-radius: 4px;\r\n        }\r\n\r\n        .system {\r\n            align-self: center;\r\n            font-size: 0.8rem;\r\n            color: var(--text-dim);\r\n            background: transparent;\r\n        }\r\n\r\n        #input-area {\r\n            padding: 10px;\r\n            background: var(--surface);\r\n            display: flex;\r\n            gap: 10px;\r\n        }\r\n    </style>\r\n</head>\r\n\r\n<body>\r\n\r\n    <!-- Auth Modal -->\r\n    <div id=\"auth-overlay\">\r\n        <div class=\"card\">\r\n            <h2>ðŸ”’ Secure Access</h2>\r\n            <p style=\"color:var(--text-dim); margin-bottom:20px\">Enter the bridge token from your PC console.</p>\r\n            <input type=\"password\" id=\"token-input\" placeholder=\"Paste Token Here\">\r\n            <button onclick=\"saveToken()\">Connect</button>\r\n        </div>\r\n    </div>\r\n\r\n    <!-- Main Chat -->\r\n    <header>\r\n        <span style=\"font-weight:bold\">Sovereign Coda</span>\r\n        <button onclick=\"logout()\" style=\"width:auto; padding:5px 10px; font-size:12px; background:#333\">Logout</button>\r\n    </header>\r\n\r\n    <div id=\"chat-box\"></div>\r\n\r\n    <div id=\"input-area\">\r\n        <input type=\"text\" id=\"msg-input\" placeholder=\"Message...\" onkeypress=\"handleKey(event)\" autocomplete=\"off\">\r\n        <button onclick=\"send()\" style=\"width:60px\">âž¤</button>\r\n    </div>\r\n\r\n    <script>\r\n        let TOKEN = localStorage.getItem('bridge_token');\r\n        const DOM = {\r\n            auth: document.getElementById('auth-overlay'),\r\n            input: document.getElementById('msg-input'),\r\n            box: document.getElementById('chat-box')\r\n        };\r\n\r\n        if (TOKEN) {\r\n            DOM.auth.style.display = 'none';\r\n        }\r\n\r\n        function saveToken() {\r\n            const val = document.getElementById('token-input').value.trim();\r\n            if (val) {\r\n                localStorage.setItem('bridge_token', val);\r\n                TOKEN = val;\r\n                DOM.auth.style.display = 'none';\r\n            }\r\n        }\r\n\r\n        function logout() {\r\n            localStorage.removeItem('bridge_token');\r\n            location.reload();\r\n        }\r\n\r\n        function append(role, text) {\r\n            const div = document.createElement('div');\r\n            div.className = `msg ${role}`;\r\n            div.innerText = text;\r\n            DOM.box.appendChild(div);\r\n            DOM.box.scrollTop = DOM.box.scrollHeight;\r\n            return div;\r\n        }\r\n\r\n        function handleKey(e) {\r\n            if (e.key === 'Enter') send();\r\n        }\r\n\r\n        async function send() {\r\n            const text = DOM.input.value.trim();\r\n            if (!text) return;\r\n\r\n            DOM.input.value = '';\r\n            append('user', text);\r\n\r\n            // Create pending placeholder\r\n            const loadingDiv = append('assistant', '...');\r\n\r\n            try {\r\n                const res = await fetch('/v1/chat/completions', {\r\n                    method: 'POST',\r\n                    headers: {\r\n                        'Content-Type': 'application/json',\r\n                        'Authorization': `Bearer ${TOKEN}`\r\n                    },\r\n                    body: JSON.stringify({\r\n                        model: \"mobile-chat\", // Bridge ignores this usually, or we can fetch models\r\n                        messages: [{ role: \"user\", content: text }],\r\n                        stream: false // Simple non-streaming for mobile stability first\r\n                    })\r\n                });\r\n\r\n                if (res.status === 401) {\r\n                    loadingDiv.innerText = \"âŒ Unauthorized. Check Token.\";\r\n                    logout(); // Force re-login\r\n                    return;\r\n                }\r\n\r\n                if (!res.ok) {\r\n                    throw new Error(`Server Error: ${res.status}`);\r\n                }\r\n\r\n                const data = await res.json();\r\n                const reply = data.choices?.[0]?.message?.content || \"No response.\";\r\n                loadingDiv.innerText = reply;\r\n\r\n            } catch (e) {\r\n                loadingDiv.innerText = `Error: ${e.message}`;\r\n                loadingDiv.style.color = 'red';\r\n            }\r\n        }\r\n    </script>\r\n</body>\r\n\r\n</html>",
    "source": "tools\\mobile-chat.html"
  },
  {
    "id": "tools\\model-server-chat.html",
    "timestamp": 1766387588,
    "role": "file",
    "content": "<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Root Coda Console</title>\n    <style>\n        * {\n            box-sizing: border-box;\n        }\n\n        body {\n            background: #0f0f11;\n            color: #ccc;\n            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n            display: flex;\n            height: 100vh;\n            margin: 0;\n        }\n\n        /* --- Resizable Split Layout --- */\n        #container {\n            display: flex;\n            width: 100%;\n            height: 100vh;\n            overflow: hidden;\n        }\n\n        #sidebar {\n            width: 320px;\n            /* Default width */\n            min-width: 200px;\n            max-width: 80%;\n            background: #151517;\n            color: #d4d4d4;\n            display: flex;\n            flex-direction: column;\n            border-right: 1px solid #333;\n            transition: width 0.1s ease;\n        }\n\n        /* Resize Handle */\n        #resizer {\n            width: 5px;\n            cursor: col-resize;\n            background: #333;\n            transition: background 0.2s;\n            z-index: 10;\n        }\n\n        #resizer:hover,\n        #resizer.resizing {\n            background: #00ff88;\n        }\n\n        #main {\n            flex: 1;\n            display: flex;\n            flex-direction: column;\n            background: #1e1e1e;\n            position: relative;\n            min-width: 0;\n        }\n\n        /* --- Collapsible Details --- */\n        details {\n            margin-bottom: 10px;\n            border-bottom: 1px solid #333;\n        }\n\n        summary {\n            padding: 10px;\n            cursor: pointer;\n            font-weight: bold;\n            user-select: none;\n            background: #252526;\n            list-style: none;\n        }\n\n        summary::-webkit-details-marker {\n            display: none;\n        }\n\n        summary::after {\n            content: 'â–¼';\n            float: right;\n            font-size: 0.8em;\n            transition: transform 0.2s;\n        }\n\n        details[open] summary::after {\n            transform: rotate(180deg);\n        }\n\n        .panel-content {\n            padding: 10px;\n            display: flex;\n            flex-direction: column;\n            gap: 8px;\n        }\n\n        /* --- Chat Box --- */\n        #chat-box {\n            flex: 1;\n            overflow-y: auto;\n            margin-bottom: 20px;\n            padding-right: 10px;\n        }\n\n        #chat-box::-webkit-scrollbar {\n            width: 8px;\n        }\n\n        #chat-box::-webkit-scrollbar-track {\n            background: #333;\n        }\n\n        #chat-box::-webkit-scrollbar-thumb {\n            background: #555;\n            border-radius: 4px;\n        }\n\n        .msg {\n            padding: 12px;\n            margin: 8px 0;\n            border-radius: 6px;\n            background: #333;\n            max-width: 85%;\n            word-wrap: break-word;\n        }\n\n        .user {\n            background: #005f3b;\n            /* Root Green-ish */\n            color: white;\n            align-self: flex-end;\n            margin-left: auto;\n        }\n\n        .assistant {\n            background: #2d2d2d;\n            border-left: 3px solid #00ff88;\n        }\n\n        .msg details {\n            margin-top: 10px;\n            font-size: 0.85rem;\n            opacity: 0.7;\n            border: none;\n        }\n\n        .msg pre {\n            background: #151515;\n            padding: 8px;\n            border-radius: 4px;\n            overflow-x: auto;\n            font-size: 0.8rem;\n        }\n\n        h3 {\n            margin: 0 0 10px 0;\n        }\n\n        #status-text {\n            font-size: 0.9rem;\n            color: #888;\n            margin-bottom: 8px;\n        }\n\n        #progress-bar {\n            height: 4px;\n            background: #333;\n            border-radius: 2px;\n            overflow: hidden;\n            margin: 8px 0;\n        }\n\n        #progress {\n            height: 100%;\n            background: #00ff88;\n            width: 0%;\n            transition: width 0.2s;\n        }\n\n        #status-log {\n            flex: 1;\n            overflow-y: auto;\n            font-family: 'Consolas', monospace;\n            font-size: 0.75rem;\n            margin-top: 10px;\n            padding: 8px;\n            background: #0f0f0f;\n            border-radius: 4px;\n            border: 1px solid #333;\n        }\n\n        #status-log div {\n            margin: 2px 0;\n            padding: 2px 0;\n        }\n\n        .info {\n            color: #888;\n        }\n\n        .warn {\n            color: #ffc107;\n        }\n\n        .error {\n            color: #ff4444;\n        }\n\n        .success {\n            color: #00ff88;\n        }\n\n        #input-area {\n            display: flex;\n            gap: 10px;\n        }\n\n        textarea {\n            flex: 1;\n            height: 60px;\n            background: #3c3c3c;\n            border: 1px solid #555;\n            color: white;\n            padding: 10px;\n            border-radius: 4px;\n            resize: vertical;\n            font-family: 'Segoe UI', sans-serif;\n        }\n\n        textarea:focus {\n            outline: none;\n            border-color: #00ff88;\n        }\n\n        button {\n            padding: 8px 20px;\n            background: #2d2d2d;\n            color: white;\n            border: 1px solid #444;\n            border-radius: 4px;\n            cursor: pointer;\n            font-weight: bold;\n            align-self: flex-end;\n            transition: all 0.2s;\n        }\n\n        button:hover {\n            border-color: #00ff88;\n            color: #00ff88;\n        }\n\n        button:disabled {\n            background: #222;\n            border-color: #333;\n            color: #555;\n            cursor: not-allowed;\n        }\n\n        .streaming {\n            border-right: 2px solid #00ff88;\n            animation: blink 0.7s infinite;\n        }\n\n        @keyframes blink {\n            50% {\n                border-color: transparent;\n            }\n        }\n    </style>\n</head>\n\n<body>\n    <div id=\"container\">\n        <div id=\"sidebar\">\n            <div\n                style=\"padding: 10px; font-weight: bold; font-size: 16px; border-bottom: 1px solid #444; color: #00ff88;\">\n                âš¡ ROOT CODA\n            </div>\n            <small id=\"status-text\" style=\"padding: 0 10px;\">Initializing...</small>\n            <div id=\"progress-bar\" style=\"margin: 8px 10px 15px 10px;\">\n                <div id=\"progress\"></div>\n            </div>\n\n            <!-- COLLAPSIBLE: Model Selection -->\n            <details open>\n                <summary>Model Selection</summary>\n                <div class=\"panel-content\">\n                    <label for=\"hw-profile\"\n                        style=\"display:block; font-size: 11px; color: #ccc; margin-bottom: 4px;\">Hardware\n                        Profile:</label>\n                    <select id=\"hw-profile\" class=\"form-control\"\n                        style=\"width: 100%; padding: 5px; background: #333; color: white; border: 1px solid #555; margin-bottom: 10px;\">\n                        <option value=\"lite\">ðŸ”‹ Lite (Mobile / Snapdragon) - 2k Context</option>\n                        <option value=\"mid\" selected>ðŸ’» Mid (8GB VRAM) - 4k Context</option>\n                        <option value=\"high\">ðŸš€ High (16GB VRAM) - 16k Context</option>\n                        <option value=\"ultra\">âš¡ Ultra (24GB+ VRAM) - 32k Context</option>\n                    </select>\n                    <select id=\"model-select\" disabled\n                        style=\"width: 100%; padding: 5px; background: #333; color: white; border: 1px solid #555;\">\n                        <option value=\"\" disabled>-- Select a Model --</option>\n\n                        <optgroup label=\"âœ¨ SOTA (Latest)\">\n                            <option value=\"mlc-ai/DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC\">DeepSeek R1 (7B Distill) [Verified]</option>\n                            <option value=\"mlc-ai/Qwen3-4B-q4f16_1-MLC\">Qwen 3 4B (Base) [Verified]</option>\n                            <option value=\"mlc-ai/Qwen3-8B-q4f16_1-MLC\">Qwen 3 8B (Base) [Verified]</option>\n                            <option value=\"mlc-ai/Qwen2.5-7B-Instruct-q4f16_1-MLC\" selected>Qwen 2.5 7B (Instruct) [Verified]</option>\n                            <option value=\"mlc-ai/Phi-3.5-mini-instruct-q4f16_1-MLC\">Phi 3.5 Mini (3.8B)</option>\n                        </optgroup>\n\n                        <optgroup label=\"ðŸš€ High Performance (Small)\">\n                            <option value=\"mlc-ai/SmolLM2-1.7B-Instruct-q4f16_1-MLC\">SmolLM2 1.7B</option>\n                            <option value=\"mlc-ai/SmolLM2-360M-Instruct-q4f16_1-MLC\">SmolLM2 360M (Ultra Fast)</option>\n                            <option value=\"mlc-ai/Qwen2.5-3B-Instruct-q4f16_1-MLC\">Qwen 2.5 3B (Reliable)</option>\n                        </optgroup>\n\n                        <optgroup label=\"ðŸŒŸ 14B Models\">\n                            <option value=\"mlc-ai/Qwen2.5-14B-Instruct-q4f16_1-MLC\">Qwen 2.5 14B (Instruct)</option>\n                            <option value=\"mlc-ai/DeepSeek-R1-Distill-Qwen-14B-q4f16_1-MLC\">DeepSeek R1 (14B Distill)</option>\n                        </optgroup>\n\n                        <optgroup label=\"ðŸ§ª Experimental / Other\">\n                            <option value=\"mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC\">Llama 3.2 3B</option>\n                            <option value=\"mlc-ai/gemma-2-2b-it-q4f16_1-MLC\">Gemma 2 2B</option>\n                            <option value=\"mlc-ai/gemma-3-2b-it-q4f16_1-MLC\">Gemma 3 2B</option>\n                            <option value=\"mlc-ai/TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC\">TinyLlama 1.1B</option>\n                        </optgroup>\n\n                        <option value=\"custom\">-- Custom --</option>\n                    </select>\n                    <input id=\"custom-model-input\" type=\"text\" placeholder=\"Custom model ID\"\n                        style=\"width: 100%; padding: 5px; font-size: 11px;\" disabled />\n                    <button id=\"load-model-btn\" disabled\n                        style=\"width: 100%; padding: 6px; margin-top:5px; font-size: 11px;\">Load Model</button>\n                    <div style=\"font-size: 9px; color: #888; margin-top: 5px;\">\n                        * Models marked with * may require checking availability in MLC-AI repository\n                    </div>\n                </div>\n            </details>\n\n            <!-- COLLAPSIBLE: Controls -->\n            <details>\n                <summary>System Controls</summary>\n                <div class=\"panel-content\">\n                    <div\n                        style=\"background: #222; padding: 4px; margin-bottom: 4px; border: 1px solid #444; border-radius: 4px;\">\n                        <input type=\"checkbox\" id=\"enable-bridge-toggle\" onchange=\"toggleBridge(this.checked)\">\n                        <label for=\"enable-bridge-toggle\" style=\"font-size: 11px; cursor: pointer;\">Enable Wave Bridge\n                            (ws:8080)</label>\n                        <div id=\"bridge-status\" style=\"font-size: 10px; color: #666; margin-left: 20px;\">Disconnected\n                        </div>\n                    </div>\n                    <button id=\"clear-cache-btn\"\n                        style=\"width: 100%; padding: 6px; background: #a43131; border:none; margin-top:5px; font-size: 11px;\">âš ï¸\n                        Delete Model Cache</button>\n                    <button id=\"debug-gpu-btn\"\n                        style=\"width: 100%; padding: 6px; background: #555; border:none; margin-top: 5px; font-size: 11px;\">â“\n                        Debug GPU</button>\n                </div>\n            </details>\n\n            <!-- COLLAPSIBLE: Logs -->\n            <details open style=\"flex: 1; display: flex; flex-direction: column;\">\n                <summary>System Logs</summary>\n                <div class=\"panel-content\" style=\"flex: 1; display: flex; flex-direction: column; overflow: hidden;\">\n                    <button id=\"copy-logs-btn\" style=\"width: 100%; padding: 4px; background: #333; font-size: 10px;\">ðŸ“‹\n                        Copy Logs</button>\n                    <div id=\"status-log\"></div>\n                </div>\n            </details>\n        </div>\n\n        <div id=\"resizer\"></div>\n\n        <div id=\"main\">\n            <!-- Split view for Chat and Context -->\n            <div style=\"flex: 1; display: flex; height: 100%; overflow: hidden;\">\n                <!-- Chat Column -->\n                <div style=\"flex: 1; display: flex; flex-direction: column; border-right: 1px solid #333;\">\n                    <div style=\"padding: 10px; background: #252526; font-weight: bold; border-bottom: 1px solid #333;\">\n                        ðŸ’¬ Chat Stream</div>\n                    <div id=\"chat-box\"></div>\n                    <div id=\"input-area\" style=\"padding: 10px; border-top: 1px solid #333;\">\n                        <textarea id=\"input\" disabled placeholder=\"Waiting for Engine...\"></textarea>\n                        <button id=\"send-btn\" disabled>Send</button>\n                    </div>\n                </div>\n\n                <!-- Context Column -->\n                <div style=\"width: 40%; display: flex; flex-direction: column; background: #151515;\">\n                    <div style=\"padding: 10px; background: #252526; font-weight: bold; border-bottom: 1px solid #333;\">\n                        ðŸ§  Root Memory</div>\n                    <div id=\"context-box\"\n                        style=\"flex: 1; overflow-y: auto; padding: 10px; font-family: monospace; font-size: 12px; white-space: pre-wrap; color: #aaa;\">\n                        <div style=\"text-align: center; margin-top: 50px; color: #555;\">(Active retrievals will appear\n                            here)</div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n\n    <script type=\"module\">\n        // --- IMPORTS ---\n        import { SovereignLogger, createStore, getWebGPUConfig, initCozo } from './modules/sovereign.js';\n        import { CozoDb } from './cozo_lib_wasm.js';\n        import { loadAllFromIndexedDb, writeToIndexedDb } from './indexeddb.js';\n        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.16.0';\n        import { CreateWebWorkerMLCEngine } from \"https://esm.run/@mlc-ai/web-llm\";\n        import { marked } from \"https://cdn.jsdelivr.net/npm/marked/lib/marked.esm.js\";\n\n        env.allowLocalModels = false;\n\n        // --- ROOT KERNEL SETUP ---\n        const logger = new SovereignLogger('Root-Console');\n\n        const { state, subscribe } = createStore({\n            status: \"Initializing...\",\n            progress: 0,\n            activeModel: null\n        });\n\n        // Bridge legacy UI logging to Sovereign Logger\n        const ui = {\n            log: (msg, type = 'info') => {\n                // Bridge to Kernel Logger\n                if (type === 'debug') type = 'info';\n                if (logger[type]) logger[type](msg); else logger.info(msg);\n\n                // Update on-screen log\n                const el = document.getElementById('status-log');\n                if (el) {\n                    const div = document.createElement('div');\n                    div.className = type;\n                    div.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;\n                    div.style.fontSize = '11px';\n                    div.style.padding = '2px';\n                    div.style.borderBottom = '1px solid #222';\n                    el.insertBefore(div, el.firstChild);\n                    if (el.children.length > 100) el.removeChild(el.lastChild);\n                }\n            },\n            updateProgress: (pct, text) => {\n                const bar = document.getElementById('progress');\n                if (bar) bar.style.width = (pct * 100) + \"%\";\n                if (text) {\n                    const el = document.getElementById('status-text');\n                    if (el) el.innerText = text;\n                }\n            },\n            append: (role, text, meta = null) => {\n                const box = document.getElementById('chat-box');\n                const div = document.createElement('div');\n                div.className = `msg ${role}`;\n                div.innerHTML = text ? marked.parse(text) : \"\";\n\n                if (meta && meta.trace && meta.trace.length > 0) {\n                    const details = document.createElement('details');\n                    const summary = document.createElement('summary');\n                    summary.textContent = 'ðŸ“‹ Reasoning Trace';\n                    const pre = document.createElement('pre');\n                    pre.textContent = JSON.stringify(meta.trace, null, 2);\n                    details.appendChild(summary);\n                    details.appendChild(pre);\n                    div.appendChild(details);\n                }\n\n                box.appendChild(div);\n                box.scrollTop = box.scrollHeight;\n\n                return {\n                    div,\n                    update: (newText, isMarkdown = true) => {\n                        div.innerHTML = isMarkdown ? marked.parse(newText) : newText;\n                        box.scrollTop = box.scrollHeight;\n                    },\n                    appendText: (chunk) => {\n                        if (div.innerText.endsWith(\"...\")) div.innerText = div.innerText.slice(0, -3);\n                        div.innerText += chunk;\n                        box.scrollTop = box.scrollHeight;\n                    }\n                };\n            },\n            appendContext: (title, details) => {\n                const box = document.getElementById('context-box');\n                const div = document.createElement('div');\n                div.style.borderBottom = '1px solid #333';\n                div.style.marginBottom = '10px';\n                div.style.paddingBottom = '10px';\n\n                const h4 = document.createElement('div');\n                h4.style.fontWeight = 'bold';\n                h4.style.color = '#00ff88';\n                h4.style.marginBottom = '5px';\n                h4.textContent = `[${new Date().toLocaleTimeString()}] ${title}`;\n\n                const p = document.createElement('div');\n                p.style.whiteSpace = 'pre-wrap';\n                p.textContent = details;\n\n                div.appendChild(h4);\n                div.appendChild(p);\n                box.appendChild(div);\n                box.scrollTop = box.scrollHeight;\n            }\n        };\n\n        // --- GLOBAL STATE ---\n        let db;\n        let embedder;\n        let engine;\n        let contextManager;\n        let selectedModelId = null;\n\n        // --- UTILS: Response Pattern Matcher ---\n        class ResponsePattern {\n            static match(response) {\n                let data = response;\n                if (typeof response === 'string') {\n                    try {\n                        const clean = response.replace(/```json/g, '').replace(/```/g, '').trim();\n                        if (clean.startsWith('{')) data = JSON.parse(clean);\n                    } catch (e) { }\n                }\n                if (data?.rows && Array.isArray(data.rows)) return { type: 'DB_RESULT', rows: data.rows, count: data.rows.length };\n                if (data?.error || (typeof response === 'string' && response.toLowerCase().includes('error:'))) return { type: 'ERROR', error: data?.error || response };\n                if (data?.ok === false && data?.message) return { type: 'ERROR', error: data.message };\n                return { type: 'RAW_TEXT', text: typeof response === 'string' ? response : JSON.stringify(response) };\n            }\n        }\n\n        // --- LOGIC: Context Manager (SFS) ---\n        class ContextManager {\n            constructor(engine, db) {\n                this.engine = engine;\n                this.db = db;\n                this.maxIterations = 3;\n            }\n\n            async retrieveInitialContext(userText) {\n                ui.log(\"ðŸ” Reflex: Initiating Hybrid Retrieval...\", \"info\");\n\n                // 1. GENERATE QUERY VECTOR (Semantic)\n                let vectorResults = [];\n                if (embedder) {\n                    try {\n                        const output = await embedder(userText, { pooling: 'mean', normalize: true });\n                        const queryVec = Array.from(output.data);\n\n                        // CozoDB Vector Search (Brute Force L2 for accuracy on local sets)\n                        // Query: Find top 10 nearest neighbors where embedding exists\n                        const vecQuery = `\n                            ?[id, content, dist, timestamp] := *memory{id, content, embedding, timestamp},\n                            !is_null(embedding),\n                            dist = vec_l2(embedding, $vec)\n                            :sort dist\n                            :limit 10\n                        `;\n                        const res = await this.db.run(vecQuery, JSON.stringify({ vec: queryVec }));\n                        const parsed = ResponsePattern.match(res);\n                        if (parsed.rows) vectorResults = parsed.rows.map(r => ({ id: r[0], content: r[1], dist: r[2], ts: r[3], source: 'semantic' }));\n                        ui.log(`ðŸ§  Semantic: Found ${vectorResults.length} concept matches.`, \"info\");\n                    } catch (e) {\n                        ui.log(`âš ï¸ Vector Search failed: ${e.message}`, \"warn\");\n                    }\n                }\n\n                // 2. GENERATE KEYWORD QUERY (Lexical)\n                let keywordResults = [];\n                const rawWords = userText.match(/[a-zA-Z0-9_\\-]+/g) || [];\n                const stopWords = new Set(['the', 'and', 'is', 'in', 'at', 'of', 'on', 'for', 'to', 'it', 'this', 'that', 'what', 'who', 'how', 'why', 'when', 'where', 'did', 'does', 'do', 'can', 'could', 'would', 'should', 'will', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'a', 'an', 'tell', 'me', 'about']);\n                const keywords = rawWords.map(w => w.replace(/^[-_]+|[-_]+$/g, '')).filter(w => w.length > 2 && !stopWords.has(w.toLowerCase()));\n\n                if (keywords.length > 0) {\n                    const conditions = keywords.map(w => `regex_matches(content, '(?i)${w}')`).join(' or ');\n                    const kwQuery = `?[id, content, timestamp] := *memory{id, content, timestamp}, ${conditions} :sort -timestamp :limit 10`;\n                    try {\n                        const res = await this.db.run(kwQuery, \"{}\");\n                        const parsed = ResponsePattern.match(res);\n                        if (parsed.rows) keywordResults = parsed.rows.map(r => ({ id: r[0], content: r[1], dist: 0, ts: r[2], source: 'lexical' }));\n                        ui.log(`ðŸ“– Lexical: Found ${keywordResults.length} keyword matches.`, \"info\");\n                    } catch (e) { console.warn(e); }\n                }\n\n                // 3. MERGE & DEDUPLICATE\n                // Priority: Vector (Concepts) + Lexical (Specifics)\n                const combined = new Map();\n\n                // Add Vector Results first\n                vectorResults.forEach(item => combined.set(item.content, item));\n\n                // Add Lexical (only if not already present)\n                keywordResults.forEach(item => {\n                    if (!combined.has(item.content)) combined.set(item.content, item);\n                });\n\n                const finalItems = Array.from(combined.values());\n\n                if (finalItems.length === 0) return \"\";\n\n                // 4. FORMAT OUTPUT (Smart Window)\n                // Sort by relevance (Vector distance low is good, Lexical is 0 distance but prioritized by recency)\n                // Let's just take Top 10 mixed.\n                const topItems = finalItems.slice(0, 10);\n\n                const paths = [];\n                const clues = topItems.map((item, index) => {\n                    const id = index + 1;\n                    let title = \"doc_\" + id;\n                    if (item.content.length > 0) {\n                        const safeTitle = item.content.substring(0, 30).replace(/[^a-zA-Z0-9 ]/g, '').trim().replace(/\\s+/g, '_').toLowerCase();\n                        if (safeTitle.length > 3) title = safeTitle;\n                    }\n                    const path = `/knowledge/${item.source}/${title}`;\n                    paths.push(path);\n\n                    // Smart Truncate: If it's a vector match, we might want more context. \n                    // Current limit 300 chars to save tokens.\n                    let snippet = item.content.substring(0, 300).replace(/\\n/g, ' ');\n                    if (item.content.length > 300) snippet += \"...\";\n\n                    return `[CLUE #${id}] [Path: ${path}] [Source: ${item.source.toUpperCase()}]\\nSnippet: \"${snippet}\"`;\n                });\n\n                ui.log(`âœ… Hybrid Retrieval: ${topItems.length} active clues.`, \"success\");\n                const treeMap = `[CURRENT REALITY MAP]\\n` + paths.map(p => `- ${p}`).join('\\n');\n                return `${treeMap}\\n\\n[CONTEXT CLUES]\\n${clues.join('\\n\\n')}`;\n            }\n\n            buildVirtualPrompt(systemPrompt, retrievedMemories, chatHistory, userText) {\n                const physicsInstruction = `\n### COGNITIVE PROTOCOL:\n1. **TRUST THE CLUES:** You are operating in a \"Sovereign\" environment. The [CONTEXT CLUES] provided are the Ground Truth.\n2. **MINIMIZE ENTROPY:** If a Clue contains the answer, OUTPUT IT DIRECTLY. Do not generate \"filler\".\n3. **PATH OF LEAST ACTION:** The most efficient answer is the correct one.\n`;\n                return `\n### BACKGROUND INFORMATION\n${retrievedMemories ? retrievedMemories : \"No specific context available.\"} \n\n### CHAT HISTORY\n${chatHistory.map(m => `${m.role.toUpperCase()}: ${m.content}`).join('\\n')}\n\n### INSTRUCTION\n${systemPrompt}\n${physicsInstruction}\nBased on the Background Information above, answer the following question.\n\n### USER QUESTION\n${userText}\n`;\n            }\n\n            async executeR1Loop(userText, history) {\n                let iteration = 0;\n                let currentContext = await this.retrieveInitialContext(userText);\n                if (currentContext) ui.appendContext(\"Reflex Retrieval\", currentContext);\n\n                while (iteration < this.maxIterations) {\n                    iteration++;\n                    const fullPrompt = this.buildVirtualPrompt(\n                        \"You are Root Coda, a Sovereign Agent.\\n\" +\n                        \"PROTOCOL: Trust clues. Answer directly. No refusals.\",\n                        currentContext,\n                        history.slice(-5),\n                        userText\n                    );\n\n                    ui.log(`ðŸ§  Reasoning (Iter ${iteration})...`, \"info\");\n                    let reply = \"\";\n                    try {\n                        const response = await this.engine.chat.completions.create({\n                            messages: [{ role: \"user\", content: fullPrompt }],\n                            temperature: 0.1,\n                            max_tokens: 100\n                        });\n                        reply = response.choices[0].message.content.trim();\n                    } catch (genErr) {\n                        if (genErr.message.includes(\"disposed\")) return { context: currentContext, finalAnswer: \"âš ï¸ System Crash: GPU Driver lost.\" };\n                        throw genErr;\n                    }\n\n                    if (!reply) reply = \"\"; // Safety guard\n\n                    if (reply.includes(\"NEED_CONTEXT:\")) {\n                        const searchTerm = reply.split(\"NEED_CONTEXT:\")[1].trim();\n                        ui.log(`ðŸ¤– Requested search: \"${searchTerm}\"`, \"warn\");\n                        const extraData = await this.retrieveInitialContext(searchTerm);\n                        if (extraData) {\n                            currentContext += `\\n--- Additional (${searchTerm}) ---\\n${extraData}`;\n                            ui.appendContext(`Requested: ${searchTerm}`, extraData);\n                        }\n                        continue;\n                    }\n                    return { context: currentContext, finalAnswer: reply };\n                }\n                return { context: currentContext, finalAnswer: null };\n            }\n        }\n\n        // --- HANDLERS ---\n        async function handleSend() {\n            const input = document.getElementById('input');\n            const text = input.value.trim();\n            if (!text || !engine) return;\n\n            input.value = \"\";\n            input.disabled = true;\n            document.getElementById('send-btn').disabled = true;\n\n            ui.append(\"user\", text);\n\n            try {\n                const { context, finalAnswer } = await contextManager.executeR1Loop(text, []);\n                if (finalAnswer && finalAnswer.includes(\"System Crash\")) return ui.log(\"ðŸ›‘ Execution halted (GPU Crash).\", \"error\");\n\n                ui.log(\"ðŸ§ª Synthesizing...\", \"warn\");\n                const sysPrompt = `You are a helpful assistant with access to retrieved context. Use it to answer the user's question.\\n\\nCONTEXT:\\n${context || \"(No relevant context)\"}`;\n                const msgHandle = ui.append(\"assistant\", \"\");\n\n                const stream = await engine.chat.completions.create({\n                    messages: [{ role: \"system\", content: sysPrompt }, { role: \"user\", content: text }],\n                    max_tokens: 1024,\n                    temperature: 0.7,\n                    stream: true\n                });\n\n                let fullAnswer = \"\";\n                for await (const chunk of stream) {\n                    const delta = chunk.choices[0]?.delta?.content || \"\";\n                    fullAnswer += delta;\n                    msgHandle.update(fullAnswer);\n                }\n                ui.log(\"âœ… Response generated.\", \"success\");\n\n            } catch (e) {\n                ui.log(`Error: ${e.message}`, \"error\");\n                ui.append(\"assistant\", `**Error:** ${e.message}`);\n            } finally {\n                input.disabled = false;\n                document.getElementById('send-btn').disabled = false;\n                input.focus();\n            }\n        }\n\n        async function loadModel() {\n            const select = document.getElementById('model-select');\n            const customInput = document.getElementById('custom-model-input');\n            const modelInput = select.value === 'custom' ? customInput.value : select.value;\n            if (!modelInput) return alert(\"Please select a model.\");\n\n            selectedModelId = modelInput.split('/').pop();\n            document.getElementById('load-model-btn').disabled = true;\n\n            try {\n                ui.log(`Initializing Engine (${selectedModelId})...`, \"info\");\n\n                // --- KERNEL: Hardware Config ---\n                const hwProfile = document.getElementById('hw-profile').value;\n                const gpuConfig = await getWebGPUConfig(hwProfile);\n\n                if (gpuConfig.isConstrained) {\n                    ui.log(`âš ï¸ Clamping WebGPU buffer to ${Math.round(gpuConfig.maxBufferSize / 1024 / 1024)}MB`, \"warn\");\n                } else {\n                    ui.log(`âœ… GPU Configured: ${Math.round(gpuConfig.maxBufferSize / 1024 / 1024)}MB Buffer`, \"success\");\n                }\n\n                // --- Config Generation ---\n                // (Simplified Logic for cleaner file)\n                const libBase = \"https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/\";\n                let modelLib = null;\n                const lowerId = selectedModelId.toLowerCase();\n                let qTag = \"q4f16_1\"; // Default\n\n                // Mapper\n                // SOTA / New\n                if (lowerId.includes('deepseek-r1') && !lowerId.includes('14b')) modelLib = libBase + `Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('qwen3-4b')) modelLib = libBase + `Qwen3-4B-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('qwen3-8b')) modelLib = libBase + `Qwen3-8B-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('qwen2.5-7b')) modelLib = libBase + `Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('phi-3.5-mini')) modelLib = libBase + `Phi-3.5-mini-instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n\n                // Small / Efficient\n                else if (lowerId.includes('smollm2-1.7b')) modelLib = libBase + `SmolLM2-1.7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('smollm2-360m')) modelLib = libBase + `SmolLM2-360M-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('tinyllama-1.1b')) modelLib = libBase + `TinyLlama-1.1B-Chat-v1.0-q4f16_1-ctx2k_cs1k-webgpu.wasm`;\n\n                // 14B Models\n                else if (lowerId.includes('qwen2.5-14b')) modelLib = libBase + `Qwen2.5-14B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('deepseek-r1-distill-qwen-14b')) modelLib = libBase + `Qwen2.5-14B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n\n                // Legacy / Stable\n                else if (lowerId.includes('qwen2.5-3b')) modelLib = libBase + `Qwen2.5-3B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('llama-3.2-3b')) modelLib = libBase + `Llama-3.2-3B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('gemma-2-2b')) modelLib = libBase + `gemma-2-2b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('gemma-3-2b')) modelLib = libBase + `gemma-3-2b-it-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n\n                // Fallbacks\n                else if (lowerId.includes('qwen2.5-1.5b')) modelLib = libBase + `Qwen2-1.5B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n                else if (lowerId.includes('qwen2.5-7b')) modelLib = libBase + `Qwen2-7B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`;\n\n                if (!modelLib) modelLib = libBase + `Qwen2.5-3B-Instruct-${qTag}-ctx4k_cs1k-webgpu.wasm`; // Safe Fallback 3B\n\n                let appConfig = {\n                    useIndexedDBCache: true,\n                    model_list: [{\n                        model: \"https://huggingface.co/\" + modelInput + \"/resolve/main/\",\n                        model_id: selectedModelId,\n                        model_lib: modelLib,\n                        vram_required_MB: 2000,\n                        low_resource_required: true,\n                        buffer_size_required_bytes: gpuConfig.maxBufferSize,\n                    }]\n                };\n\n                // Create the Worker\n                const worker = new Worker('./modules/llm-worker.js', { type: 'module' });\n\n                // Initialize Engine via Worker\n                engine = await CreateWebWorkerMLCEngine(\n                    worker,\n                    selectedModelId,\n                    {\n                        appConfig, // Passing the VRAM/Buffer limits we calculated\n                        initProgressCallback: (rep) => ui.updateProgress(rep.progress, rep.text)\n                    }\n                );\n\n                ui.log(\"ðŸŽ‰ Root Console Online\", \"success\");\n                contextManager = new ContextManager(engine, db);\n                document.getElementById('input').disabled = false;\n                document.getElementById('send-btn').disabled = false;\n                document.getElementById('input').focus();\n\n            } catch (e) {\n                const errorMsg = e.message || String(e);\n                ui.log(`Load Failed: ${errorMsg}`, \"error\");\n                // Provide suggestion for common model name issues\n                if (errorMsg && errorMsg.includes(\"Network response was not ok\")) {\n                    ui.log(`ðŸ’¡ Hint: Model may not exist or be temporarily unavailable. Try another model.`, \"warn\");\n                }\n                document.getElementById('load-model-btn').disabled = false;\n            }\n        }\n\n        async function init() {\n            try {\n                ui.log(\"ðŸš€ Root Kernel Starting...\", \"info\");\n\n                // 1. CozoDB\n                await initCozo('./cozo_lib_wasm_bg.wasm');\n                // Recovery Logic\n                try {\n                    const [keys] = await loadAllFromIndexedDb('coda_memory', 'cozo_store', () => { });\n                    if (keys.length > 0) {\n                        db = await CozoDb.new_from_indexed_db('coda_memory', 'cozo_store', () => { });\n                        ui.log(\"âœ… Root Graph Connected (Persistent)\", \"success\");\n                    } else {\n                        db = CozoDb.new();\n                        ui.log(\"âœ… Root Graph Created (Memory)\", \"info\");\n                    }\n                } catch (e) {\n                    db = CozoDb.new();\n                    ui.log(\"âš ï¸ Fallback to Memory Graph\", \"warn\");\n                }\n\n                // 2. Embedder (Optional)\n                ui.updateProgress(0.3, \"Loading Embedder...\");\n                const embedderPromise = pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2', { device: 'wasm' });\n                try {\n                    embedder = await Promise.race([embedderPromise, new Promise((_, r) => setTimeout(() => r(new Error(\"Timeout\")), 10000))]);\n                    ui.log(\"âœ… Neural Embedder Ready\", \"success\");\n                } catch (e) { ui.log(\"âš ï¸ Embedder Skipped (Timeout)\", \"warn\"); }\n\n            } catch (e) {\n                ui.log(`Init Error: ${e.message}`, \"error\");\n            } finally {\n                // Ensure controls are unlocked even if init fails (partial functionality)\n                ui.updateProgress(1.0, \"Ready\");\n                document.getElementById('model-select').disabled = false;\n                document.getElementById('load-model-btn').disabled = false;\n                document.getElementById('load-model-btn').addEventListener('click', loadModel);\n\n                // Input Handlers (idempotent)\n                const sendBtn = document.getElementById('send-btn');\n                const input = document.getElementById('input');\n                if (sendBtn && input) {\n                    sendBtn.onclick = handleSend; // Use property to avoid duplicates\n                    input.onkeydown = (e) => {\n                        if (e.key === 'Enter' && !e.shiftKey && !sendBtn.disabled) {\n                            e.preventDefault();\n                            handleSend();\n                        }\n                    };\n                }\n            }\n        }\n\n        // --- BRIDGE LOGIC ---\n        let bridgeWs = null;\n        window.toggleBridge = function (enabled) {\n            if (enabled) {\n                if (!engine) { alert(\"Load model first!\"); document.getElementById('enable-bridge-toggle').checked = false; return; }\n                bridgeWs = new WebSocket(\"ws://localhost:8080/ws/chat\");\n                bridgeWs.onopen = () => { document.getElementById('bridge-status').innerText = \"ðŸŸ¢ Connected\"; ui.log(\"Bridge Online\", \"success\"); };\n                bridgeWs.onmessage = async (e) => {\n                    const msg = JSON.parse(e.data);\n                    if (msg.type === 'chat') {\n                        ui.log(`Bridge Request: ${msg.id}`, \"info\");\n                        const completion = await engine.chat.completions.create({ messages: msg.data.messages, stream: true });\n                        for await (const chunk of completion) bridgeWs.send(JSON.stringify({ id: msg.id, chunk }));\n                        bridgeWs.send(JSON.stringify({ id: msg.id, done: true }));\n                    }\n                };\n            } else if (bridgeWs) { bridgeWs.close(); bridgeWs = null; document.getElementById('bridge-status').innerText = \"Disconnected\"; }\n        };\n\n        window.addEventListener('load', init);\n    </script>\n</body>\n\n</html>",
    "source": "tools\\model-server-chat.html"
  },
  {
    "id": "tools\\prepare_cozo_import.py",
    "timestamp": 1765904026,
    "role": "file",
    "content": "#!/usr/bin/env python3\r\n\"\"\"\r\nPrepare a CozoDB import payload from an existing combined_memory.json file.\r\nUsage:\r\n  python tools/prepare_cozo_import.py [input_path] [output_path]\r\nIf input_path is omitted the script will search likely locations.\r\n\"\"\"\r\nimport json\r\nimport os\r\nimport sys\r\nfrom pathlib import Path\r\n\r\n# Defaults\r\nPOSSIBLE_INPUTS = [\r\n    Path(\"combined_memory.json\")\r\n]\r\nDEFAULT_OUTPUT = Path(\"cozo_import_memory.json\")\r\n\r\ndef find_input(path_arg=None):\r\n    if path_arg:\r\n        p = Path(path_arg)\r\n        if p.exists():\r\n            return p\r\n        else:\r\n            print(f\"âŒ Specified input not found: {p}\")\r\n            return None\r\n    for p in POSSIBLE_INPUTS:\r\n        if p.exists():\r\n            return p\r\n    # fallback: search workspace for first combined_memory.json\r\n    for p in Path('.').rglob('combined_memory.json'):\r\n        return p\r\n    return None\r\n\r\n\r\ndef normalize_record(rec):\r\n    # Ensure the fields Cozo expects. Return None to skip invalid records.\r\n    uid = rec.get(\"id\") or rec.get(\"uid\") or rec.get(\"uuid\") or None\r\n    if not uid:\r\n        # try deterministic id from source+timestamp\r\n        src = rec.get(\"source\") or rec.get(\"file\") or \"\"\r\n        ts = rec.get(\"timestamp\") or rec.get(\"created_at\") or 0\r\n        uid = f\"auto:{abs(hash(src + str(ts)))}\"\r\n    try:\r\n        uid = str(uid)\r\n    except Exception:\r\n        uid = str(uid)\r\n\r\n    try:\r\n        ts = int(rec.get(\"timestamp\", rec.get(\"created_at\", 0)) or 0)\r\n    except Exception:\r\n        try:\r\n            ts = int(float(rec.get(\"timestamp\", 0)))\r\n        except Exception:\r\n            ts = 0\r\n\r\n    role = str(rec.get(\"role\", \"system\"))\r\n    content = rec.get(\"content\", \"\")\r\n    if not isinstance(content, str):\r\n        try:\r\n            content = json.dumps(content, ensure_ascii=False)\r\n        except Exception:\r\n            content = str(content)\r\n    # cap content size to be safe\r\n    MAX_CONTENT = 200_000\r\n    if len(content) > MAX_CONTENT:\r\n        content = content[:MAX_CONTENT]\r\n\r\n    source = rec.get(\"source\", rec.get(\"file\", \"historical_import\"))\r\n    try:\r\n        source = str(source)\r\n    except Exception:\r\n        source = \"historical_import\"\r\n\r\n    embedding = rec.get(\"embedding\", None)\r\n    # Keep embedding as-is if present and looks like a list of numbers\r\n    if isinstance(embedding, list):\r\n        # Optionally validate length later; leave as-is\r\n        pass\r\n    else:\r\n        embedding = None\r\n\r\n    return [uid, ts, role, content, source, embedding]\r\n\r\n\r\ndef main():\r\n    input_arg = sys.argv[1] if len(sys.argv) > 1 else None\r\n    output_arg = sys.argv[2] if len(sys.argv) > 2 else None\r\n\r\n    inp = find_input(input_arg)\r\n    if not inp:\r\n        print(\"âŒ Could not find a combined_memory.json file. Provide the path as the first argument.\")\r\n        return 1\r\n\r\n    out = Path(output_arg) if output_arg else DEFAULT_OUTPUT\r\n\r\n    print(f\"Reading {inp}...\")\r\n    try:\r\n        raw = json.loads(inp.read_text(encoding='utf-8'))\r\n    except json.JSONDecodeError as e:\r\n        print(f\"âŒ JSON decode error: {e}\")\r\n        return 1\r\n\r\n    if not isinstance(raw, list):\r\n        print(\"â— Warning: input root is not a list. Attempting to find list under 'records' or 'data'.\")\r\n        if isinstance(raw, dict):\r\n            if 'records' in raw and isinstance(raw['records'], list):\r\n                raw = raw['records']\r\n            elif 'data' in raw and isinstance(raw['data'], list):\r\n                raw = raw['data']\r\n            else:\r\n                print(\"âŒ Could not find the expected list of records in input JSON.\")\r\n                return 1\r\n\r\n    print(f\"Found {len(raw)} records. Normalizing and formatting...\")\r\n\r\n    rows = []\r\n    for rec in raw:\r\n        nr = normalize_record(rec)\r\n        if nr is None:\r\n            continue\r\n        rows.append(nr)\r\n\r\n    payload = {\r\n        \"relations\": [\r\n            {\r\n                \"name\": \"memory\",\r\n                \"headers\": [\"id\", \"timestamp\", \"role\", \"content\", \"source\", \"embedding\"],\r\n                \"rows\": rows,\r\n            }\r\n        ]\r\n    }\r\n\r\n    print(f\"Writing {len(rows)} rows to {out}...\")\r\n    out.write_text(json.dumps(payload, ensure_ascii=False, separators=(',', ':')), encoding='utf-8')\r\n    print(\"âœ… Done. You can now drag 'cozo_import_memory.json' into the Builder or use the console import helper.\")\r\n    return 0\r\n\r\n\r\nif __name__ == '__main__':\r\n    raise SystemExit(main())\r\n",
    "source": "tools\\prepare_cozo_import.py"
  },
  {
    "id": "tools\\README.md",
    "timestamp": 1766020713,
    "role": "file",
    "content": "## Requirements\r\n\r\n*   **Browser**: Chrome 113+, Edge 113+ (WebGPU required)\r\n*   **GPU**: WebGPU-compatible (most modern GPUs)\r\n*   **RAM**: 4GB+ for 7B models, 2GB+ for 1.5B models\r\n*   **Storage**: IndexedDB for persistent memory (browser-managed)\r\n\r\n## Corruption Recovery\r\n\r\nIf you see \"Failed to convert Uint8Array to Vec<u8>\" or WASM panics:\r\n1. Click **ðŸš¨ Recover from Crash** button (appears automatically)\r\n2. Or use **Nuke Database** for complete reset\r\n3. Data export available before recovery for backup\r\n\r\n## Quick Start: Zero Dependencies\r\n\r\n### Option 1: Direct HTML (Recommended)\r\n1. Open `tools/index.html` in Chrome/Edge\r\n2. Click **Model Server Chat** â†’ Select model â†’ Start chatting\r\n3. Click **Memory Builder** â†’ Ingest your data\r\n4. All processing happens in-browser via WebGPU/WASM\r\n\r\n### Option 2: Extension Integration (Optional)\r\nInstall Chrome extension for automatic page context injection",
    "source": "tools\\README.md"
  },
  {
    "id": "tools\\root-dreamer.html",
    "timestamp": 1766387308,
    "role": "file",
    "content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Root Dreamer (Subconscious)</title>\n    <link rel=\"icon\" href=\"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒ™</text></svg>\">\n    <style>\n        :root {\n            --bg-color: #0d1117;\n            --text-color: #c9d1d9;\n            --border-color: #30363d;\n            --accent-color: #58a6ff;\n            --success-color: #238636;\n            --danger-color: #da3633;\n            --thought-color: #d29922;\n            --raw-color: #8b949e;\n        }\n\n        body {\n            background-color: var(--bg-color);\n            color: var(--text-color);\n            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Helvetica, Arial, sans-serif;\n            margin: 0;\n            padding: 20px;\n            display: flex;\n            flex-direction: column;\n            height: 100vh;\n            box-sizing: border-box;\n        }\n\n        header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            border-bottom: 1px solid var(--border-color);\n            padding-bottom: 10px;\n            margin-bottom: 20px;\n        }\n\n        h1 { margin: 0; font-size: 1.5rem; }\n\n        .status-panel {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n            gap: 10px;\n            margin-bottom: 20px;\n        }\n\n        .card {\n            background: #161b22;\n            border: 1px solid var(--border-color);\n            border-radius: 6px;\n            padding: 15px;\n        }\n\n        .stat-value {\n            font-size: 2rem;\n            font-weight: bold;\n            color: var(--accent-color);\n        }\n\n        .stat-label {\n            font-size: 0.9rem;\n            color: #8b949e;\n        }\n\n        .controls {\n            display: flex;\n            gap: 10px;\n        }\n\n        button {\n            background-color: #21262d;\n            color: var(--text-color);\n            border: 1px solid var(--border-color);\n            padding: 8px 16px;\n            border-radius: 6px;\n            cursor: pointer;\n            font-size: 0.9rem;\n            transition: background-color 0.2s;\n        }\n\n        button:hover { background-color: #30363d; }\n        \n        button.active {\n            background-color: var(--success-color);\n            color: white;\n            border-color: var(--success-color);\n        }\n        \n        button.stop {\n            background-color: var(--danger-color);\n            border-color: var(--danger-color);\n        }\n\n        /* Tabs */\n        .tabs {\n            display: flex;\n            border-bottom: 1px solid var(--border-color);\n            margin-bottom: 0;\n        }\n        \n        .tab {\n            padding: 10px 20px;\n            cursor: pointer;\n            border-bottom: 2px solid transparent;\n            color: #8b949e;\n        }\n        \n        .tab:hover { color: var(--text-color); }\n        \n        .tab.active {\n            color: var(--text-color);\n            border-bottom-color: var(--accent-color);\n        }\n\n        /* Logs */\n        .log-container {\n            flex-grow: 1;\n            background: #000;\n            border: 1px solid var(--border-color);\n            border-top: none;\n            border-bottom-left-radius: 6px;\n            border-bottom-right-radius: 6px;\n            padding: 10px;\n            font-family: 'Courier New', Courier, monospace;\n            font-size: 0.85rem;\n            overflow-y: auto;\n            white-space: pre-wrap;\n            display: none; /* Hidden by default */\n        }\n        \n        .log-container.active { display: block; }\n\n        .log-entry { margin-bottom: 5px; border-bottom: 1px solid #222; padding-bottom: 2px; }\n        .log-info { color: #58a6ff; }\n        .log-success { color: #238636; }\n        .log-warn { color: #d29922; }\n        .log-error { color: #f85149; }\n        \n        .log-thought { color: var(--thought-color); font-style: italic; border-left: 2px solid var(--thought-color); padding-left: 10px; margin: 5px 0; }\n        .log-raw { color: var(--raw-color); font-size: 0.8rem; opacity: 0.8; }\n        .log-json { color: var(--success-color); font-weight: bold; }\n\n    </style>\n</head>\n<body>\n    <header>\n        <h1>Root Dreamer (Subconscious)</h1>\n        <div class=\"controls\">\n            <button id=\"btn-toggle\" class=\"active\">Wake Up</button>\n        </div>\n    </header>\n\n    <div class=\"status-panel\">\n        <div class=\"card\">\n            <div class=\"stat-value\" id=\"stat-processed\">0</div>\n            <div class=\"stat-label\">Memories Processed</div>\n        </div>\n        <div class=\"card\">\n            <div class=\"stat-value\" id=\"stat-synapses\">0</div>\n            <div class=\"stat-label\">Synapses Formed</div>\n        </div>\n        <div class=\"card\">\n            <div class=\"stat-value\" id=\"stat-model\">Loading...</div>\n            <div class=\"stat-label\">Model Status</div>\n        </div>\n    </div>\n\n    <div class=\"tabs\">\n        <div class=\"tab active\" data-target=\"log-main\">Stream</div>\n        <div class=\"tab\" data-target=\"log-thoughts\">Thoughts (Internal Monologue)</div>\n        <div class=\"tab\" data-target=\"log-synapses\">Synapses (Connections)</div>\n        <div class=\"tab\" data-target=\"log-raw\">Raw Protocol</div>\n    </div>\n\n    <div id=\"log-main\" class=\"log-container active\"></div>\n    <div id=\"log-thoughts\" class=\"log-container\"></div>\n    <div id=\"log-synapses\" class=\"log-container\"></div>\n    <div id=\"log-raw\" class=\"log-container\"></div>\n\n    <script type=\"module\">\n        import { SovereignLogger, createStore, getWebGPUConfig, initCozo } from './modules/sovereign.js';\n        import { CreateWebWorkerMLCEngine } from \"https://esm.run/@mlc-ai/web-llm\";\n\n        const logger = new SovereignLogger('Dreamer');\n        const MODEL_ID = \"Qwen2.5-1.5B-Instruct-q4f32_1-MLC\";\n        \n        // State\n        const store = createStore({\n            processedCount: 0,\n            synapseCount: 0,\n            isDreaming: false,\n            modelReady: false\n        });\n\n        // DOM Elements\n        const elProcessed = document.getElementById('stat-processed');\n        const elSynapses = document.getElementById('stat-synapses');\n        const elModel = document.getElementById('stat-model');\n        const elToggle = document.getElementById('btn-toggle');\n        \n        const logs = {\n            main: document.getElementById('log-main'),\n            thoughts: document.getElementById('log-thoughts'),\n            synapses: document.getElementById('log-synapses'),\n            raw: document.getElementById('log-raw')\n        };\n\n        // Tab Switching\n        document.querySelectorAll('.tab').forEach(t => {\n            t.addEventListener('click', () => {\n                document.querySelectorAll('.tab').forEach(x => x.classList.remove('active'));\n                document.querySelectorAll('.log-container').forEach(x => x.classList.remove('active'));\n                \n                t.classList.add('active');\n                document.getElementById(t.dataset.target).classList.add('active');\n            });\n        });\n\n        // Logging UI Helper\n        function appendLog(targetId, msg, type = 'info') {\n            const container = logs[targetId];\n            const div = document.createElement('div');\n            \n            // Special styling based on type\n            if (type === 'thought') div.className = 'log-thought';\n            else if (type === 'json') div.className = 'log-json';\n            else if (type === 'raw') div.className = 'log-raw';\n            else div.className = `log-entry log-${type}`;\n\n            // Timestamp for main stream only usually, but good for all\n            const ts = `[${new Date().toLocaleTimeString()}] `;\n            \n            if (type === 'thought' || type === 'json' || type === 'raw') {\n                div.textContent = msg; // Raw content for these\n            } else {\n                div.textContent = ts + msg;\n            }\n            \n            container.appendChild(div);\n            container.scrollTop = container.scrollHeight;\n        }\n\n        // Subscribe to state\n        store.subscribe((prop, val) => {\n            if (prop === 'processedCount') elProcessed.textContent = val;\n            if (prop === 'synapseCount') elSynapses.textContent = val;\n            if (prop === 'modelReady') elModel.textContent = val ? \"Ready\" : \"Loading...\";\n            if (prop === 'isDreaming') {\n                elToggle.textContent = val ? \"Sleep\" : \"Wake Up\";\n                elToggle.className = val ? \"active\" : \"\";\n            }\n        });\n\n        // Initialize Cozo\n        let db;\n        \n        async function init() {\n            try {\n                logger.info(\"Initializing Root Dreamer...\");\n                appendLog('main', \"Initializing CozoDB...\");\n                const CozoDb = await initCozo();\n                \n                try {\n                    db = await CozoDb.new_from_indexed_db('coda_memory', 'cozo_store', () => {});\n                    appendLog('main', \"Connected to Persistent Brain (coda_memory).\", 'success');\n                } catch (e) {\n                    logger.warn(`Persistence failed, falling back to RAM: ${e.message}`);\n                    db = CozoDb.new(); \n                    appendLog('main', \"Connected to Transient Brain (In-Memory).\", 'warn');\n                }\n                \n                // Ensure tables exist (idempotent)\n                await db.run(`\n                    :create memory {\n                        id: String,\n                        timestamp: Int,\n                        role: String,\n                        content: String,\n                        source: String,\n                        embedding: [F32; 384]?\n                    }\n                `);\n                \n                await db.run(`\n                    :create relationships {\n                        source_id: String,\n                        target_id: String,\n                        type: String,\n                        weight: Float\n                    }\n                `);\n\n                appendLog('main', \"CozoDB Ready.\");\n                \n                // Initialize LLM\n                appendLog('main', `Loading Model: ${MODEL_ID}...`);\n                const worker = new Worker('./modules/llm-worker.js', { type: 'module' });\n                window.engine = await CreateWebWorkerMLCEngine(worker, MODEL_ID, {\n                    initProgressCallback: (report) => {\n                        elModel.textContent = report.text;\n                        if (report.progress === 1) store.state.modelReady = true;\n                    }\n                });\n\n                appendLog('main', \"Model Loaded. Ready to dream.\");\n                store.state.modelReady = true;\n\n            } catch (e) {\n                logger.error(e.message);\n                appendLog('main', `Initialization Error: ${e.message}`, 'error');\n            }\n        }\n\n        // The Dream Loop\n        let isLoopRunning = false;\n        async function dreamLoop() {\n            if (isLoopRunning || !store.state.isDreaming) return;\n            if (!store.state.modelReady) {\n                await new Promise(r => setTimeout(r, 1000));\n                return dreamLoop();\n            }\n\n            isLoopRunning = true;\n            try {\n                // 1. Select Orphan\n                const query = `\n                    ?[id, content] := *memory{id, content}, \n                    not *relationships{source_id: id}\n                    :limit 1\n                `;\n                \n                const result = await db.run(query);\n                if (!result.ok) throw new Error(result.message);\n\n                if (result.rows.length === 0) {\n                    appendLog('main', \"No orphans found. Resting...\", 'info');\n                    await new Promise(r => setTimeout(r, 2000)); \n                    isLoopRunning = false;\n                    if (store.state.isDreaming) dreamLoop();\n                    return;\n                }\n\n                const [id, content] = result.rows[0];\n                appendLog('main', `Dreaming on memory: ${id}...`);\n                \n                // Truncate content\n                const safeContent = content.length > 3000 ? content.substring(0, 3000) + \"...\" : content;\n                \n                // 2. Deep Analysis Prompt\n                const prompt = `\nYou are the Subconscious. Deeply analyze this memory to find hidden patterns, abstract themes, and architectural implications.\nDon't just look at surface keywords. Dig deeper.\n\nStep 1: THOUGHTS. Discuss with yourself potential connections. Explore ambiguities. Ask \"Why is this here?\" and \"What does this imply?\".\nStep 2: JSON Extract 2-5 strongest concepts as a JSON array.\n\nFormat your response exactly like this:\n<thought>\n[Your internal monologue and deep analysis here]\n</thought>\n<json>\n[{\"target\": \"ConceptName\", \"type\": \"relates_to\", \"weight\": 0.9}]\n</json>\n\nMemory:\n${safeContent}\n                `.trim();\n\n                // Log Raw Request\n                appendLog('raw', `>>> PROMPT:\n${prompt}\n\n`, 'raw');\n\n                const response = await window.engine.chat.completions.create({\n                    messages: [{ role: \"user\", content: prompt }],\n                    temperature: 0.3, // Slightly higher for creativity in thoughts\n                    max_tokens: 1024\n                });\n                \n                const rawReply = response.choices[0].message.content;\n                appendLog('raw', `<<< REPLY:\n${rawReply}\n-----------------------------------\n`, 'raw');\n\n                // 3. Parse Output\n                const thoughtMatch = rawReply.match(/<thought>([\\s\\S]*?)<\\/thought>/);\n                const jsonMatch = rawReply.match(/<json>([\\s\\S]*?)<\\/json>/);\n\n                // Log Thoughts\n                if (thoughtMatch && thoughtMatch[1]) {\n                    appendLog('thoughts', `[Memory: ${id}]\n${thoughtMatch[1].trim()}`, 'thought');\n                } else {\n                    appendLog('thoughts', `[Memory: ${id}] (No internal monologue generated)`, 'warn');\n                }\n\n                // Parse JSON\n                let relationships = [];\n                try {\n                    let jsonStr = jsonMatch ? jsonMatch[1] : rawReply; // Fallback to raw if tags missing\n                    // Cleanup markdown\n                    jsonStr = jsonStr.replace(/```json/g, '').replace(/```/g, '').trim();\n                    relationships = JSON.parse(jsonStr);\n                    \n                    if (!Array.isArray(relationships)) throw new Error(\"Not an array\");\n                    \n                    appendLog('synapses', `[Memory: ${id}] Synthesized:\n${JSON.stringify(relationships, null, 2)}`, 'json');\n\n                } catch (parseErr) {\n                    appendLog('main', `Failed to parse dream JSON: ${parseErr.message}`, 'warn');\n                    // Mark processed to avoid loop\n                    relationships = [{ target: id, type: \"self_processed\", weight: 0.1 }];\n                }\n\n                // 4. Store\n                const rows = relationships.map(r => [id, r.target, r.type || 'relates_to', r.weight || 0.5]);\n                \n                if (rows.length > 0) {\n                    const insertQuery = `\n                        ?[src, tgt, type, w] <- $rows\n                        :put relationships {source_id: src, target_id: tgt, type: type, weight: w}\n                    `;\n                    \n                    const insertRes = await db.run(insertQuery, { rows });\n                    if (insertRes.ok) {\n                        store.state.processedCount++;\n                        store.state.synapseCount += rows.length;\n                        appendLog('main', `Synthesized ${rows.length} connections.`, 'success');\n                    }\n                }\n                \n                // Short pause\n                await new Promise(r => setTimeout(r, 2000));\n                \n            } catch (err) {\n                appendLog('main', `Dream Error: ${err.message}`, 'error');\n                await new Promise(r => setTimeout(r, 5000));\n            } finally {\n                isLoopRunning = false;\n            }\n            \n            // Re-trigger loop\n            if (store.state.isDreaming) dreamLoop();\n        }\n\n        // Toggle\n        elToggle.addEventListener('click', () => {\n            store.state.isDreaming = !store.state.isDreaming;\n            if (store.state.isDreaming) {\n                dreamLoop();\n            }\n        });\n\n        // Start\n        init();\n\n    </script>\n</body>\n</html>",
    "source": "tools\\root-dreamer.html"
  },
  {
    "id": "tools\\root-mic.html",
    "timestamp": 1766311214,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>Root Mic ðŸŽ™ï¸</title>\r\n    <style>\r\n        :root {\r\n            --bg-color: #0f0f11;\r\n            --surface-color: #1a1a1d;\r\n            --primary-color: #00ff88;\r\n            --accent-color: #00ccff;\r\n            --text-color: #eeeeee;\r\n            --danger-color: #ff4444;\r\n        }\r\n\r\n        body {\r\n            background-color: var(--bg-color);\r\n            color: var(--text-color);\r\n            font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;\r\n            margin: 0;\r\n            display: flex;\r\n            flex-direction: column;\r\n            align-items: center;\r\n            justify-content: center;\r\n            height: 100vh;\r\n            overflow: hidden;\r\n        }\r\n\r\n        .container {\r\n            text-align: center;\r\n            width: 100%;\r\n            max-width: 500px;\r\n            padding: 20px;\r\n        }\r\n\r\n        h1 {\r\n            font-weight: 300;\r\n            letter-spacing: 2px;\r\n            margin-bottom: 30px;\r\n            text-transform: uppercase;\r\n            font-size: 1.5rem;\r\n            color: var(--accent-color);\r\n            text-shadow: 0 0 10px rgba(0, 204, 255, 0.3);\r\n        }\r\n\r\n        #mic-btn {\r\n            width: 150px;\r\n            height: 150px;\r\n            border-radius: 50%;\r\n            background: radial-gradient(circle at 30% 30%, #444, #222);\r\n            border: 4px solid #333;\r\n            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.5), 0 0 0 4px var(--bg-color);\r\n            cursor: pointer;\r\n            transition: all 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);\r\n            display: flex;\r\n            align-items: center;\r\n            justify-content: center;\r\n            margin: 0 auto 30px;\r\n            position: relative;\r\n            outline: none;\r\n            -webkit-tap-highlight-color: transparent;\r\n        }\r\n\r\n        #mic-btn::after {\r\n            content: '';\r\n            position: absolute;\r\n            top: -10px;\r\n            left: -10px;\r\n            right: -10px;\r\n            bottom: -10px;\r\n            border-radius: 50%;\r\n            border: 2px solid var(--primary-color);\r\n            opacity: 0;\r\n            transform: scale(0.8);\r\n            transition: all 0.3s;\r\n        }\r\n\r\n        #mic-btn:hover {\r\n            transform: scale(1.05);\r\n            background: radial-gradient(circle at 30% 30%, #555, #333);\r\n        }\r\n\r\n        #mic-btn.active {\r\n            background: radial-gradient(circle at 30% 30%, #ff5555, #aa0000);\r\n            box-shadow: 0 0 30px rgba(255, 68, 68, 0.6);\r\n            border-color: #ff4444;\r\n            transform: scale(0.95);\r\n        }\r\n\r\n        #mic-btn.active::after {\r\n            animation: pulse 1.5s infinite;\r\n            opacity: 1;\r\n        }\r\n\r\n        #mic-icon {\r\n            font-size: 64px;\r\n            color: #888;\r\n            transition: color 0.3s;\r\n        }\r\n\r\n        #mic-btn.active #mic-icon {\r\n            color: white;\r\n        }\r\n\r\n        #clarify-btn {\r\n            background: transparent;\r\n            color: var(--accent-color);\r\n            border: 1px solid var(--accent-color);\r\n            padding: 8px 16px;\r\n            border-radius: 20px;\r\n            cursor: pointer;\r\n            font-size: 0.9rem;\r\n            margin-bottom: 20px;\r\n            transition: all 0.3s;\r\n            text-transform: uppercase;\r\n            letter-spacing: 1px;\r\n        }\r\n\r\n        #clarify-btn:hover:not(:disabled) {\r\n            background: rgba(0, 204, 255, 0.1);\r\n            transform: translateY(-2px);\r\n        }\r\n\r\n        #clarify-btn:disabled {\r\n            opacity: 0.3;\r\n            cursor: not-allowed;\r\n            border-color: #555;\r\n            color: #555;\r\n        }\r\n\r\n        #status {\r\n            font-size: 1.2rem;\r\n            margin-bottom: 20px;\r\n            height: 1.5em;\r\n            color: #888;\r\n        }\r\n\r\n        .visualizer {\r\n            width: 100%;\r\n            height: 60px;\r\n            background: var(--surface-color);\r\n            border-radius: 12px;\r\n            margin-bottom: 20px;\r\n            position: relative;\r\n            overflow: hidden;\r\n            border: 1px solid #333;\r\n        }\r\n\r\n        .bar-container {\r\n            display: flex;\r\n            align-items: center;\r\n            justify-content: center;\r\n            height: 100%;\r\n            gap: 2px;\r\n        }\r\n\r\n        .bar {\r\n            width: 4px;\r\n            background: var(--primary-color);\r\n            border-radius: 2px;\r\n            height: 4px;\r\n            transition: height 0.1s ease;\r\n        }\r\n\r\n        #output {\r\n            background: var(--surface-color);\r\n            padding: 20px;\r\n            border-radius: 12px;\r\n            border: 1px solid #333;\r\n            min-height: 100px;\r\n            text-align: left;\r\n            font-family: 'Courier New', monospace;\r\n            font-size: 0.9rem;\r\n            color: #ccc;\r\n            position: relative;\r\n            overflow-y: auto;\r\n            max-height: 200px;\r\n        }\r\n\r\n        #copy-toast {\r\n            position: absolute;\r\n            top: 20px;\r\n            right: 20px;\r\n            background: var(--primary-color);\r\n            color: #000;\r\n            padding: 8px 16px;\r\n            border-radius: 20px;\r\n            font-weight: bold;\r\n            opacity: 0;\r\n            transform: translateY(-20px);\r\n            transition: all 0.3s;\r\n            pointer-events: none;\r\n        }\r\n\r\n        #copy-toast.show {\r\n            opacity: 1;\r\n            transform: translateY(0);\r\n        }\r\n\r\n        footer {\r\n            margin-top: 40px;\r\n            font-size: 0.7rem;\r\n            color: #444;\r\n        }\r\n\r\n        @keyframes pulse {\r\n            0% {\r\n                transform: scale(1);\r\n                opacity: 1;\r\n                border-color: var(--danger-color);\r\n            }\r\n\r\n            100% {\r\n                transform: scale(1.5);\r\n                opacity: 0;\r\n                border-color: var(--danger-color);\r\n            }\r\n        }\r\n\r\n        #loading-overlay {\r\n            position: fixed;\r\n            top: 0;\r\n            left: 0;\r\n            width: 100%;\r\n            height: 100%;\r\n            background: rgba(0, 0, 0, 0.9);\r\n            display: flex;\r\n            flex-direction: column;\r\n            align-items: center;\r\n            justify-content: center;\r\n            z-index: 1000;\r\n            transition: opacity 0.5s;\r\n        }\r\n\r\n        .loader {\r\n            width: 48px;\r\n            height: 48px;\r\n            border: 5px solid #FFF;\r\n            border-bottom-color: var(--primary-color);\r\n            border-radius: 50%;\r\n            display: inline-block;\r\n            box-sizing: border-box;\r\n            animation: rotation 1s linear infinite;\r\n        }\r\n\r\n        .progress-text {\r\n            margin-top: 20px;\r\n            font-family: monospace;\r\n            color: var(--primary-color);\r\n        }\r\n\r\n        @keyframes rotation {\r\n            0% {\r\n                transform: rotate(0deg);\r\n            }\r\n\r\n            100% {\r\n                transform: rotate(360deg);\r\n            }\r\n        }\r\n    </style>\r\n</head>\r\n<body>\r\n    <div id=\"loading-overlay\">\r\n        <span class=\"loader\"></span>\r\n        <div id=\"loading-text\" class=\"progress-text\">Initializing Neural Engines...</div>\r\n    </div>\r\n    <div id=\"copy-toast\">Copied to Clipboard!</div>\r\n    <div class=\"container\">\r\n        <h1>Root Mic ðŸŽ™ï¸</h1>\r\n        <div class=\"visualizer\"><div class=\"bar-container\" id=\"bars\"></div></div>\r\n        <button id=\"mic-btn\"><div id=\"mic-icon\">ðŸŽ™ï¸</div></button>\r\n        <button id=\"clarify-btn\" disabled>Summarize & Clarify</button>\r\n        <div id=\"status\">Ready</div>\r\n        <div id=\"output\">...</div>\r\n        <footer>Running Locally: Whisper-Tiny (Audio) + Qwen2.5-1.5B (Text)</footer>\r\n    </div>\r\n\r\n    <script type=\"module\">\r\n        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.14.0';\r\n        import * as webllm from \"https://esm.run/@mlc-ai/web-llm\";\r\n        \r\n        // THE NEW KERNEL\r\n        import { SovereignLogger, createStore, getWebGPUConfig } from './modules/sovereign.js';\r\n\r\n        const logger = new SovereignLogger('Root-Mic');\r\n        \r\n        // Reactive Store\r\n        const { state, subscribe } = createStore({\r\n            status: 'Ready',\r\n            output: '...',\r\n            isLoading: true,\r\n            loadingText: 'Initializing Neural Engines...',\r\n            isRecording: false\r\n        });\r\n\r\n        // UI Bindings\r\n        subscribe((prop, val) => {\r\n            if (prop === 'status') document.getElementById('status').innerText = val;\r\n            if (prop === 'output') {\r\n                document.getElementById('output').innerText = val;\r\n                // Enable clarify button if there is text (and not just placeholder/loading)\r\n                const btn = document.getElementById('clarify-btn');\r\n                if (val && val !== '...' && val.length > 10) {\r\n                    btn.disabled = false;\r\n                } else {\r\n                    btn.disabled = true;\r\n                }\r\n            }\r\n            if (prop === 'loadingText') document.getElementById('loading-text').innerText = val;\r\n            if (prop === 'isLoading') {\r\n                const ol = document.getElementById('loading-overlay');\r\n                ol.style.opacity = val ? '1' : '0';\r\n                setTimeout(() => ol.style.display = val ? 'flex' : 'none', 500);\r\n            }\r\n            if (prop === 'isRecording') {\r\n                const btn = document.getElementById('mic-btn');\r\n                if (val) btn.classList.add('active'); else btn.classList.remove('active');\r\n            }\r\n        });\r\n\r\n        let whisperer = null;\r\n        let llmEngine = null;\r\n        let mediaRecorder = null;\r\n        let audioChunks = [];\r\n        let audioContext = null;\r\n        let analyser = null;\r\n        let dataArray = null;\r\n        let animationId = null;\r\n        let silenceStart = 0;\r\n\r\n        async function init() {\r\n            try {\r\n                // 1. Whisper Init\r\n                state.loadingText = \"Step 1/2: Downloading Whisper (Ears)...\";\r\n                env.allowLocalModels = false;\r\n                whisperer = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en', { device: 'wasm' });\r\n                logger.success(\"Whisper Loaded\");\r\n\r\n                // 2. LLM Init (Using Kernel)\r\n                state.loadingText = \"Step 2/2: Config Qwen2.5 (Brain)...\";\r\n                await initLLM();\r\n\r\n                state.isLoading = false;\r\n                initVisualizer();\r\n                logger.success(\"Root Mic Online\");\r\n            } catch (e) {\r\n                logger.error(e.message);\r\n                state.loadingText = `Error: ${e.message}`;\r\n            }\r\n        }\r\n\r\n        // Clarify Logic\r\n        document.getElementById('clarify-btn').addEventListener('click', async () => {\r\n            if (!state.output || state.output === '...' || state.output.length < 5) return;\r\n            \r\n            const originalText = state.output;\r\n            state.status = \"Summarizing...\";\r\n            state.output = originalText + \"\\n\\n[Thinking...]\";\r\n\r\n            try {\r\n                const reply = await llmEngine.chat.completions.create({\r\n                    messages: [\r\n                        { role: \"system\", content: \"You are a helpful assistant. Provide a concise summary and clarification of the user's text. Focus on the core meaning and intent.\" },\r\n                        { role: \"user\", content: `Please summarize and clarify this text:\\n\\n\"${originalText}\"` }\r\n                    ],\r\n                    temperature: 0.5,\r\n                    max_tokens: 512,\r\n                });\r\n\r\n                const summary = reply.choices[0].message.content;\r\n                state.output = summary; // Replace output with summary\r\n                state.status = \"Clarified\";\r\n                \r\n                if (document.hasFocus()) {\r\n                    navigator.clipboard.writeText(summary);\r\n                    const t = document.getElementById('copy-toast');\r\n                    t.innerText = \"Summary Copied!\";\r\n                    t.classList.add('show');\r\n                    setTimeout(() => { \r\n                        t.classList.remove('show');\r\n                        t.innerText = \"Copied to Clipboard!\";\r\n                    }, 2000);\r\n                }\r\n\r\n            } catch (e) {\r\n                logger.error(\"Clarify failed: \" + e.message);\r\n                state.status = \"Error\";\r\n                state.output = originalText; // Revert\r\n            }\r\n        });\r\n\r\n        async function initLLM() {\r\n            const modelId = \"mlc-ai/Qwen2.5-1.5B-Instruct-q4f16_1-MLC\";\r\n            const snapdragonId = \"snapdragon-mic-qwen\";\r\n\r\n            // KERNEL CALL: Get safe GPU config\r\n            const gpuConfig = await getWebGPUConfig('lite');\r\n            \r\n            if (gpuConfig.isConstrained) {\r\n                logger.warn(`Clamping Buffer to ${Math.round(gpuConfig.maxBufferSize/1024/1024)}MB for Mobile/XPS compatibility.`);\r\n            }\r\n\r\n            // Create device explicitly with limits\r\n            const device = await gpuConfig.adapter.requestDevice(gpuConfig.deviceConfig);\r\n\r\n            const appConfig = {\r\n                model_list: [{\r\n                    model: \"https://huggingface.co/\" + modelId + \"/resolve/main/\",\r\n                    model_id: snapdragonId,\r\n                    model_lib: \"https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm\",\r\n                    vram_required_MB: 2000,\r\n                    low_resource_required: true,\r\n                    buffer_size_required_bytes: gpuConfig.maxBufferSize\r\n                }]\r\n            };\r\n\r\n            llmEngine = await webllm.CreateMLCEngine(snapdragonId, {\r\n                appConfig,\r\n                device, \r\n                initProgressCallback: (report) => {\r\n                    state.loadingText = `Loading Brain: ${Math.round(report.progress * 100)}%`;\r\n                }\r\n            });\r\n        }\r\n\r\n        function initVisualizer() {\r\n            const container = document.getElementById('bars');\r\n            for (let i = 0; i < 30; i++) {\r\n                const bar = document.createElement('div');\r\n                bar.className = 'bar';\r\n                container.appendChild(bar);\r\n            }\r\n        }\r\n\r\n        // Recording Logic\r\n        document.getElementById('mic-btn').addEventListener('click', async () => {\r\n            if (!state.isRecording) startRecording(); else stopRecording();\r\n        });\r\n\r\n        async function startRecording() {\r\n            try {\r\n                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n                mediaRecorder = new MediaRecorder(stream);\r\n                audioChunks = [];\r\n                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);\r\n                mediaRecorder.onstop = processAudio;\r\n\r\n                // Visualizer\r\n                audioContext = new (window.AudioContext || window.webkitAudioContext)();\r\n                const source = audioContext.createMediaStreamSource(stream);\r\n                analyser = audioContext.createAnalyser();\r\n                analyser.fftSize = 64;\r\n                source.connect(analyser);\r\n                dataArray = new Uint8Array(analyser.frequencyBinCount);\r\n                animateVisualizer();\r\n\r\n                mediaRecorder.start();\r\n                state.isRecording = true;\r\n                silenceStart = Date.now();\r\n                state.status = \"Listening...\";\r\n                state.output = \"...\";\r\n            } catch (e) { alert(e.message); }\r\n        }\r\n\r\n        function stopRecording() {\r\n            mediaRecorder.stop();\r\n            state.isRecording = false;\r\n            state.status = \"Processing...\";\r\n            cancelAnimationFrame(animationId);\r\n            if (audioContext) audioContext.close();\r\n            document.querySelectorAll('.bar').forEach(b => b.style.height = '4px');\r\n        }\r\n\r\n        function animateVisualizer() {\r\n            if (!state.isRecording) return;\r\n            animationId = requestAnimationFrame(animateVisualizer);\r\n            analyser.getByteFrequencyData(dataArray);\r\n            const bars = document.querySelectorAll('.bar');\r\n            let maxVol = 0;\r\n            for (let i = 0; i < bars.length; i++) {\r\n                const val = dataArray[i];\r\n                if (val > maxVol) maxVol = val;\r\n                bars[i].style.height = `${Math.max(4, (val / 255) * 50)}px`;\r\n            }\r\n            if (maxVol > 10) silenceStart = Date.now();\r\n            else if (Date.now() - silenceStart > 3000) state.status = \"âš ï¸ No Audio?\";\r\n        }\r\n\r\n        async function processAudio() {\r\n            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); // Default browser format\r\n\r\n            // 1. Decode to System Sample Rate (e.g., 48000Hz)\r\n            const audioCtx = new AudioContext();\r\n            const arrayBuffer = await audioBlob.arrayBuffer();\r\n            const decodedBuffer = await audioCtx.decodeAudioData(arrayBuffer);\r\n\r\n            // 2. Resample to 16000Hz (Required by Whisper)\r\n            const targetRate = 16000;\r\n            const offlineCtx = new OfflineAudioContext(1, decodedBuffer.duration * targetRate, targetRate);\r\n            const source = offlineCtx.createBufferSource();\r\n            source.buffer = decodedBuffer;\r\n            source.connect(offlineCtx.destination);\r\n            source.start(0);\r\n            \r\n            const resampledBuffer = await offlineCtx.startRendering();\r\n            let audioData = resampledBuffer.getChannelData(0);\r\n\r\n            // NORMALIZE / AMPLIFY with Noise Gate\r\n            let peak = 0;\r\n            for (let i = 0; i < audioData.length; i++) {\r\n                const val = Math.abs(audioData[i]);\r\n                if (val > peak) peak = val;\r\n            }\r\n\r\n            // Cap amplification to avoid boosting silence/hiss into \"Applause\"\r\n            // If peak is TOO low (silence), don't amplify at all.\r\n            let ampFactor = 1.0;\r\n            if (peak > 0.01 && peak < 0.5) {\r\n                ampFactor = Math.min(0.5 / peak, 5.0); // Max 5x boost\r\n                for (let i = 0; i < audioData.length; i++) {\r\n                    audioData[i] = audioData[i] * ampFactor;\r\n                }\r\n            } else if (peak <= 0.01) {\r\n                // Too quiet, likely silence. Don't send to Whisper or send silence.\r\n                state.status = \"Too quiet (Ignored)\";\r\n                return;\r\n            }\r\n\r\n            state.status = \"Transcribing...\";\r\n            \r\n            // Enable chunking for long-form audio (>30s)\r\n            const result = await whisperer(audioData, { \r\n                language: 'english',\r\n                chunk_length_s: 30,\r\n                stride_length_s: 5\r\n            });\r\n            let rawText = result.text.trim();\r\n            \r\n            // Hallucination Filter (Aggressive)\r\n            const hallucinations = [\r\n                '[Music]', '[BLANK_AUDIO]', 'Computed', '*sigh*', '*breathing*', \r\n                'Applause', 'Thank you', 'Subtitles', 'Amara.org', 'Copyright', \r\n                'Â©', 'Caption', 'Sovereign' \r\n            ];\r\n            \r\n            hallucinations.forEach(h => { \r\n                // Case-insensitive check\r\n                const regex = new RegExp(h.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&'), 'gi');\r\n                rawText = rawText.replace(regex, '').trim();\r\n            });\r\n\r\n            // Filter single punctuation or very short junk\r\n            if (/^[.,?!;:]+$/.test(rawText) || rawText.length < 2) rawText = \"\";\r\n\r\n            if (!rawText || rawText.length < 1) {\r\n                state.status = \"Heard nothing\";\r\n                return;\r\n            }\r\n\r\n            state.output = `Raw: \"${rawText}\"\\n\\nCleaning...`;\r\n            state.status = \"Refining...\";\r\n\r\n            const reply = await llmEngine.chat.completions.create({\r\n                messages: [\r\n                    { role: \"system\", content: \"You are a verbatim transcription corrector. Your ONLY task is to fix grammar, spelling, and punctuation. Do NOT answer questions. Do NOT add commentary. Output ONLY the corrected text.\" },\r\n                    { role: \"user\", content: `Correct this text: \"${rawText}\"` }\r\n                ],\r\n                temperature: 0.3,\r\n                max_tokens: 512,\r\n            });\r\n\r\n            const cleanText = reply.choices[0].message.content;\r\n            state.output = cleanText;\r\n            state.status = \"Ready\";\r\n            \r\n            // Auto Copy (Handle focus requirement)\r\n            if (document.hasFocus()) {\r\n                navigator.clipboard.writeText(cleanText).then(() => {\r\n                    const t = document.getElementById('copy-toast');\r\n                    t.classList.add('show');\r\n                    setTimeout(() => t.classList.remove('show'), 2000);\r\n                }).catch(err => {\r\n                    console.warn(\"Clipboard write failed (focus lost?):\", err);\r\n                });\r\n            } else {\r\n                console.warn(\"Clipboard write skipped: Document not focused.\");\r\n                state.output += \"\\n(Copy skipped - Click to copy)\";\r\n            }\r\n        }\r\n\r\n        init();\r\n    </script>\r\n</body>\r\n</html>\r\n",
    "source": "tools\\root-mic.html"
  },
  {
    "id": "tools\\sovereign-db-builder.html",
    "timestamp": 1766356737,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <title>Root Memory Builder</title>\r\n    <style>\r\n        :root {\r\n            --bg: #1e1e1e;\r\n            --text: #e0e0e0;\r\n            --accent: #00ff88;\r\n            --danger: #ff4444;\r\n            --warn: #ffc107;\r\n            --surface: #252526;\r\n        }\r\n\r\n        body {\r\n            font-family: 'Segoe UI', sans-serif;\r\n            background: var(--bg);\r\n            color: var(--text);\r\n            padding: 20px;\r\n            max-width: 800px;\r\n            margin: 0 auto;\r\n        }\r\n\r\n        h1 {\r\n            border-bottom: 1px solid #333;\r\n            padding-bottom: 10px;\r\n            color: var(--accent);\r\n            font-weight: 300;\r\n            letter-spacing: 1px;\r\n        }\r\n\r\n        .drop-zone {\r\n            border: 2px dashed #444;\r\n            padding: 40px;\r\n            text-align: center;\r\n            margin: 20px 0;\r\n            border-radius: 8px;\r\n            transition: all 0.3s;\r\n            cursor: pointer;\r\n            background: #111;\r\n        }\r\n\r\n        .drop-zone:hover {\r\n            border-color: var(--accent);\r\n            background: var(--surface);\r\n        }\r\n\r\n        .log-area {\r\n            background: #111;\r\n            border: 1px solid #333;\r\n            padding: 10px;\r\n            height: 300px;\r\n            overflow-y: auto;\r\n            font-family: 'Consolas', monospace;\r\n            font-size: 0.85rem;\r\n            color: #aaa;\r\n            border-radius: 4px;\r\n        }\r\n\r\n        button {\r\n            background: #333;\r\n            color: white;\r\n            border: 1px solid #555;\r\n            padding: 10px 20px;\r\n            border-radius: 4px;\r\n            cursor: pointer;\r\n            font-size: 0.9rem;\r\n            margin-right: 10px;\r\n            transition: all 0.2s;\r\n        }\r\n\r\n        button:hover {\r\n            border-color: var(--accent);\r\n            color: var(--accent);\r\n        }\r\n\r\n        button:disabled {\r\n            background: #222;\r\n            color: #555;\r\n            border-color: #333;\r\n            cursor: not-allowed;\r\n        }\r\n\r\n        button.primary {\r\n            background: var(--accent);\r\n            color: #000;\r\n            border: none;\r\n        }\r\n\r\n        button.primary:hover {\r\n            background: #00cc6a;\r\n        }\r\n\r\n        button.danger {\r\n            background: var(--danger);\r\n            border-color: var(--danger);\r\n        }\r\n\r\n        button.danger:hover {\r\n            background: #cc0000;\r\n        }\r\n\r\n        .stat-box {\r\n            display: flex;\r\n            gap: 20px;\r\n            margin-bottom: 20px;\r\n        }\r\n\r\n        .stat {\r\n            background: var(--surface);\r\n            padding: 15px;\r\n            border-radius: 6px;\r\n            flex: 1;\r\n            text-align: center;\r\n            border: 1px solid #333;\r\n        }\r\n\r\n        .stat-val {\r\n            font-size: 1.5rem;\r\n            font-weight: bold;\r\n            display: block;\r\n            margin-bottom: 5px;\r\n        }\r\n\r\n        .stat-label {\r\n            font-size: 0.8rem;\r\n            color: #888;\r\n            text-transform: uppercase;\r\n        }\r\n\r\n        textarea {\r\n            width: 100%;\r\n            height: 60px;\r\n            background: #111;\r\n            color: #e0e0e0;\r\n            border: 1px solid #555;\r\n            padding: 10px;\r\n            border-radius: 4px;\r\n            resize: vertical;\r\n            margin-bottom: 10px;\r\n            font-family: inherit;\r\n        }\r\n\r\n        textarea:focus {\r\n            outline: none;\r\n            border-color: var(--accent);\r\n        }\r\n    </style>\r\n</head>\r\n\r\n<body>\r\n\r\n    <h1>ðŸŒ± Root Memory Builder</h1>\r\n    <p>Ingest session logs into your local Root Graph.</p>\r\n\r\n    <div class=\"stat-box\">\r\n        <div class=\"stat\">\r\n            <span id=\"db-status\" class=\"stat-val\" style=\"color: #ff6b6b\">Offline</span>\r\n            <span class=\"stat-label\">Status</span>\r\n        </div>\r\n        <div class=\"stat\">\r\n            <span id=\"mem-count\" class=\"stat-val\">0</span>\r\n            <span class=\"stat-label\">Memories</span>\r\n        </div>\r\n        <div class=\"stat\">\r\n            <span id=\"vec-status\" class=\"stat-val\">Loading...</span>\r\n            <span class=\"stat-label\">Embedder</span>\r\n        </div>\r\n    </div>\r\n\r\n    <div class=\"drop-zone\" id=\"drop-zone\">\r\n        Drag & Drop <code>combined_memory.json</code>, logs, or text files here<br>\r\n        <small style=\"color: #666\">JSON, MD, TXT, PY, JS, HTML</small>\r\n    </div>\r\n    <input type=\"file\" id=\"file-input\" multiple style=\"display:none\">\r\n\r\n    <!-- Quick Add Section -->\r\n    <div style=\"margin: 20px 0; padding: 20px; border: 1px solid #333; background: var(--surface); border-radius: 8px;\">\r\n        <h3 style=\"margin-top: 0; font-weight: 300;\">ðŸ“ Quick Add</h3>\r\n        <textarea id=\"quick-mem-content\" placeholder=\"Type a memory here (e.g. 'Project X password is...')\"></textarea>\r\n        <div style=\"text-align: right;\">\r\n            <button id=\"quick-add-btn\" class=\"primary\">Add to Graph</button>\r\n        </div>\r\n    </div>\r\n\r\n    <div style=\"margin-bottom: 10px; display: flex; gap: 10px; flex-wrap: wrap;\">\r\n        <button id=\"auto-import-btn\" disabled title=\"Import from ./cozo_import_memory.json\">Auto-Import</button>\r\n        <button id=\"export-db-btn\" disabled>Export JSON</button>\r\n        <button id=\"query-btn\" disabled>Test Query</button>\r\n        <div style=\"flex-grow: 1\"></div>\r\n        <button id=\"reset-btn\" class=\"danger\" disabled>Nuke Database</button>\r\n    </div>\r\n\r\n    <div class=\"log-area\" id=\"logs\"></div>\r\n\r\n    <script type=\"module\">\r\n        import { SovereignLogger, initCozo, createStore } from './modules/sovereign.js';\r\n        import { loadAllFromIndexedDb, closeDatabase, clearIndexedDbStore, flushPendingWrites } from './indexeddb.js';\r\n        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.16.0';\r\n\r\n        env.allowLocalModels = false;\r\n\r\n        // --- 0. KERNEL SETUP ---\r\n        const logger = new SovereignLogger('Root-Builder');\r\n\r\n        // Wrap logger to output to DOM as well\r\n        const originalInfo = logger.info.bind(logger);\r\n        logger.info = (msg) => { originalInfo(msg); appendLog(msg, 'info'); };\r\n\r\n        const originalWarn = logger.warn.bind(logger);\r\n        logger.warn = (msg) => { originalWarn(msg); appendLog(msg, 'warn'); };\r\n\r\n        const originalError = logger.error.bind(logger);\r\n        logger.error = (msg) => { originalError(msg); appendLog(msg, 'error'); };\r\n\r\n        const originalSuccess = logger.success.bind(logger);\r\n        logger.success = (msg) => { originalSuccess(msg); appendLog(msg, 'success'); };\r\n\r\n        function appendLog(msg, type) {\r\n            const logs = document.getElementById('logs');\r\n            const line = document.createElement('div');\r\n            const time = new Date().toLocaleTimeString();\r\n            line.textContent = `[${time}] ${msg}`;\r\n            if (type === 'error') line.style.color = '#ff6b6b';\r\n            if (type === 'success') line.style.color = '#00ff88';\r\n            if (type === 'warn') line.style.color = '#ffc107';\r\n            logs.appendChild(line);\r\n            logs.scrollTop = logs.scrollHeight;\r\n        }\r\n\r\n        const { state, subscribe } = createStore({\r\n            dbStatus: 'Offline',\r\n            dbColor: '#ff6b6b',\r\n            memCount: 0,\r\n            embedderStatus: 'Loading...',\r\n            embedderColor: '#ffc107',\r\n            isReady: false\r\n        });\r\n\r\n        // UI Bindings\r\n        subscribe((prop, val) => {\r\n            if (prop === 'dbStatus') {\r\n                const el = document.getElementById('db-status');\r\n                el.innerText = val;\r\n                el.style.color = state.dbColor;\r\n            }\r\n            if (prop === 'memCount') document.getElementById('mem-count').innerText = val;\r\n            if (prop === 'embedderStatus') {\r\n                const el = document.getElementById('vec-status');\r\n                el.innerText = val;\r\n                el.style.color = state.embedderColor;\r\n            }\r\n            if (prop === 'isReady' && val === true) {\r\n                document.getElementById('auto-import-btn').disabled = false;\r\n                document.getElementById('export-db-btn').disabled = false;\r\n                document.getElementById('reset-btn').disabled = false;\r\n                document.getElementById('query-btn').disabled = false;\r\n            }\r\n        });\r\n\r\n        let db;\r\n        let embedder;\r\n        let CozoDbClass;\r\n\r\n        // --- 1. INITIALIZATION ---\r\n        async function init() {\r\n            try {\r\n                logger.info(\"Initializing Root Kernel...\");\r\n\r\n                // Load Cozo WASM via Kernel\r\n                CozoDbClass = await initCozo('./cozo_lib_wasm_bg.wasm');\r\n\r\n                // Probe IndexedDB (Recovery Logic)\r\n                try {\r\n                    const [keys, items] = await loadAllFromIndexedDb('coda_memory', 'cozo_store', () => { });\r\n                    logger.info(`Storage Probe: Found ${keys.length} items in persistence layer.`);\r\n                    closeDatabase(); // Important: Release lock\r\n\r\n                    // Try Persistent Load\r\n                    try {\r\n                        const dbPromise = CozoDbClass.new_from_indexed_db('coda_memory', 'cozo_store', () => { });\r\n                        // Timeout protection\r\n                        const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error('DB Load Timeout')), 5000));\r\n                        db = await Promise.race([dbPromise, timeoutPromise]);\r\n\r\n                        state.dbStatus = \"Active (Persistent)\";\r\n                        state.dbColor = \"#00ff88\";\r\n                        logger.success(\"Root Graph Online (Persistent).\");\r\n                    } catch (e) {\r\n                        logger.warn(`Persistence load failed: ${e.message}. Clearing corruption...`);\r\n                        await clearIndexedDbStore('coda_memory', 'cozo_store');\r\n                        // Fallback to In-Memory\r\n                        db = CozoDbClass.new();\r\n                        state.dbStatus = \"Active (Memory-Only)\";\r\n                        state.dbColor = \"#ffc107\";\r\n                        logger.warn(\"Fallback to In-Memory DB. Data will not be saved.\");\r\n                    }\r\n\r\n                } catch (e) {\r\n                    logger.warn(\"Storage probe failed. Creating fresh in-memory DB.\");\r\n                    db = CozoDbClass.new();\r\n                    state.dbStatus = \"Active (Memory-Only)\";\r\n                    state.dbColor = \"#ffc107\";\r\n                }\r\n\r\n                // Global Exposure for Debugging\r\n                window.db = db;\r\n                window.runQuery = safeRun;\r\n\r\n                // Load Embedder\r\n                pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2').then(pipe => {\r\n                    embedder = pipe;\r\n                    state.embedderStatus = \"Ready\";\r\n                    state.embedderColor = \"#00ff88\";\r\n                    logger.success(\"Neural Embedder Loaded.\");\r\n                }).catch(e => {\r\n                    state.embedderStatus = \"Error\";\r\n                    state.embedderColor = \"#ff4444\";\r\n                    logger.error(`Embedder failed: ${e.message}`);\r\n                });\r\n\r\n                // Schema Sync\r\n                await ensureSchema();\r\n                await updateStats();\r\n                state.isReady = true;\r\n\r\n            } catch (e) {\r\n                logger.error(`CRITICAL FAILURE: ${e.message}`);\r\n            }\r\n        }\r\n\r\n        async function safeRun(query, params = \"{}\") {\r\n            if (!db) throw new Error(\"DB offline\");\r\n            const res = await db.run(query, params);\r\n            let parsed = res;\r\n            if (typeof res === 'string') {\r\n                try { parsed = JSON.parse(res); } catch (e) { }\r\n            }\r\n            if (parsed && parsed.ok === false) throw new Error(parsed.message);\r\n            return parsed;\r\n        }\r\n\r\n        async function ensureSchema() {\r\n            try {\r\n                // 1. Check if table exists\r\n                await safeRun(\"?[id] := *memory{id} :limit 1\", \"{}\");\r\n\r\n                // 2. Migration: Try to add new columns if they don't exist\r\n                // (CozoDB ignores 'add' if column exists or throws specific error, we catch to be safe)\r\n                try { await safeRun(\"::alter memory add mime_type: String?\", \"{}\"); } catch (e) { }\r\n                try { await safeRun(\"::alter memory add blob_ref: String?\", \"{}\"); } catch (e) { }\r\n\r\n            } catch (e) {\r\n                logger.warn(\"Schema missing. Creating Root Graph schema...\");\r\n                await safeRun(`\r\n                    :create memory {\r\n                        id: String =>\r\n                        timestamp: Int,\r\n                        role: String,\r\n                        content: String,\r\n                        source: String,\r\n                        embedding: <F32; 384>,\r\n                        mime_type: String?,\r\n                        blob_ref: String?\r\n                    }\r\n                `, \"{}\");\r\n                logger.success(\"Schema Created.\");\r\n            }\r\n        }\r\n\r\n        async function updateStats() {\r\n            try {\r\n                const res = await safeRun(`?[count(id)] := *memory{id}`, \"{}\");\r\n                if (res.rows && res.rows.length) state.memCount = res.rows[0][0];\r\n            } catch (e) { }\r\n        }\r\n\r\n        // --- 2. INGESTION LOGIC ---\r\n        const SOV_BATCH_SIZE = 50;\r\n\r\n        async function handleFiles(files) {\r\n            if (!embedder || !db) return logger.error(\"System not ready.\");\r\n            for (const file of files) {\r\n                logger.info(`Reading ${file.name} (${file.type || 'unknown'})...`);\r\n                try {\r\n                    let records = [];\r\n\r\n                    // Binary Handling (Images/Audio)\r\n                    if (file.type.startsWith('image/') || file.type.startsWith('audio/')) {\r\n                        records = [{\r\n                            role: 'user',\r\n                            source: file.name,\r\n                            timestamp: file.lastModified,\r\n                            content: `[BINARY_REF] ${file.name}`, // Placeholder for text search\r\n                            mime_type: file.type,\r\n                            blob_ref: file.name\r\n                        }];\r\n                    }\r\n                    // Text Handling\r\n                    else {\r\n                        const text = await file.text();\r\n\r\n                        if (file.name.endsWith('.json')) {\r\n                            const json = JSON.parse(text);\r\n                            if (Array.isArray(json)) records = json;\r\n                            else if (json.conversations) records = json.conversations;\r\n                            else if (json.relations) {\r\n                                // Extract rows logic simplified\r\n                                const mem = json.relations.find(r => r.name === 'memory') || json.relations[0];\r\n                                if (mem) {\r\n                                    const hdr = mem.headers || ['id', 'timestamp', 'role', 'content', 'source', 'embedding'];\r\n                                    records = (mem.rows || []).map(r => {\r\n                                        const obj = {};\r\n                                        hdr.forEach((h, i) => obj[h] = r[i]);\r\n                                        return obj;\r\n                                    });\r\n                                }\r\n                            }\r\n                        } else {\r\n                            // Text file\r\n                            records = [{\r\n                                role: 'system',\r\n                                source: file.name,\r\n                                timestamp: file.lastModified,\r\n                                content: text\r\n                            }];\r\n                        }\r\n                    }\r\n\r\n                    await processRecords(records, file.name);\r\n                } catch (e) {\r\n                    logger.error(`Failed ${file.name}: ${e.message}`);\r\n                }\r\n            }\r\n            await updateStats();\r\n        }\r\n\r\n        async function processRecords(records, sourceName) {\r\n            let batch = [];\r\n            for (const rec of records) {\r\n                let content = rec.content || rec.message || \"\";\r\n                if (!content) continue;\r\n                if (content.length > 20000) content = content.substring(0, 20000) + \"...[TRUNCATED]\";\r\n\r\n                let embedding = rec.embedding || [];\r\n                if (!embedding.length) {\r\n                    const out = await embedder(content, { pooling: 'mean', normalize: true });\r\n                    embedding = Array.from(out.data);\r\n                }\r\n\r\n                const ts = rec.timestamp ? new Date(rec.timestamp).getTime() : Date.now();\r\n                const id = `${ts}-${Math.random().toString(36).substr(2, 9)}`;\r\n\r\n                const mime = rec.mime_type || null;\r\n                const ref = rec.blob_ref || null;\r\n\r\n                batch.push([id, ts, rec.role || 'unknown', content, rec.source || sourceName, embedding, mime, ref]);\r\n\r\n                if (batch.length >= SOV_BATCH_SIZE) {\r\n                    await insertBatch(batch);\r\n                    batch = [];\r\n                }\r\n            }\r\n            if (batch.length) await insertBatch(batch);\r\n            try { await flushPendingWrites(); } catch (e) { }\r\n            logger.success(`Imported ${records.length} items from ${sourceName}`);\r\n        }\r\n\r\n        async function insertBatch(rows) {\r\n            const q = `?[id, ts, role, content, src, vec, mime, ref] <- $data :put memory { id, timestamp: ts, role, content, source: src, embedding: vec, mime_type: mime, blob_ref: ref }`;\r\n            await safeRun(q, JSON.stringify({ data: rows }));\r\n        }\r\n\r\n        // --- 3. EVENT LISTENERS ---\r\n        document.getElementById('drop-zone').addEventListener('click', () => document.getElementById('file-input').click());\r\n        document.getElementById('file-input').addEventListener('change', (e) => handleFiles(e.target.files));\r\n\r\n        document.getElementById('drop-zone').addEventListener('dragover', (e) => { e.preventDefault(); e.target.style.borderColor = '#00ff88'; });\r\n        document.getElementById('drop-zone').addEventListener('drop', (e) => { e.preventDefault(); e.target.style.borderColor = '#444'; handleFiles(e.dataTransfer.files); });\r\n\r\n        document.getElementById('quick-add-btn').addEventListener('click', async () => {\r\n            const val = document.getElementById('quick-mem-content').value.trim();\r\n            if (!val) return;\r\n            await processRecords([{ role: 'manual', content: val, source: 'user_input' }], 'QuickAdd');\r\n            document.getElementById('quick-mem-content').value = \"\";\r\n            await updateStats();\r\n        });\r\n\r\n        document.getElementById('reset-btn').addEventListener('click', async () => {\r\n            if (confirm(\"NUKE DATABASE? This destroys all data.\")) {\r\n                await clearIndexedDbStore('coda_memory', 'cozo_store');\r\n                location.reload();\r\n            }\r\n        });\r\n\r\n        document.getElementById('query-btn').addEventListener('click', async () => {\r\n            try {\r\n                const res = await safeRun(\"?[ts, content] := *memory{timestamp: ts, content} :sort -ts :limit 5\");\r\n                if (res.rows) logger.info(\"Recent:\\n\" + res.rows.map(r => `${new Date(r[0]).toLocaleTimeString()}: ${r[1].substring(0, 50)}...`).join('\\n'));\r\n                else logger.warn(\"No rows returned.\");\r\n            } catch (e) { logger.error(e.message); }\r\n        });\r\n\r\n        document.getElementById('auto-import-btn').addEventListener('click', async () => {\r\n            try {\r\n                const res = await fetch('./cozo_import_memory.json');\r\n                const json = await res.json();\r\n                let recs = Array.isArray(json) ? json : (json.conversations || []);\r\n                if (recs.length) await processRecords(recs, 'auto-import');\r\n                else logger.warn(\"No records found in auto-import file.\");\r\n            } catch (e) { logger.error(e.message); }\r\n        });\r\n\r\n        document.getElementById('export-db-btn').addEventListener('click', async () => {\r\n            try {\r\n                logger.info(\"Exporting Root Memory...\");\r\n                // Export the 'memory' relation including vectors\r\n                const jsonStr = await db.export_relations(JSON.stringify({relations: [\"memory\"]}));\r\n                \r\n                // Create Blob and Download\r\n                const blob = new Blob([jsonStr], {type: \"application/json\"});\r\n                const url = URL.createObjectURL(blob);\r\n                const a = document.createElement('a');\r\n                a.href = url;\r\n                a.download = `root_coda_memory_dump_${Date.now()}.json`;\r\n                document.body.appendChild(a);\r\n                a.click();\r\n                document.body.removeChild(a);\r\n                URL.revokeObjectURL(url);\r\n                \r\n                logger.success(\"Export Complete. You can now drag this file into another Root Coda instance.\");\r\n            } catch (e) {\r\n                logger.error(\"Export Failed: \" + e.message);\r\n            }\r\n        });\r\n\r\n        init();\r\n    </script>\r\n</body>\r\n\r\n</html>",
    "source": "tools\\sovereign-db-builder.html"
  },
  {
    "id": "tools\\start-bridge.bat",
    "timestamp": 1766171656,
    "role": "file",
    "content": "@echo off\r\necho Starting WebGPU Bridge...\r\necho This bridge allows external tools (like Wave Terminal) to talk to the browser.\r\necho.\r\npython webgpu_bridge.py\r\npause\r\n",
    "source": "tools\\start-bridge.bat"
  },
  {
    "id": "tools\\webgpu-server-chat.html",
    "timestamp": 1766171656,
    "role": "file",
    "content": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <title>WebGPU Chat Server (Worker)</title>\r\n    <style>\r\n        body {\r\n            background: #001;\r\n            color: #0f0;\r\n            font-family: monospace;\r\n            padding: 20px;\r\n        }\r\n\r\n        .log {\r\n            margin-top: 10px;\r\n            color: #8c8;\r\n            font-size: 0.9em;\r\n        }\r\n\r\n        .success {\r\n            color: #0f0;\r\n        }\r\n\r\n        .error {\r\n            color: #f00;\r\n        }\r\n\r\n        #status {\r\n            font-weight: bold;\r\n            font-size: 1.2em;\r\n            margin-bottom: 20px;\r\n        }\r\n\r\n        input,\r\n        select {\r\n            background: #222;\r\n            color: #fff;\r\n            border: 1px solid #444;\r\n            padding: 5px;\r\n        }\r\n\r\n        button {\r\n            background: #060;\r\n            color: #fff;\r\n            border: none;\r\n            padding: 5px 15px;\r\n            cursor: pointer;\r\n        }\r\n    </style>\r\n</head>\r\n\r\n<body>\r\n    <div id=\"status\">ðŸ”´ Disconnected</div>\r\n    <div>\r\n        <label>Chat Model:</label>\r\n        <input type=\"text\" id=\"model-input\" value=\"Qwen2.5-1.5B-Instruct-q4f16_1-MLC\" style=\"width: 400px;\">\r\n        <!-- Common options helper -->\r\n        <select id=\"model-helper\" onchange=\"document.getElementById('model-input').value = this.value\">\r\n            <option value=\"\">-- Presets --</option>\r\n            <option value=\"Qwen2.5-1.5B-Instruct-q4f16_1-MLC\">Qwen2.5-1.5B (Fast)</option>\r\n            <option value=\"Qwen2.5-7B-Instruct-q4f16_1-MLC\">Qwen2.5-7B (Balanced)</option>\r\n            <option value=\"DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC\">DeepSeek-R1-7B</option>\r\n            <option value=\"DeepSeek-V2-Lite-Chat-q4f16_1-MLC\">DeepSeek-V2-Lite</option>\r\n            <option value=\"Llama-3.1-8B-Instruct-q4f32_1-MLC\">Llama-3.1-8B</option>\r\n        </select>\r\n    </div>\r\n    <div style=\"margin-top: 10px;\">\r\n        <label>Bridge URL:</label>\r\n        <input type=\"text\" id=\"bridge-url\" value=\"ws://localhost:8080/ws/chat\" style=\"width: 300px;\">\r\n        <button id=\"connect-btn\">Start Server</button>\r\n    </div>\r\n    <div id=\"logs\" style=\"margin-top: 20px; border-top: 1px solid #333;\"></div>\r\n\r\n    <script type=\"module\">\r\n        import { CreateMLCEngine } from \"https://esm.run/@mlc-ai/web-llm\";\r\n\r\n        const statusDiv = document.getElementById('status');\r\n        const logsDiv = document.getElementById('logs');\r\n        const connectBtn = document.getElementById('connect-btn');\r\n        const modelInput = document.getElementById('model-input');\r\n\r\n        let engine = null;\r\n        let ws = null;\r\n\r\n        function log(msg, type = 'log') {\r\n            const div = document.createElement('div');\r\n            div.className = type;\r\n            div.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;\r\n            logsDiv.prepend(div);\r\n        }\r\n\r\n        connectBtn.onclick = async () => {\r\n            connectBtn.disabled = true;\r\n            const model = modelInput.value;\r\n\r\n            try {\r\n                log(`Loading WebGPU Engine (${model})...`);\r\n                engine = await CreateMLCEngine(model, {\r\n                    initProgressCallback: (report) => {\r\n                        statusDiv.textContent = `ðŸŸ¡ Loading Model: ${report.text}`;\r\n                    }\r\n                });\r\n                log(\"Engine Loaded.\", \"success\");\r\n\r\n                connectWebSocket();\r\n            } catch (e) {\r\n                log(`Engine Load Failed: ${e.message}`, \"error\");\r\n                connectBtn.disabled = false;\r\n            }\r\n        };\r\n\r\n        function connectWebSocket() {\r\n            const bridgeUrl = document.getElementById('bridge-url').value;\r\n            log(`Connecting to Bridge (${bridgeUrl})...`);\r\n            ws = new WebSocket(bridgeUrl);\r\n\r\n            ws.onopen = () => {\r\n                statusDiv.textContent = \"ðŸŸ¢ Bridge Connected (Ready for Requests)\";\r\n                log(\"Bridge Connected.\", \"success\");\r\n            };\r\n\r\n            ws.onclose = () => {\r\n                statusDiv.textContent = \"ðŸ”´ Disconnected\";\r\n                log(\"Bridge Disconnected. Retrying in 3s...\", \"error\");\r\n                setTimeout(connectWebSocket, 3000);\r\n            };\r\n\r\n            ws.onmessage = async (event) => {\r\n                const msg = JSON.parse(event.data);\r\n                if (msg.type === 'chat') {\r\n                    handleChatRequest(msg.id, msg.data);\r\n                }\r\n            };\r\n        }\r\n\r\n        async function handleChatRequest(reqId, data) {\r\n            log(`Chat Request ${reqId.slice(0, 8)}...`);\r\n            try {\r\n                // OpenAI Compatibility Mapping\r\n                const messages = data.messages;\r\n                const stream = data.stream !== false; // Default to true if undefined\r\n\r\n                const completion = await engine.chat.completions.create({\r\n                    messages,\r\n                    stream: true,\r\n                    temperature: data.temperature || 0.7,\r\n                    max_tokens: data.max_tokens || 4096\r\n                });\r\n\r\n                for await (const chunk of completion) {\r\n                    // Forward chunk to bridge\r\n                    ws.send(JSON.stringify({\r\n                        id: reqId,\r\n                        chunk: chunk\r\n                    }));\r\n                }\r\n\r\n                // Signal done\r\n                ws.send(JSON.stringify({\r\n                    id: reqId,\r\n                    done: true\r\n                }));\r\n\r\n                log(`Request ${reqId.slice(0, 8)} Complete.`, \"success\");\r\n\r\n            } catch (e) {\r\n                log(`Request Failed: ${e.message}`, \"error\");\r\n                if (ws && ws.readyState === WebSocket.OPEN) {\r\n                    ws.send(JSON.stringify({ id: reqId, error: e.message }));\r\n                }\r\n            }\r\n        }\r\n    </script>\r\n</body>\r\n\r\n</html>",
    "source": "tools\\webgpu-server-chat.html"
  },
  {
    "id": "tools\\webgpu_bridge.py",
    "timestamp": 1766240083,
    "role": "file",
    "content": "import asyncio\r\nimport uvicorn\r\nimport json\r\nimport uuid\r\nimport os\r\nimport time\r\nfrom collections import deque\r\nfrom fastapi import FastAPI, WebSocket, Request, HTTPException\r\nfrom fastapi.responses import StreamingResponse, JSONResponse\r\nfrom fastapi.middleware.cors import CORSMiddleware\r\nfrom typing import Dict, Any\r\n\r\napp = FastAPI(title=\"WebGPU Bridge\")\r\n\r\napp.add_middleware(\r\n    CORSMiddleware,\r\n    allow_origins=[\"*\"],\r\n    allow_methods=[\"*\"],\r\n    allow_headers=[\"*\"],\r\n)\r\n\r\n# Store active WebSocket connections\r\n# We use a simple single-worker model for now (one browser tab per role)\r\nworkers: Dict[str, WebSocket] = {\r\n    \"chat\": None,\r\n    \"embed\": None\r\n}\r\n\r\n# Store pending response futures\r\n# Map: request_id -> asyncio.Queue\r\nactive_requests: Dict[str, asyncio.Queue] = {}\r\n\r\n# --- Logging / observability ---\r\n# Keep a ring buffer of recent bridge logs for the HTML log viewer.\r\n_LOG_MAX_LINES = int(os.getenv(\"BRIDGE_LOG_MAX_LINES\", \"5000\"))\r\n_LOG_MAX_CHARS_PER_LINE = int(os.getenv(\"BRIDGE_LOG_MAX_CHARS_PER_LINE\", \"400\"))\r\n# If enabled, log streamed content deltas (can be noisy but is what you want for prompt-pipeline debugging)\r\n_LOG_STREAM_DELTAS = os.getenv(\"BRIDGE_LOG_STREAM_DELTAS\", \"true\").strip().lower() in (\"1\", \"true\", \"yes\", \"on\")\r\n\r\n_bridge_logs: deque[tuple[int, str]] = deque(maxlen=_LOG_MAX_LINES)\r\n_bridge_log_seq: int = 0\r\n\r\n# Per-request telemetry (timing/throughput)\r\n_req_meta: Dict[str, Dict[str, Any]] = {}\r\n\r\n\r\ndef _clip(s: str, max_chars: int) -> str:\r\n    if s is None:\r\n        return \"\"\r\n    s = str(s)\r\n    if len(s) <= max_chars:\r\n        return s\r\n    return s[: max_chars - 1] + \"â€¦\"\r\n\r\ndef log(msg: str):\r\n    import datetime\r\n    from pathlib import Path\r\n    \r\n    timestamp = datetime.datetime.now().isoformat()\r\n    entry = f\"{timestamp} - {msg}\"\r\n    print(entry)\r\n    global _bridge_log_seq\r\n    _bridge_log_seq += 1\r\n    _bridge_logs.append((_bridge_log_seq, entry))\r\n        \r\n    # Write to file\r\n    try:\r\n        log_path = Path(\"../backend/logs/webgpu_bridge.log\")\r\n        log_path.parent.mkdir(parents=True, exist_ok=True)\r\n        with open(log_path, \"a\", encoding=\"utf-8\") as f:\r\n            f.write(entry + \"\\n\")\r\n    except Exception as e:\r\n        print(f\"Failed to write to log file: {e}\")\r\n\r\n@app.get(\"/logs\")\r\nasync def get_logs(limit: int = 200, since: int = 0):\r\n    \"\"\"Return recent bridge logs.\r\n\r\n    Query params:\r\n    - limit: max number of log lines to return\r\n    - since: return only entries with seq > since\r\n\r\n    Response:\r\n    - logs: [{seq, line}, ...]\r\n    - last_seq: latest sequence number currently available\r\n    \"\"\"\r\n    # Snapshot to avoid holding references while iterating\r\n    items = list(_bridge_logs)\r\n    if since and since > 0:\r\n        items = [it for it in items if it[0] > since]\r\n    if limit and limit > 0:\r\n        items = items[-limit:]\r\n    last_seq = items[-1][0] if items else _bridge_log_seq\r\n    return {\r\n        \"logs\": [{\"seq\": seq, \"line\": line} for seq, line in items],\r\n        \"last_seq\": last_seq,\r\n    }\r\n\r\n\r\n@app.post(\"/logs/clear\")\r\nasync def clear_logs():\r\n    _bridge_logs.clear()\r\n    return {\"ok\": True}\r\n\r\n@app.get(\"/v1/models\")\r\nasync def list_models():\r\n    \"\"\"\r\n    Return a list of available models.\r\n    Since this is a bridge, we return the models currently loaded in the connected workers.\r\n    \"\"\"\r\n    models = []\r\n    \r\n    if workers[\"chat\"]:\r\n        # We could query the worker for the actual model name, but for now we'll use a placeholder\r\n        # or assume the client knows what it's doing.\r\n        # Ideally, the worker should send its loaded model ID on connection.\r\n        models.append({\r\n            \"id\": \"webgpu-chat\",\r\n            \"object\": \"model\",\r\n            \"created\": 1677610602,\r\n            \"owned_by\": \"webgpu-bridge\"\r\n        })\r\n        \r\n    if workers[\"embed\"]:\r\n        models.append({\r\n            \"id\": \"webgpu-embedding\",\r\n            \"object\": \"model\",\r\n            \"created\": 1677610602,\r\n            \"owned_by\": \"webgpu-bridge\"\r\n        })\r\n        \r\n    return {\"object\": \"list\", \"data\": models}\r\n\r\n\r\n# --- Compatibility endpoint: audit/server-logs ---\r\n# Some UI pages (log-viewer.html) expect '/audit/server-logs' provided by the full backend (ECE_Core).\r\n# If that backend isn't running, provide a graceful fallback here that returns bridge logs so UI doesn't see 404s.\r\nfrom pathlib import Path\r\n\r\n@app.get('/audit/server-logs')\r\nasync def get_audit_server_logs(limit: int = 50):\r\n    try:\r\n        # Try known workspace locations for the backend server log (same heuristic used elsewhere)\r\n        log_file = Path(\"logs/server.log\")\r\n        if not log_file.exists():\r\n            log_file = Path(\"../logs/server.log\")\r\n\r\n        if log_file.exists():\r\n            with log_file.open('r', encoding='utf-8', errors='ignore') as f:\r\n                lines = f.read().splitlines()\r\n            tail = lines[-int(limit):] if limit and len(lines) > 0 else lines\r\n            return {\"logs\": tail, \"count\": len(tail)}\r\n\r\n        # Fallback: serve bridge internal logs if backend log file not present\r\n        items = list(_bridge_logs)[-int(limit):]\r\n        tail = [line for (_seq, line) in items]\r\n        return {\"logs\": tail, \"count\": len(tail)}\r\n    except Exception as e:\r\n        return {\"logs\": [f\"Bridge audit logs error: {str(e)}\"], \"count\": 0}\r\n\r\n@app.websocket(\"/ws/{worker_type}\")\r\nasync def websocket_endpoint(websocket: WebSocket, worker_type: str):\r\n    if worker_type not in workers:\r\n        await websocket.close(code=4000)\r\n        return\r\n    \r\n    await websocket.accept()\r\n    workers[worker_type] = websocket\r\n    log(f\"âœ… {worker_type.upper()} Worker Connected\")\r\n    \r\n    try:\r\n        while True:\r\n            data = await websocket.receive_text()\r\n            message = json.loads(data)\r\n            \r\n            # Log token usage if present\r\n            if \"usage\" in message:\r\n                log(f\"ðŸ“Š Token Usage: {json.dumps(message['usage'])}\")\r\n            elif \"chunk\" in message and \"usage\" in message[\"chunk\"]:\r\n                 # Sometimes usage is inside the chunk\r\n                 log(f\"ðŸ“Š Token Usage (Chunk): {json.dumps(message['chunk']['usage'])}\")\r\n\r\n            req_id = message.get(\"id\")\r\n\r\n            # Capture streamed token/chunk content for debugging.\r\n            # The worker typically sends OpenAI-compatible SSE chunks under `chunk`.\r\n            if req_id and isinstance(message, dict):\r\n                # Handle chunk deltas\r\n                if _LOG_STREAM_DELTAS and \"chunk\" in message:\r\n                    try:\r\n                        ch = message.get(\"chunk\")\r\n                        # Try chat-completions delta\r\n                        if isinstance(ch, dict) and isinstance(ch.get(\"choices\"), list) and ch[\"choices\"]:\r\n                            choice0 = ch[\"choices\"][0] if isinstance(ch[\"choices\"][0], dict) else {}\r\n                            delta = choice0.get(\"delta\") if isinstance(choice0, dict) else None\r\n                            if isinstance(delta, dict) and \"content\" in delta:\r\n                                piece = delta.get(\"content\") or \"\"\r\n                                if piece:\r\n                                    log(f\"Î” {req_id}: {_clip(piece, _LOG_MAX_CHARS_PER_LINE)}\")\r\n                                    meta = _req_meta.get(req_id)\r\n                                    if meta is not None:\r\n                                        meta[\"chars\"] = int(meta.get(\"chars\", 0)) + len(piece)\r\n                                        meta[\"chunks\"] = int(meta.get(\"chunks\", 0)) + 1\r\n                    except Exception:\r\n                        pass\r\n\r\n                # Handle token_events emitted by the browser worker\r\n                if \"token_events\" in message and isinstance(message.get(\"token_events\"), list):\r\n                    try:\r\n                        events = message.get(\"token_events\")\r\n                        meta = _req_meta.get(req_id)\r\n                        for ev in events:\r\n                            # Normalize fields\r\n                            tidx = ev.get(\"idx\")\r\n                            ttext = _clip(ev.get(\"text\", \"\"), _LOG_MAX_CHARS_PER_LINE)\r\n                            tdt = float(ev.get(\"dt_ms\") or ev.get(\"dt\") or 0.0)\r\n                            tlogp = ev.get(\"logprob\")\r\n                            # Log a compact token-line for the viewer to parse\r\n                            log(f\"TOK {req_id} IDX={tidx} DTms={tdt:.2f} TOK=\" + ttext + (\" LOGP=\" + str(tlogp) if tlogp is not None else \"\"))\r\n                            if meta is not None:\r\n                                meta[\"chars\"] = int(meta.get(\"chars\", 0)) + len(ttext)\r\n                                meta[\"chunks\"] = int(meta.get(\"chunks\", 0)) + 1\r\n                    except Exception:\r\n                        pass\r\n            if req_id in active_requests:\r\n                # Put the chunk/result into the queue for the HTTP handler to consume\r\n                await active_requests[req_id].put(message)\r\n                \r\n    except Exception as e:\r\n        log(f\"âŒ {worker_type.upper()} Worker Disconnected: {e}\")\r\n    finally:\r\n        workers[worker_type] = None\r\n\r\nasync def stream_generator(req_id: str):\r\n    queue = active_requests[req_id]\r\n    try:\r\n        while True:\r\n            message = await queue.get()\r\n            \r\n            if message.get(\"error\"):\r\n                yield f\"data: {json.dumps({'error': message['error']})}\\n\\n\"\r\n                break\r\n                \r\n            if message.get(\"done\"):\r\n                # Emit summary telemetry if available\r\n                meta = _req_meta.pop(req_id, None)\r\n                if meta is not None:\r\n                    dt = max(1e-6, time.perf_counter() - float(meta.get(\"t0\", time.perf_counter())))\r\n                    chars = int(meta.get(\"chars\", 0))\r\n                    chunks = int(meta.get(\"chunks\", 0))\r\n                    log(f\"âœ… Done {req_id}: {chars} chars in {dt:.2f}s across {chunks} chunks (~{(chars / dt):.1f} chars/s)\")\r\n                yield \"data: [DONE]\\n\\n\"\r\n                break\r\n            \r\n            # Forward the chunk exactly as received (OpenAI format)\r\n            if \"chunk\" in message:\r\n                yield f\"data: {json.dumps(message['chunk'])}\\n\\n\"\r\n            \r\n    finally:\r\n        if req_id in active_requests:\r\n            del active_requests[req_id]\r\n\r\nasync def collect_full_response(req_id: str):\r\n    \"\"\"\r\n    Collects the full response for non-streaming requests.\r\n    Aggregates chunks if the worker sends them as a stream.\r\n    \"\"\"\r\n    queue = active_requests[req_id]\r\n    \r\n    # Initialize accumulator\r\n    accumulated_content = \"\"\r\n    first_chunk = None\r\n    finish_reason = None\r\n    \r\n    try:\r\n        while True:\r\n            message = await queue.get()\r\n            \r\n            if message.get(\"error\"):\r\n                raise HTTPException(status_code=500, detail=message['error'])\r\n                \r\n            if message.get(\"done\"):\r\n                break\r\n            \r\n            if \"chunk\" in message:\r\n                chunk = message[\"chunk\"]\r\n                \r\n                # If it's a full response object (not a delta), just use it\r\n                if \"choices\" in chunk and \"message\" in chunk[\"choices\"][0]:\r\n                    return chunk\r\n                \r\n                # Otherwise, accumulate deltas\r\n                if not first_chunk:\r\n                    first_chunk = chunk\r\n                \r\n                if \"choices\" in chunk and len(chunk[\"choices\"]) > 0:\r\n                    delta = chunk[\"choices\"][0].get(\"delta\", {})\r\n                    content = delta.get(\"content\", \"\")\r\n                    if content:\r\n                        accumulated_content += content\r\n                    \r\n                    if chunk[\"choices\"][0].get(\"finish_reason\"):\r\n                        finish_reason = chunk[\"choices\"][0][\"finish_reason\"]\r\n                \r\n    finally:\r\n        if req_id in active_requests:\r\n            del active_requests[req_id]\r\n\r\n        meta = _req_meta.pop(req_id, None)\r\n        if meta is not None:\r\n            dt = max(1e-6, time.perf_counter() - float(meta.get(\"t0\", time.perf_counter())))\r\n            chars = int(meta.get(\"chars\", 0))\r\n            chunks = int(meta.get(\"chunks\", 0))\r\n            log(f\"âœ… Done {req_id}: {chars} chars in {dt:.2f}s across {chunks} chunks (~{(chars / dt):.1f} chars/s)\")\r\n            \r\n    if not first_chunk:\r\n        raise HTTPException(status_code=500, detail=\"No response received from WebGPU worker\")\r\n        \r\n    # Construct final response object from accumulated chunks\r\n    final_response = first_chunk.copy()\r\n    final_response[\"object\"] = \"chat.completion\"\r\n    final_response[\"choices\"] = [{\r\n        \"index\": 0,\r\n        \"message\": {\r\n            \"role\": \"assistant\",\r\n            \"content\": accumulated_content\r\n        },\r\n        \"finish_reason\": finish_reason or \"stop\"\r\n    }]\r\n        \r\n    return final_response\r\n\r\n@app.post(\"/v1/chat/completions\")\r\n@app.post(\"/chat/completions\")\r\nasync def chat_completions(request: Request):\r\n    if not workers[\"chat\"]:\r\n        raise HTTPException(status_code=503, detail=\"WebGPU Chat Worker not connected. Open tools/webgpu-server-chat.html\")\r\n    \r\n    body = await request.json()\r\n    req_id = str(uuid.uuid4())\r\n    active_requests[req_id] = asyncio.Queue()\r\n    \r\n    stream = body.get(\"stream\", False)\r\n    log(f\"Chat Request: {req_id} - Model: {body.get('model')} - Stream: {stream}\")\r\n    # Track request timing/throughput\r\n    _req_meta[req_id] = {\"t0\": time.perf_counter(), \"chars\": 0, \"chunks\": 0}\r\n\r\n    # Forward request to browser\r\n    await workers[\"chat\"].send_json({\r\n        \"id\": req_id,\r\n        \"type\": \"chat\",\r\n        \"data\": body\r\n    })\r\n    \r\n    if stream:\r\n        # Return streaming response\r\n        return StreamingResponse(stream_generator(req_id), media_type=\"text/event-stream\")\r\n    else:\r\n        # Return standard JSON response\r\n        response_data = await collect_full_response(req_id)\r\n        # Log a concise summary of the chat response for UI/bridge observability\r\n        try:\r\n            summary = None\r\n            if isinstance(response_data, dict):\r\n                # Try to extract assistant content if present\r\n                choices = response_data.get('choices')\r\n                if choices and isinstance(choices, list) and len(choices) > 0:\r\n                    msg = choices[0].get('message') if isinstance(choices[0], dict) else None\r\n                    if msg and isinstance(msg, dict):\r\n                        content = msg.get('content') or ''\r\n                        summary = content[:200]\r\n            if summary is None:\r\n                summary = str(response_data)[:200]\r\n            log(f\"[WEBGPU-CHAT] RESP {req_id}: {summary}\")\r\n        except Exception:\r\n            pass\r\n        return JSONResponse(content=response_data)\r\n\r\n@app.post(\"/v1/embeddings\")\r\nasync def embeddings(request: Request):\r\n    if not workers[\"embed\"]:\r\n        raise HTTPException(status_code=503, detail=\"WebGPU Embed Worker not connected. Open tools/webgpu-server-embed.html\")\r\n    \r\n    body = await request.json()\r\n    \r\n    # Override model name to match what the worker expects/has loaded\r\n    # The worker is strict about the model name matching its loaded model\r\n    # body[\"model\"] = \"snowflake-arctic-embed-m-q0f32-MLC-b32\" \r\n    \r\n    req_id = str(uuid.uuid4())\r\n    active_requests[req_id] = asyncio.Queue()\r\n    \r\n    log(f\"Embed Request: {req_id} - Input length: {len(str(body.get('input')))}\")\r\n\r\n    # Forward request to browser\r\n    await workers[\"embed\"].send_json({\r\n        \"id\": req_id,\r\n        \"type\": \"embedding\",\r\n        \"data\": body\r\n    })\r\n    \r\n    # Wait for the single response (Embeddings are usually not streamed, but we use the queue for async wait)\r\n    response_msg = await active_requests[req_id].get()\r\n    del active_requests[req_id]\r\n    \r\n    if response_msg.get(\"error\"):\r\n        raise HTTPException(status_code=500, detail=response_msg[\"error\"])\r\n        \r\n    # Log a concise summary of embedding result for visibility\r\n    try:\r\n        res = response_msg.get('result')\r\n        if res:\r\n            summary = str(res)\r\n            log(f\"[WEBGPU-EMBED] RESP {req_id}: {summary[:200]}\")\r\n    except Exception:\r\n        pass\r\n\r\n    return JSONResponse(content=response_msg[\"result\"])\r\n\r\nimport secrets\r\nimport random\r\nimport mimetypes\r\n\r\n# --- Authentication & Config ---\r\nAUTH_TOKEN = os.getenv(\"BRIDGE_TOKEN\")\r\nif not AUTH_TOKEN:\r\n    AUTH_TOKEN = secrets.token_urlsafe(16) # Generate secure token if not set\r\n\r\n# Middleware for Auth\r\n@app.middleware(\"http\")\r\nasync def verify_token(request: Request, call_next):\r\n    # Allow OPTIONS (CORS preflight) and the mobile UI page itself\r\n    if request.method == \"OPTIONS\" or request.url.path in [\"/mobile\", \"/favicon.ico\", \"/logs\"]:\r\n        return await call_next(request)\r\n    \r\n    # Allow local loopback without token (optional, but convenient for localhost dev)\r\n    # client_host = request.client.host\r\n    # if client_host == \"127.0.0.1\" or client_host == \"localhost\":\r\n    #     return await call_next(request)\r\n\r\n    auth_header = request.headers.get(\"Authorization\")\r\n    if not auth_header or not auth_header.startswith(\"Bearer \") or auth_header.split(\" \")[1] != AUTH_TOKEN:\r\n        # Return 401 but allows 403 for specific logic. \r\n        # Using JSON response to keep it clean.\r\n        return JSONResponse(status_code=401, content={\"error\": \"Unauthorized. Invalid Token.\"})\r\n\r\n    return await call_next(request)\r\n\r\n@app.get(\"/mobile\")\r\nasync def serve_mobile_app():\r\n    \"\"\"Serves the lightweight mobile chat interface.\"\"\"\r\n    file_path = \"mobile-chat.html\"\r\n    # If not in current dir, check tools/\r\n    if not os.path.exists(file_path):\r\n        file_path = \"tools/mobile-chat.html\"\r\n    \r\n    if os.path.exists(file_path):\r\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\r\n            return HTMLResponse(content=f.read())\r\n    else:\r\n        return HTMLResponse(content=\"<h1>Mobile App Not Found</h1><p>Ensure mobile-chat.html exists.</p>\", status_code=404)\r\n\r\nfrom fastapi.responses import HTMLResponse\r\n\r\nif __name__ == \"__main__\":\r\n    host = os.getenv(\"BRIDGE_HOST\", \"0.0.0.0\")\r\n    \r\n    # Obfuscated / Random Port Logic\r\n    default_port = os.getenv(\"BRIDGE_PORT\")\r\n    if default_port:\r\n        port = int(default_port)\r\n    else:\r\n        # Pick a random port in the dynamic/private range to obscure services\r\n        port = random.randint(9000, 9999)\r\n\r\n    print(\"\\n\" + \"=\"*60)\r\n    print(f\"ðŸ”’ SECURE BRIDGE STARTING\")\r\n    print(f\"   Host: {host}\")\r\n    print(f\"   Port: {port}\")\r\n    print(f\"   ðŸ”‘ TOKEN: {AUTH_TOKEN}\")\r\n    print(f\"   ðŸ“± Mobile URL: http://{host}:{port}/mobile\")\r\n    print(\"=\"*60 + \"\\n\")\r\n    \r\n    uvicorn.run(app, host=host, port=port)\r\n",
    "source": "tools\\webgpu_bridge.py"
  },
  {
    "id": "tools\\modules\\llm-worker.js",
    "timestamp": 1766356590,
    "role": "file",
    "content": "import { WebWorkerMLCEngineHandler, MLCEngine } from \"https://esm.run/@mlc-ai/web-llm\";\n\n// The handler bridges messages between the Main Thread and the Engine\nconst engine = new MLCEngine();\nconst handler = new WebWorkerMLCEngineHandler(engine);\n\nself.onmessage = (msg) => {\n    handler.onmessage(msg);\n};",
    "source": "tools\\modules\\llm-worker.js"
  },
  {
    "id": "tools\\modules\\sovereign.js",
    "timestamp": 1766311214,
    "role": "file",
    "content": "/* tools/modules/sovereign.js */\r\n\r\n// Import CozoDB bindings from the parent directory\r\nimport initWasm, { CozoDb } from '../cozo_lib_wasm.js';\r\n\r\n/**\r\n * Sovereign Coda Kernel (v2.0)\r\n * Standard Library for Logging, State, Hardware, and Memory.\r\n */\r\n\r\n// --- 1. THE NERVOUS SYSTEM (Unified Logging) ---\r\nexport class SovereignLogger {\r\n    constructor(sourceId) {\r\n        this.source = sourceId;\r\n        this.logChannel = new BroadcastChannel('sovereign-logs');\r\n        this.codaChannel = new BroadcastChannel('coda_logs');\r\n    }\r\n\r\n    info(msg) { this._emit(msg, 'info'); }\r\n    warn(msg) { this._emit(msg, 'warn'); }\r\n    error(msg) { this._emit(msg, 'error'); }\r\n    success(msg) { this._emit(msg, 'success'); }\r\n\r\n    _emit(msg, type) {\r\n        // 1. Console Fallback\r\n        const style = type === 'error' ? 'color:red' : (type === 'success' ? 'color:green' : 'color:blue');\r\n        console.log(`%c[${this.source}] ${msg}`, style);\r\n        \r\n        // 2. Broadcast to Mission Control\r\n        const timestamp = new Date().toISOString();\r\n        const timeShort = new Date().toLocaleTimeString();\r\n        \r\n        try {\r\n            // New JSON Channel (for Mission Control)\r\n            this.codaChannel.postMessage({\r\n                source: this.source,\r\n                type,\r\n                message: msg,\r\n                timestamp\r\n            });\r\n            // Legacy Channel (for Log Viewer compatibility)\r\n            this.logChannel.postMessage({ \r\n                source: 'system', \r\n                msg: `[${this.source}] ${msg}`, \r\n                type, \r\n                time: timeShort \r\n            });\r\n        } catch (e) {\r\n            console.warn('Logger broadcast failed', e);\r\n        }\r\n    }\r\n}\r\n\r\n// --- 2. THE STATE MANAGER (Nano Store) ---\r\n// Zero-dependency reactive state.\r\nexport function createStore(initialState) {\r\n    const listeners = new Set();\r\n    \r\n    const proxy = new Proxy(initialState, {\r\n        set(target, property, value) {\r\n            target[property] = value;\r\n            listeners.forEach(fn => fn(property, value));\r\n            return true;\r\n        }\r\n    });\r\n\r\n    return {\r\n        state: proxy,\r\n        subscribe: (fn) => listeners.add(fn),\r\n        unsubscribe: (fn) => listeners.delete(fn)\r\n    };\r\n}\r\n\r\n// --- 3. HARDWARE DETECTOR (The XPS Fix) ---\r\n// Centralized WebGPU configuration to prevent crashes on 256MB cards.\r\nexport async function getWebGPUConfig(profile = 'mid') {\r\n    if (!navigator.gpu) throw new Error(\"WebGPU not supported\");\r\n    \r\n    // 1. Request Adapter (Prefer High Performance)\r\n    const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' }) \r\n                 || await navigator.gpu.requestAdapter();\r\n    \r\n    if (!adapter) throw new Error(\"No WebGPU Adapter found.\");\r\n\r\n    // 2. Detect Hardware Limits\r\n    const hardwareLimit = adapter.limits.maxStorageBufferBindingSize;\r\n    let requested = 1024 * 1024 * 1024; // Default 1GB\r\n\r\n    // 3. Apply Profile Strategy\r\n    if (profile === 'lite') requested = 256 * 1024 * 1024; // 256MB\r\n    else if (profile === 'mid') requested = 1024 * 1024 * 1024; // 1GB\r\n    else if (profile === 'high') requested = 2048 * 1024 * 1024; // 2GB\r\n\r\n    // 4. The Safety Clamp\r\n    const finalLimit = Math.min(requested, hardwareLimit);\r\n    const isConstrained = finalLimit < requested;\r\n\r\n    return {\r\n        adapter,\r\n        deviceConfig: {\r\n            requiredLimits: { maxStorageBufferBindingSize: finalLimit },\r\n            requiredFeatures: adapter.features.has(\"shader-f16\") ? [\"shader-f16\"] : []\r\n        },\r\n        maxBufferSize: finalLimit,\r\n        isConstrained\r\n    };\r\n}\r\n\r\n// --- 4. MEMORY CORE (CozoDB Helper) ---\r\nexport async function initCozo(wasmUrl = '../cozo_lib_wasm_bg.wasm') {\r\n    await initWasm(wasmUrl);\r\n    return CozoDb;\r\n}\r\n",
    "source": "tools\\modules\\sovereign.js"
  }
]